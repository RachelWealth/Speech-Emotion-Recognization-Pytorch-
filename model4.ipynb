{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f11f69d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有1440行\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILE</th>\n",
       "      <th>EMOTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>db/RAVDESS/Actor_01/03-01-01-01-01-01-01.wav</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>db/RAVDESS/Actor_01/03-01-01-01-01-02-01.wav</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>db/RAVDESS/Actor_01/03-01-01-01-02-01-01.wav</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>db/RAVDESS/Actor_01/03-01-01-01-02-02-01.wav</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db/RAVDESS/Actor_01/03-01-02-01-01-01-01.wav</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>db/RAVDESS/Actor_01/03-01-02-01-01-02-01.wav</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>db/RAVDESS/Actor_01/03-01-02-01-02-01-01.wav</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>db/RAVDESS/Actor_01/03-01-02-01-02-02-01.wav</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>db/RAVDESS/Actor_01/03-01-02-02-01-01-01.wav</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>db/RAVDESS/Actor_01/03-01-02-02-01-02-01.wav</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           FILE EMOTION\n",
       "0  db/RAVDESS/Actor_01/03-01-01-01-01-01-01.wav      01\n",
       "1  db/RAVDESS/Actor_01/03-01-01-01-01-02-01.wav      01\n",
       "2  db/RAVDESS/Actor_01/03-01-01-01-02-01-01.wav      01\n",
       "3  db/RAVDESS/Actor_01/03-01-01-01-02-02-01.wav      01\n",
       "4  db/RAVDESS/Actor_01/03-01-02-01-01-01-01.wav      02\n",
       "5  db/RAVDESS/Actor_01/03-01-02-01-01-02-01.wav      02\n",
       "6  db/RAVDESS/Actor_01/03-01-02-01-02-01-01.wav      02\n",
       "7  db/RAVDESS/Actor_01/03-01-02-01-02-02-01.wav      02\n",
       "8  db/RAVDESS/Actor_01/03-01-02-02-01-01-01.wav      02\n",
       "9  db/RAVDESS/Actor_01/03-01-02-02-01-02-01.wav      02"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: UTF-8 -*-\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "\n",
    "EMOTIONS = {1:\"neu\",2:'cal',3:'hap',4:'sad',5:'ang',6:'fea',7:'dis',8:'sur'}\n",
    "EMOTION_NUM = 8\n",
    "TILTLEEMOTIONS={\"neu\":'中性','cal':'平静','hap':'快乐','sad':'悲伤','ang':'生气','fea':'害怕','dis':'厌恶','sur':'惊讶'}\n",
    "SOURCE_PATH = \"db/RAVDESS/\"\n",
    "SAMPLE_RATE = 48000\n",
    "EPOCH=10\n",
    "FILE_PATH=[]\n",
    "DURATION=3\n",
    "OFFSET=0.5\n",
    "\n",
    "df = pd.DataFrame(columns = ['FILE','EMOTION',])\n",
    "FILE_NAME=[]\n",
    "EMOTIONLIST=[]\n",
    "for director, _, file_names in os.walk(SOURCE_PATH):\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(director+'/',file_name)\n",
    "        FILE_NAME.append(file_path)\n",
    "        EMOTIONLIST.append(file_name.split('.')[0].split('-')[2])\n",
    "df[\"FILE\"]=FILE_NAME\n",
    "df[\"EMOTION\"]=EMOTIONLIST\n",
    "\n",
    "print(\"共有{}行\".format(df.shape[0]))\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "952453d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index前10个:\t [135, 368, 750, 801, 1322, 1060, 613, 994, 527, 484]\n",
      "eval_index前10个:\t [1092, 495, 75, 1398, 215, 1108, 1279, 223, 735, 1053]\n",
      "test_index前十个:\t [65, 1093, 925, 1170, 536, 675, 1417, 921, 1081, 1383]\n",
      "train_index/(train_index+test_eval_index)=1152/(1152+288)=0.8\n",
      "eval_index/(test_index+eval_index)=144/(144+144)=0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_index,test_eval_index=train_test_split(list(df.index),test_size=0.2,random_state=1)\n",
    "test_index,eval_index=train_test_split(test_eval_index,test_size=0.5,random_state=1)\n",
    "\n",
    "print(\"train_index前10个:\\t\",train_index[:10])\n",
    "print(\"eval_index前10个:\\t\",eval_index[:10])\n",
    "print(\"test_index前十个:\\t\",test_index[:10])\n",
    "print('train_index/(train_index+test_eval_index)={}/({}+{})={}'.format(len(train_index),len(train_index),len(test_eval_index),len(train_index)/(len(train_index)+len(test_eval_index))))\n",
    "print('eval_index/(test_index+eval_index)={}/({}+{})={}'.format(len(eval_index),len(test_index),len(eval_index),len(eval_index)/(len(eval_index)+len(test_index))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "279eed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "def getMELspec(data,sr):\n",
    "    # shape=(n_mels, t)\n",
    "    mel_spec = librosa.feature.melspectrogram(y = data,\n",
    "                                              sr = SAMPLE_RATE,\n",
    "                                              n_fft=1024,      # length of the FFT window\n",
    "                                              win_length=1024,\n",
    "                                              window='hamming',\n",
    "                                              hop_length=512,\n",
    "                                              n_mels=64\n",
    "                                             )\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec,ref=np.max)\n",
    "    mfccs = librosa.feature.mfcc(S=mel_spec_db)\n",
    "    return mel_spec_db,mfccs\n",
    "\n",
    "y_data=np.array(df['EMOTION'])\n",
    "y_data=y_data.astype(np.int32)\n",
    "y_data=y_data-1\n",
    "\n",
    "alpha = 0.97\n",
    "def PreEmphsised(data):\n",
    "    return np.append(data[0],data[1:] - alpha * data[:-1])\n",
    "\n",
    "def sameLenData(data):\n",
    "    smLenData = np.zeros(SAMPLE_RATE*DURATION)\n",
    "    smLenData[0:len(data)]=data\n",
    "    return smLenData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fdd716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "scaler = StandardScaler()\n",
    "DURATION=3\n",
    "OFFSET=0.5\n",
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self,index,setName=None):\n",
    "        self.x_data = []\n",
    "        self.arg = np.zeros([1,144000])\n",
    "        self.y_data = []\n",
    "        with tqdm(total=len(index)+1,desc=\"数据加载\") as loadbar:\n",
    "            for i in index: # 写入1440个文件的数据\n",
    "                data, sr = librosa.load(df['FILE'][i],sr=SAMPLE_RATE,duration=DURATION,offset=OFFSET)\n",
    "                smLenData = sameLenData(data)\n",
    "                # 预加重\n",
    "                smLenData = PreEmphsised(smLenData)\n",
    "                # 特征向量\n",
    "                mel_data,mfcc_data = getMELspec(smLenData,sr)\n",
    "                # 差分向量\n",
    "                #_,_,mel_data = get3DMel(mel_data)\n",
    "                self.x_data.append(list(mel_data))\n",
    "                self.y_data.append(y_data[i])\n",
    "                loadbar.update(1)\n",
    "#             if setName=='train_index':\n",
    "#                 self.x_data=np.concatenate([self.x_data,arg_data],axis=0)\n",
    "#                 self.y_data=np.concatenate([self.y_data,arg_label],axis=0)\n",
    "            self.x_data=np.expand_dims(self.x_data,1)\n",
    "            shape=np.array(self.x_data).shape\n",
    "            self.x_data = np.reshape(self.x_data,newshape=(shape[0],-1))\n",
    "            if setName=='train_index':\n",
    "                self.x_data = scaler.fit_transform(self.x_data)\n",
    "            else:\n",
    "                self.x_data = scaler.transform(self.x_data)\n",
    "            self.x_data=np.reshape(self.x_data,newshape=shape)\n",
    "            self.x_data=torch.from_numpy(np.array(self.x_data,dtype=np.float64))\n",
    "            self.y_data=torch.from_numpy(np.array(self.y_data,dtype=np.float64))\n",
    "  \n",
    "            self.len = len(index)\n",
    "            loadbar.update(1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c292971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "数据加载: 100%|████████████████████████████████████████████████████████████████████| 1153/1153 [00:48<00:00, 23.96it/s]\n",
      "数据加载: 100%|██████████████████████████████████████████████████████████████████████| 145/145 [00:04<00:00, 29.59it/s]\n",
      "数据加载: 100%|██████████████████████████████████████████████████████████████████████| 145/145 [00:05<00:00, 28.03it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=32\n",
    "\n",
    "# 训练集加载\n",
    "train_dataset = SpeechDataset(train_index,'train_index')\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          shuffle=True,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                         )\n",
    "# 验证集加载\n",
    "eval_dataset = SpeechDataset(eval_index)\n",
    "eval_loader = DataLoader(eval_dataset,\n",
    "                          shuffle=False,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                         )\n",
    "# 测试集加载\n",
    "test_dataset = SpeechDataset(test_index)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                          shuffle=False,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c78df93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1152, 1, 64, 282])\n",
      "torch.Size([144, 1, 64, 282])\n",
      "torch.Size([144, 1, 64, 282])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.x_data.shape)\n",
    "print(eval_dataset.x_data.shape)\n",
    "print(test_dataset.x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33347a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: torch.Size([1152, 1, 64, 282])   y_data torch.Size([1152])\n",
      "[[[-0.67325471 -0.6821769  -0.69511429 ... -0.63889715 -0.64009395\n",
      "   -0.12269867]\n",
      "  [-0.62930198 -0.59434941 -0.60018943 ... -0.55454918 -0.56611444\n",
      "    0.14377254]\n",
      "  [-0.61070813 -0.5604981  -0.57121697 ... -0.5390266  -0.5435462\n",
      "   -0.06885969]\n",
      "  ...\n",
      "  [-1.04204697 -1.06620386 -1.07144973 ...  0.01656576 -0.19195955\n",
      "   -0.21951804]\n",
      "  [-1.0418595  -1.07270438 -1.07460435 ... -0.04612548 -0.30882887\n",
      "   -0.15334563]\n",
      "  [-1.03902234 -1.06338046 -1.07141052 ... -0.09199534 -0.34217952\n",
      "   -0.38634281]]]\n",
      "[[[2.15082589 0.50382796 0.43699593 ... 3.69490294 3.83674473 3.89645083]\n",
      "  [2.38720546 1.01889965 1.01030396 ... 1.4825624  1.45573554 1.25276435]\n",
      "  [1.89543636 1.08976406 1.02939147 ... 0.51136153 0.52635476 0.48685327]\n",
      "  ...\n",
      "  [2.03571829 1.45808851 1.78926593 ... 2.24626856 2.29379796 2.1371975 ]\n",
      "  [2.08007865 1.46623807 1.63826211 ... 2.16340767 2.16687631 2.19449819]\n",
      "  [2.16775224 1.86209643 1.72413553 ... 2.14209925 2.45407809 2.25984235]]]\n",
      "[[[-0.4257037  -0.43329915 -0.44958875 ... -0.43081116 -0.42947406\n",
      "   -0.43211949]\n",
      "  [-0.31297175 -0.24447725 -0.2509149  ... -0.31365687 -0.32312423\n",
      "   -0.3400689 ]\n",
      "  [-0.29416954 -0.20259875 -0.22408623 ...  0.04502089 -0.30298551\n",
      "   -0.31527431]\n",
      "  ...\n",
      "  [-0.82520401 -0.84708481 -0.85089225 ...  1.00757977  0.52584528\n",
      "    0.54357526]\n",
      "  [-0.82529567 -0.85293428 -0.85382905 ...  0.97437292  0.77931921\n",
      "    0.69027301]\n",
      "  [-0.81939792 -0.83854671 -0.84617996 ...  1.24546998  1.03420691\n",
      "    0.7570671 ]]]\n"
     ]
    }
   ],
   "source": [
    "print('x_data:',train_dataset.x_data.shape,'  y_data',train_dataset.y_data.shape)\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "print(np.array(train_dataset.x_data[0]))\n",
    "print(np.array(eval_dataset.x_data[0]))\n",
    "print(np.array(test_dataset.x_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df600b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Inception, self).__init__()\n",
    "        self.block1x1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.block5x5_1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.block5x5_2 = torch.nn.Conv2d(16, 24, kernel_size=5, padding=2)\n",
    "        self.block3x3_1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.block3x3_2 = torch.nn.Conv2d(16, 24, kernel_size=3, padding=1)\n",
    "        self.block3x3_3 = torch.nn.Conv2d(24, 24, kernel_size=3, padding=1)\n",
    "        self.block_pool = torch.nn.Conv2d(in_channels, 24, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        block1x1 = self.block1x1(x)\n",
    "        block5x5 = self.block5x5_2(self.block5x5_1(x))\n",
    "        block3x3 = self.block3x3_3(self.block3x3_2(self.block3x3_1(x)))\n",
    "        block_pool = self.block_pool(F.avg_pool2d(x, kernel_size=3, stride=1, padding=1))\n",
    "        outputs = [block1x1, block3x3, block5x5, block_pool]\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f08ae8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class attention(nn.Module):\n",
    "    def __init__(self,en_hidden_dim,de_hidden_dim,direction):\n",
    "        super().__init__()\n",
    "        middle_size = de_hidden_dim\n",
    "        # H与s0拼接出来为(batch_size,src_len,en_hidden_dim*direction+de_hidden_dim)\n",
    "        # 需要转化维度。首先，a(batch_size,src_len),公式2得知v(batch_size,?),E(?,src_len)\n",
    "        # 因此?可以是任意维度，此处取de_hidden_dim\n",
    "        self.s_en2de=nn.Linear(en_hidden_dim*2,de_hidden_dim)\n",
    "        self.attn=nn.Linear(en_hidden_dim*direction+de_hidden_dim,middle_size)\n",
    "        self.v = nn.Linear(middle_size,1)\n",
    "        \n",
    "    def forward(self,gru_output,gru_hidden):       \n",
    "        # H(batch_size,src_len,en_hidden_dim*direction)\n",
    "        _,src_len,_=gru_output.shape\n",
    "        # s0(batch_size,en_hidden_dim*direction)\n",
    "        # 但是s0作为dcoder初始隐藏状态，应该是s0(batch_size,de_hidden_dim)\n",
    "        # 并且为了与H拼接，需要加一个维度，变成s0(batch_size,src_len,de_hidden_dim)\n",
    "        s = torch.cat((gru_hidden[:, -2,: ], gru_hidden[:, -1,:]),dim=1)  # (batch_size,en_hidden_dim*direction)\n",
    "        s = self.s_en2de(s)  # (batch_size,de_hidden_dim)\n",
    "        # s=torc.tanh(s)  \n",
    "        s=s.unsqueeze(1).repeat(1,src_len,1) # (batch_size,src_len,de_hidden_dim)     \n",
    "        self.attn_hidden = torch.tanh(self.attn(torch.cat((s,gru_output),dim=2)))     \n",
    "        attention_weight = self.v(self.attn_hidden).squeeze(2) #(batch_size,1,src_len)\n",
    "        \n",
    "        return F.softmax(attention_weight,dim=1)   #A dimension along which Softmax will be computed (so every slice along dim will sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dcb8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size,input_size,p=128,16,0.3\n",
    "kernel_size,stride=4,4\n",
    "directional = 2\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "         input dimension every epoch is [32,1,128,282]\n",
    "        \"\"\"\n",
    "        # conv2d\n",
    "#         self.conv2d=nn.Sequential(# No 1\n",
    "#                                    nn.Conv2d(in_channels=1,out_channels=8,kernel_size=3,stride=1,padding=1)\n",
    "#                                   ,nn.BatchNorm2d(8)\n",
    "#                                   ,nn.ReLU()\n",
    "#                                   ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "#                                   ,nn.Dropout(p)\n",
    "                                    \n",
    "#                                   #,Inception(8)  #outchannel 88     35840\n",
    "                                  \n",
    "#                                   ,ResidualBlock(8)\n",
    "            \n",
    "#                                   ,nn.Conv2d(in_channels=8,out_channels=16,kernel_size=3,stride=1,padding=1)\n",
    "#                                   ,nn.BatchNorm2d(128)\n",
    "#                                   ,nn.ReLU()\n",
    "#                                   ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "#                                   ,nn.Dropout(p)\n",
    "#         )\n",
    "        self.conv2d=nn.Sequential(# No 1\n",
    "                                   nn.Conv2d(in_channels=1,out_channels=16,kernel_size=3,stride=1,padding=1)\n",
    "                                  ,nn.BatchNorm2d(16)\n",
    "                                  ,nn.ReLU()\n",
    "                                  ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "                                  ,nn.Dropout(p)\n",
    "            \n",
    "                                  # No 2\n",
    "                                  ,nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "                                  ,nn.BatchNorm2d(32)\n",
    "                                  ,nn.ReLU()\n",
    "                                  ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "                                  ,nn.Dropout(p)\n",
    "            \n",
    "                                  # No 3\n",
    "                                  ,nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1)\n",
    "                                  ,nn.BatchNorm2d(64)\n",
    "                                  ,nn.ReLU()\n",
    "                                  ,nn.MaxPool2d(kernel_size=4,stride=4)\n",
    "                                  ,nn.Dropout(p)\n",
    "            \n",
    "                                  # No 4\n",
    "                                  ,nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1)\n",
    "                                  ,nn.BatchNorm2d(64)\n",
    "                                  ,nn.ReLU()\n",
    "                                  ,nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "                                  ,nn.Dropout(p)\n",
    "        )\n",
    "        \n",
    "        # GRU\n",
    "        self.mp = nn.MaxPool2d(kernel_size=kernel_size,stride=stride)\n",
    "        self.gru = nn.GRU(input_size=input_size,hidden_size=hidden_size,bidirectional =bool(directional-1),batch_first=True)\n",
    "        self.dp = nn.Dropout(p)\n",
    "        \n",
    "        self.attention = attention(hidden_size,hidden_size,directional)\n",
    "        self.emo_linear=nn.Linear(hidden_size*directional+1024,EMOTION_NUM) \n",
    "       \n",
    "        self.out_dropout = nn.Dropout(0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=x.float()\n",
    "        \n",
    "        # conv\n",
    "        #convx=x[:,1].unsqueeze(1)\n",
    "        convx = self.conv2d(x)\n",
    "        convx = torch.flatten(convx,1) \n",
    "        #print(convx.shape)\n",
    "        \n",
    "        #GRU\n",
    "        x = self.mp(x)   # input x:(N,C,freq,time)\n",
    "        x = torch.squeeze(x)\n",
    "        x = x.permute(0,2,1)  # batch_size, time, freq\n",
    "        #x = torch.cat([x[:,0],x[:,1],x[:,2]],dim=2)\n",
    "        \n",
    "        # gru_output(batch_size, sequence length, hidden_size*directional)\n",
    "        # gru_h(batch_size,n_layer*directional,hidden_size)\n",
    "        # gru_h=[for_1,back_1,for_2,back_2...] \n",
    "        \n",
    "        gru_output,gru_h=self.gru(x) # gru_output(B, S, H*2), gru_h(n_layer*directional,B,H)\n",
    "        gru_h=gru_h.permute(1,0,2)\n",
    "        gru_output = self.dp(gru_output)\n",
    "        attention_weight = self.attention(gru_output,gru_h) # (batch_size,1,src_len)\n",
    "        \n",
    "        # (batch_size,1,src_len)*(batch_size,src_len,hidden_size*directional)\n",
    "        # (batch_size,1,hidden_size*directional)\n",
    "        attention_weight = attention_weight.unsqueeze(1)\n",
    "#         print(attention_weight.shape)\n",
    "#         print(gru_output.shape)\n",
    "        attention = torch.bmm(attention_weight,gru_output)\n",
    "        attention = torch.squeeze(attention,1) #（batch_size,hidden_size*directional）\n",
    "        \n",
    "        # cat\n",
    "        output = torch.cat([convx,attention],dim=1)\n",
    "        #print(attention.shape)\n",
    "        #print(output.shape)\n",
    "        output = self.out_dropout(self.emo_linear(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bde0d0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01,weight_decay=1e-3,momentum=0.5)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "loss_set=[]\n",
    "accuracy_train=[]\n",
    "accuracy_validate=[]\n",
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx,(input,target) in enumerate(train_loader,0):\n",
    "        input,target = input.to(device),target.to(device)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output=model(input)\n",
    "        _,pre = torch.max(output.data,dim=1)\n",
    "        correct += (pre==target).sum().item()\n",
    "        total += target.size(0)\n",
    "        target = target.long()\n",
    "        loss = criterion(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        loss_set.append(loss.item())\n",
    "        if batch_idx % 20 == 19:\n",
    "            print('[%d,%5d] loss: %.5f, running_loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / min((batch_idx+1)*BATCH_SIZE,df.shape[0]), running_loss))\n",
    "            running_loss = 0\n",
    "    loss_set.append(running_loss)\n",
    "    accuracy_train.append(correct / total)\n",
    "    print('Accacy on train_loader set: %d %% [%d/%d]' % (100 * correct / total, correct, total))   \n",
    "      \n",
    "#total = 0\n",
    "#correct = 0\n",
    "def validate(loader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for (input,target) in (eval_loader if loader=='eval_loader' else test_loader):\n",
    "        model.eval()\n",
    "        input,target  =input.to(device),target.to(device)\n",
    "        output = model(input)\n",
    "        _,pre = torch.max(output.data,dim=1)\n",
    "        correct += (pre==target).sum().item()\n",
    "        total += target.size(0)  \n",
    "    currect_rate = correct / total\n",
    "    print('Accacy on %s set: %d %% [%d/%d]' % (loader,100 * correct / total, correct, total)) \n",
    "    accuracy_validate.append(currect_rate)\n",
    "    return currect_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95c01cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='model\\\\model4.pt' \n",
    "opti_path='model\\\\opti4.pt' \n",
    "loss_path='model\\\\loss4.txt'\n",
    "accur_train_path='model\\\\accur_train4.txt'\n",
    "accur_valid_path='model\\\\accur_valid4.txt'\n",
    "def saveModel(model_path):\n",
    "    torch.save(model.state_dict(),model_path)\n",
    "    torch.save(optimizer.state_dict(),opti_path) \n",
    "#     print(\"Model's state_dict:\")\n",
    "#     for param_tensor in model.state_dict():\n",
    "#         print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "        \n",
    "def loadModel(model_path):\n",
    "    model = Model()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model\n",
    "\n",
    "def saveData(loss,accuracy_train,accuracy_validate):\n",
    "    np.savetxt(loss_path,np.array(loss),fmt='%0.8f')\n",
    "    np.savetxt(accur_train_path,np.array(accuracy_train),fmt='%0.8f')\n",
    "    np.savetxt(accur_valid_path,np.array(accuracy_validate),fmt='%0.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44ddf166",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   20] loss: 0.07471, running_loss: 47.812\n",
      "Accacy on train_loader set: 21 % [252/1152]\n",
      "Accacy on eval_loader set: 16 % [24/144]\n",
      "[2,   20] loss: 0.05883, running_loss: 37.650\n",
      "Accacy on train_loader set: 31 % [365/1152]\n",
      "Accacy on eval_loader set: 15 % [22/144]\n",
      "[3,   20] loss: 0.05535, running_loss: 35.426\n",
      "Accacy on train_loader set: 35 % [414/1152]\n",
      "Accacy on eval_loader set: 15 % [23/144]\n",
      "[4,   20] loss: 0.05072, running_loss: 32.458\n",
      "Accacy on train_loader set: 39 % [450/1152]\n",
      "Accacy on eval_loader set: 15 % [22/144]\n",
      "[5,   20] loss: 0.04798, running_loss: 30.707\n",
      "Accacy on train_loader set: 40 % [468/1152]\n",
      "Accacy on eval_loader set: 15 % [23/144]\n",
      "[6,   20] loss: 0.04931, running_loss: 31.556\n",
      "Accacy on train_loader set: 42 % [492/1152]\n",
      "Accacy on eval_loader set: 18 % [27/144]\n",
      "[7,   20] loss: 0.04668, running_loss: 29.877\n",
      "Accacy on train_loader set: 44 % [513/1152]\n",
      "Accacy on eval_loader set: 18 % [26/144]\n",
      "[8,   20] loss: 0.04550, running_loss: 29.122\n",
      "Accacy on train_loader set: 45 % [522/1152]\n",
      "Accacy on eval_loader set: 20 % [29/144]\n",
      "[9,   20] loss: 0.04271, running_loss: 27.334\n",
      "Accacy on train_loader set: 46 % [541/1152]\n",
      "Accacy on eval_loader set: 21 % [31/144]\n",
      "[10,   20] loss: 0.04213, running_loss: 26.964\n",
      "Accacy on train_loader set: 48 % [562/1152]\n",
      "Accacy on eval_loader set: 21 % [31/144]\n",
      "[11,   20] loss: 0.04247, running_loss: 27.181\n",
      "Accacy on train_loader set: 49 % [568/1152]\n",
      "Accacy on eval_loader set: 22 % [33/144]\n",
      "[12,   20] loss: 0.04152, running_loss: 26.570\n",
      "Accacy on train_loader set: 48 % [553/1152]\n",
      "Accacy on eval_loader set: 22 % [32/144]\n",
      "[13,   20] loss: 0.04258, running_loss: 27.252\n",
      "Accacy on train_loader set: 48 % [557/1152]\n",
      "Accacy on eval_loader set: 22 % [32/144]\n",
      "[14,   20] loss: 0.04165, running_loss: 26.654\n",
      "Accacy on train_loader set: 50 % [580/1152]\n",
      "Accacy on eval_loader set: 26 % [38/144]\n",
      "[15,   20] loss: 0.03941, running_loss: 25.225\n",
      "Accacy on train_loader set: 52 % [609/1152]\n",
      "Accacy on eval_loader set: 20 % [30/144]\n",
      "[16,   20] loss: 0.04068, running_loss: 26.037\n",
      "Accacy on train_loader set: 50 % [578/1152]\n",
      "Accacy on eval_loader set: 25 % [37/144]\n",
      "[17,   20] loss: 0.03811, running_loss: 24.392\n",
      "Accacy on train_loader set: 54 % [627/1152]\n",
      "Accacy on eval_loader set: 29 % [42/144]\n",
      "[18,   20] loss: 0.03687, running_loss: 23.596\n",
      "Accacy on train_loader set: 53 % [618/1152]\n",
      "Accacy on eval_loader set: 29 % [42/144]\n",
      "[19,   20] loss: 0.03786, running_loss: 24.231\n",
      "Accacy on train_loader set: 54 % [629/1152]\n",
      "Accacy on eval_loader set: 29 % [42/144]\n",
      "[20,   20] loss: 0.03810, running_loss: 24.383\n",
      "Accacy on train_loader set: 54 % [629/1152]\n",
      "Accacy on eval_loader set: 35 % [51/144]\n",
      "[21,   20] loss: 0.03669, running_loss: 23.484\n",
      "Accacy on train_loader set: 55 % [643/1152]\n",
      "Accacy on eval_loader set: 31 % [46/144]\n",
      "[22,   20] loss: 0.03583, running_loss: 22.931\n",
      "Accacy on train_loader set: 56 % [653/1152]\n",
      "Accacy on eval_loader set: 32 % [47/144]\n",
      "[23,   20] loss: 0.03610, running_loss: 23.104\n",
      "Accacy on train_loader set: 56 % [648/1152]\n",
      "Accacy on eval_loader set: 34 % [50/144]\n",
      "[24,   20] loss: 0.03545, running_loss: 22.687\n",
      "Accacy on train_loader set: 58 % [674/1152]\n",
      "Accacy on eval_loader set: 31 % [45/144]\n",
      "[25,   20] loss: 0.03390, running_loss: 21.695\n",
      "Accacy on train_loader set: 57 % [666/1152]\n",
      "Accacy on eval_loader set: 41 % [60/144]\n",
      "[26,   20] loss: 0.03532, running_loss: 22.605\n",
      "Accacy on train_loader set: 58 % [670/1152]\n",
      "Accacy on eval_loader set: 37 % [54/144]\n",
      "[27,   20] loss: 0.03399, running_loss: 21.754\n",
      "Accacy on train_loader set: 57 % [667/1152]\n",
      "Accacy on eval_loader set: 32 % [47/144]\n",
      "[28,   20] loss: 0.03420, running_loss: 21.885\n",
      "Accacy on train_loader set: 59 % [680/1152]\n",
      "Accacy on eval_loader set: 39 % [57/144]\n",
      "[29,   20] loss: 0.03288, running_loss: 21.040\n",
      "Accacy on train_loader set: 60 % [700/1152]\n",
      "Accacy on eval_loader set: 34 % [50/144]\n",
      "[30,   20] loss: 0.03371, running_loss: 21.575\n",
      "Accacy on train_loader set: 60 % [698/1152]\n",
      "Accacy on eval_loader set: 36 % [52/144]\n",
      "[31,   20] loss: 0.03120, running_loss: 19.970\n",
      "Accacy on train_loader set: 60 % [697/1152]\n",
      "Accacy on eval_loader set: 38 % [55/144]\n",
      "[32,   20] loss: 0.03271, running_loss: 20.933\n",
      "Accacy on train_loader set: 61 % [710/1152]\n",
      "Accacy on eval_loader set: 40 % [59/144]\n",
      "[33,   20] loss: 0.03370, running_loss: 21.568\n",
      "Accacy on train_loader set: 61 % [713/1152]\n",
      "Accacy on eval_loader set: 34 % [49/144]\n",
      "[34,   20] loss: 0.03254, running_loss: 20.829\n",
      "Accacy on train_loader set: 62 % [718/1152]\n",
      "Accacy on eval_loader set: 34 % [49/144]\n",
      "[35,   20] loss: 0.03151, running_loss: 20.166\n",
      "Accacy on train_loader set: 61 % [713/1152]\n",
      "Accacy on eval_loader set: 33 % [48/144]\n",
      "[36,   20] loss: 0.03078, running_loss: 19.697\n",
      "Accacy on train_loader set: 63 % [735/1152]\n",
      "Accacy on eval_loader set: 38 % [56/144]\n",
      "[37,   20] loss: 0.03137, running_loss: 20.077\n",
      "Accacy on train_loader set: 63 % [736/1152]\n",
      "Accacy on eval_loader set: 38 % [55/144]\n",
      "[38,   20] loss: 0.03119, running_loss: 19.964\n",
      "Accacy on train_loader set: 63 % [735/1152]\n",
      "Accacy on eval_loader set: 38 % [55/144]\n",
      "[39,   20] loss: 0.03148, running_loss: 20.145\n",
      "Accacy on train_loader set: 65 % [752/1152]\n",
      "Accacy on eval_loader set: 36 % [53/144]\n",
      "[40,   20] loss: 0.02965, running_loss: 18.979\n",
      "Accacy on train_loader set: 65 % [751/1152]\n",
      "Accacy on eval_loader set: 33 % [48/144]\n",
      "[41,   20] loss: 0.02883, running_loss: 18.451\n",
      "Accacy on train_loader set: 65 % [749/1152]\n",
      "Accacy on eval_loader set: 48 % [70/144]\n",
      "[42,   20] loss: 0.02852, running_loss: 18.256\n",
      "Accacy on train_loader set: 66 % [771/1152]\n",
      "Accacy on eval_loader set: 47 % [68/144]\n",
      "[43,   20] loss: 0.03018, running_loss: 19.314\n",
      "Accacy on train_loader set: 63 % [737/1152]\n",
      "Accacy on eval_loader set: 45 % [66/144]\n",
      "[44,   20] loss: 0.02979, running_loss: 19.063\n",
      "Accacy on train_loader set: 65 % [757/1152]\n",
      "Accacy on eval_loader set: 36 % [53/144]\n",
      "[45,   20] loss: 0.02828, running_loss: 18.102\n",
      "Accacy on train_loader set: 67 % [779/1152]\n",
      "Accacy on eval_loader set: 41 % [60/144]\n",
      "[46,   20] loss: 0.02836, running_loss: 18.148\n",
      "Accacy on train_loader set: 67 % [780/1152]\n",
      "Accacy on eval_loader set: 35 % [51/144]\n",
      "[47,   20] loss: 0.02790, running_loss: 17.858\n",
      "Accacy on train_loader set: 67 % [782/1152]\n",
      "Accacy on eval_loader set: 44 % [64/144]\n",
      "[48,   20] loss: 0.02641, running_loss: 16.902\n",
      "Accacy on train_loader set: 69 % [795/1152]\n",
      "Accacy on eval_loader set: 41 % [60/144]\n",
      "[49,   20] loss: 0.02714, running_loss: 17.370\n",
      "Accacy on train_loader set: 65 % [758/1152]\n",
      "Accacy on eval_loader set: 47 % [69/144]\n",
      "[50,   20] loss: 0.02689, running_loss: 17.211\n",
      "Accacy on train_loader set: 69 % [805/1152]\n",
      "Accacy on eval_loader set: 31 % [46/144]\n",
      "[51,   20] loss: 0.02688, running_loss: 17.203\n",
      "Accacy on train_loader set: 69 % [796/1152]\n",
      "Accacy on eval_loader set: 47 % [69/144]\n",
      "[52,   20] loss: 0.02305, running_loss: 14.749\n",
      "Accacy on train_loader set: 70 % [814/1152]\n",
      "Accacy on eval_loader set: 50 % [73/144]\n",
      "[53,   20] loss: 0.02804, running_loss: 17.944\n",
      "Accacy on train_loader set: 67 % [783/1152]\n",
      "Accacy on eval_loader set: 44 % [64/144]\n",
      "[54,   20] loss: 0.02676, running_loss: 17.124\n",
      "Accacy on train_loader set: 69 % [796/1152]\n",
      "Accacy on eval_loader set: 42 % [61/144]\n",
      "[55,   20] loss: 0.02611, running_loss: 16.707\n",
      "Accacy on train_loader set: 70 % [807/1152]\n",
      "Accacy on eval_loader set: 39 % [57/144]\n",
      "[56,   20] loss: 0.02377, running_loss: 15.213\n",
      "Accacy on train_loader set: 69 % [797/1152]\n",
      "Accacy on eval_loader set: 45 % [66/144]\n",
      "[57,   20] loss: 0.02461, running_loss: 15.747\n",
      "Accacy on train_loader set: 69 % [805/1152]\n",
      "Accacy on eval_loader set: 40 % [58/144]\n",
      "[58,   20] loss: 0.02458, running_loss: 15.733\n",
      "Accacy on train_loader set: 70 % [808/1152]\n",
      "Accacy on eval_loader set: 39 % [57/144]\n",
      "[59,   20] loss: 0.02573, running_loss: 16.465\n",
      "Accacy on train_loader set: 70 % [808/1152]\n",
      "Accacy on eval_loader set: 41 % [60/144]\n",
      "[60,   20] loss: 0.02502, running_loss: 16.010\n",
      "Accacy on train_loader set: 69 % [806/1152]\n",
      "Accacy on eval_loader set: 44 % [64/144]\n",
      "[61,   20] loss: 0.02329, running_loss: 14.908\n",
      "Accacy on train_loader set: 72 % [836/1152]\n",
      "Accacy on eval_loader set: 40 % [59/144]\n",
      "[62,   20] loss: 0.02352, running_loss: 15.056\n",
      "Accacy on train_loader set: 73 % [852/1152]\n",
      "Accacy on eval_loader set: 42 % [61/144]\n",
      "[63,   20] loss: 0.02289, running_loss: 14.652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 71 % [827/1152]\n",
      "Accacy on eval_loader set: 40 % [59/144]\n",
      "[64,   20] loss: 0.02294, running_loss: 14.679\n",
      "Accacy on train_loader set: 73 % [844/1152]\n",
      "Accacy on eval_loader set: 40 % [59/144]\n",
      "[65,   20] loss: 0.02254, running_loss: 14.423\n",
      "Accacy on train_loader set: 75 % [873/1152]\n",
      "Accacy on eval_loader set: 45 % [65/144]\n",
      "[66,   20] loss: 0.02469, running_loss: 15.801\n",
      "Accacy on train_loader set: 72 % [831/1152]\n",
      "Accacy on eval_loader set: 38 % [55/144]\n",
      "[67,   20] loss: 0.02266, running_loss: 14.505\n",
      "Accacy on train_loader set: 72 % [836/1152]\n",
      "Accacy on eval_loader set: 50 % [72/144]\n",
      "[68,   20] loss: 0.02225, running_loss: 14.238\n",
      "Accacy on train_loader set: 73 % [841/1152]\n",
      "Accacy on eval_loader set: 42 % [61/144]\n",
      "[69,   20] loss: 0.02559, running_loss: 16.381\n",
      "Accacy on train_loader set: 73 % [851/1152]\n",
      "Accacy on eval_loader set: 49 % [71/144]\n",
      "[70,   20] loss: 0.02258, running_loss: 14.454\n",
      "Accacy on train_loader set: 75 % [869/1152]\n",
      "Accacy on eval_loader set: 46 % [67/144]\n",
      "[71,   20] loss: 0.02185, running_loss: 13.981\n",
      "Accacy on train_loader set: 75 % [865/1152]\n",
      "Accacy on eval_loader set: 36 % [52/144]\n",
      "[72,   20] loss: 0.02128, running_loss: 13.619\n",
      "Accacy on train_loader set: 75 % [867/1152]\n",
      "Accacy on eval_loader set: 45 % [66/144]\n",
      "[73,   20] loss: 0.02118, running_loss: 13.556\n",
      "Accacy on train_loader set: 73 % [843/1152]\n",
      "Accacy on eval_loader set: 48 % [70/144]\n",
      "[74,   20] loss: 0.02054, running_loss: 13.144\n",
      "Accacy on train_loader set: 74 % [860/1152]\n",
      "Accacy on eval_loader set: 44 % [64/144]\n",
      "[75,   20] loss: 0.02175, running_loss: 13.922\n",
      "Accacy on train_loader set: 74 % [859/1152]\n",
      "Accacy on eval_loader set: 43 % [63/144]\n",
      "[76,   20] loss: 0.01825, running_loss: 11.682\n",
      "Accacy on train_loader set: 78 % [904/1152]\n",
      "Accacy on eval_loader set: 47 % [69/144]\n",
      "[77,   20] loss: 0.02094, running_loss: 13.403\n",
      "Accacy on train_loader set: 73 % [843/1152]\n",
      "Accacy on eval_loader set: 48 % [70/144]\n",
      "[78,   20] loss: 0.02000, running_loss: 12.798\n",
      "Accacy on train_loader set: 75 % [870/1152]\n",
      "Accacy on eval_loader set: 50 % [72/144]\n",
      "[79,   20] loss: 0.02109, running_loss: 13.496\n",
      "Accacy on train_loader set: 76 % [884/1152]\n",
      "Accacy on eval_loader set: 51 % [74/144]\n",
      "[80,   20] loss: 0.01937, running_loss: 12.395\n",
      "Accacy on train_loader set: 76 % [879/1152]\n",
      "Accacy on eval_loader set: 53 % [77/144]\n",
      "[81,   20] loss: 0.02206, running_loss: 14.121\n",
      "Accacy on train_loader set: 75 % [868/1152]\n",
      "Accacy on eval_loader set: 56 % [82/144]\n",
      "[82,   20] loss: 0.01945, running_loss: 12.448\n",
      "Accacy on train_loader set: 76 % [881/1152]\n",
      "Accacy on eval_loader set: 47 % [68/144]\n",
      "[83,   20] loss: 0.02154, running_loss: 13.788\n",
      "Accacy on train_loader set: 76 % [880/1152]\n",
      "Accacy on eval_loader set: 50 % [73/144]\n",
      "[84,   20] loss: 0.02197, running_loss: 14.058\n",
      "Accacy on train_loader set: 74 % [862/1152]\n",
      "Accacy on eval_loader set: 48 % [70/144]\n",
      "[85,   20] loss: 0.01976, running_loss: 12.645\n",
      "Accacy on train_loader set: 76 % [879/1152]\n",
      "Accacy on eval_loader set: 44 % [64/144]\n",
      "[86,   20] loss: 0.01886, running_loss: 12.070\n",
      "Accacy on train_loader set: 78 % [902/1152]\n",
      "Accacy on eval_loader set: 47 % [69/144]\n",
      "[87,   20] loss: 0.01872, running_loss: 11.980\n",
      "Accacy on train_loader set: 78 % [907/1152]\n",
      "Accacy on eval_loader set: 39 % [57/144]\n",
      "[88,   20] loss: 0.01819, running_loss: 11.644\n",
      "Accacy on train_loader set: 77 % [896/1152]\n",
      "Accacy on eval_loader set: 49 % [71/144]\n",
      "[89,   20] loss: 0.01815, running_loss: 11.615\n",
      "Accacy on train_loader set: 77 % [898/1152]\n",
      "Accacy on eval_loader set: 49 % [71/144]\n",
      "[90,   20] loss: 0.01771, running_loss: 11.334\n",
      "Accacy on train_loader set: 79 % [916/1152]\n",
      "Accacy on eval_loader set: 40 % [59/144]\n",
      "[91,   20] loss: 0.01835, running_loss: 11.743\n",
      "Accacy on train_loader set: 77 % [897/1152]\n",
      "Accacy on eval_loader set: 55 % [80/144]\n",
      "[92,   20] loss: 0.01661, running_loss: 10.631\n",
      "Accacy on train_loader set: 80 % [925/1152]\n",
      "Accacy on eval_loader set: 52 % [76/144]\n",
      "[93,   20] loss: 0.01914, running_loss: 12.250\n",
      "Accacy on train_loader set: 77 % [897/1152]\n",
      "Accacy on eval_loader set: 45 % [66/144]\n",
      "[94,   20] loss: 0.01771, running_loss: 11.333\n",
      "Accacy on train_loader set: 78 % [899/1152]\n",
      "Accacy on eval_loader set: 54 % [79/144]\n",
      "[95,   20] loss: 0.01756, running_loss: 11.236\n",
      "Accacy on train_loader set: 79 % [918/1152]\n",
      "Accacy on eval_loader set: 47 % [69/144]\n",
      "[96,   20] loss: 0.01728, running_loss: 11.057\n",
      "Accacy on train_loader set: 80 % [923/1152]\n",
      "Accacy on eval_loader set: 45 % [66/144]\n",
      "[97,   20] loss: 0.01862, running_loss: 11.916\n",
      "Accacy on train_loader set: 79 % [919/1152]\n",
      "Accacy on eval_loader set: 52 % [76/144]\n",
      "[98,   20] loss: 0.01788, running_loss: 11.442\n",
      "Accacy on train_loader set: 80 % [929/1152]\n",
      "Accacy on eval_loader set: 46 % [67/144]\n",
      "[99,   20] loss: 0.01688, running_loss: 10.804\n",
      "Accacy on train_loader set: 80 % [922/1152]\n",
      "Accacy on eval_loader set: 46 % [67/144]\n",
      "[100,   20] loss: 0.01696, running_loss: 10.856\n",
      "Accacy on train_loader set: 79 % [914/1152]\n",
      "Accacy on eval_loader set: 47 % [69/144]\n",
      "[101,   20] loss: 0.01691, running_loss: 10.821\n",
      "Accacy on train_loader set: 80 % [932/1152]\n",
      "Accacy on eval_loader set: 45 % [65/144]\n",
      "[102,   20] loss: 0.01578, running_loss: 10.099\n",
      "Accacy on train_loader set: 80 % [933/1152]\n",
      "Accacy on eval_loader set: 43 % [62/144]\n",
      "[103,   20] loss: 0.01674, running_loss: 10.711\n",
      "Accacy on train_loader set: 78 % [910/1152]\n",
      "Accacy on eval_loader set: 52 % [75/144]\n",
      "[104,   20] loss: 0.01778, running_loss: 11.379\n",
      "Accacy on train_loader set: 80 % [923/1152]\n",
      "Accacy on eval_loader set: 46 % [67/144]\n",
      "[105,   20] loss: 0.01719, running_loss: 11.004\n",
      "Accacy on train_loader set: 80 % [929/1152]\n",
      "Accacy on eval_loader set: 38 % [55/144]\n",
      "[106,   20] loss: 0.01547, running_loss: 9.903\n",
      "Accacy on train_loader set: 81 % [935/1152]\n",
      "Accacy on eval_loader set: 47 % [68/144]\n",
      "[107,   20] loss: 0.01489, running_loss: 9.532\n",
      "Accacy on train_loader set: 82 % [955/1152]\n",
      "Accacy on eval_loader set: 49 % [71/144]\n",
      "[108,   20] loss: 0.01553, running_loss: 9.939\n",
      "Accacy on train_loader set: 81 % [935/1152]\n",
      "Accacy on eval_loader set: 45 % [66/144]\n",
      "[109,   20] loss: 0.01503, running_loss: 9.618\n",
      "Accacy on train_loader set: 82 % [953/1152]\n",
      "Accacy on eval_loader set: 42 % [61/144]\n",
      "[110,   20] loss: 0.01450, running_loss: 9.282\n",
      "Accacy on train_loader set: 82 % [946/1152]\n",
      "Accacy on eval_loader set: 55 % [80/144]\n",
      "[111,   20] loss: 0.01493, running_loss: 9.553\n",
      "Accacy on train_loader set: 81 % [937/1152]\n",
      "Accacy on eval_loader set: 54 % [78/144]\n",
      "[112,   20] loss: 0.01685, running_loss: 10.785\n",
      "Accacy on train_loader set: 81 % [935/1152]\n",
      "Accacy on eval_loader set: 49 % [71/144]\n",
      "[113,   20] loss: 0.01638, running_loss: 10.485\n",
      "Accacy on train_loader set: 80 % [929/1152]\n",
      "Accacy on eval_loader set: 50 % [73/144]\n",
      "[114,   20] loss: 0.01576, running_loss: 10.087\n",
      "Accacy on train_loader set: 82 % [946/1152]\n",
      "Accacy on eval_loader set: 48 % [70/144]\n",
      "[115,   20] loss: 0.01571, running_loss: 10.055\n",
      "Accacy on train_loader set: 83 % [957/1152]\n",
      "Accacy on eval_loader set: 40 % [59/144]\n",
      "[116,   20] loss: 0.01644, running_loss: 10.524\n",
      "Accacy on train_loader set: 81 % [935/1152]\n",
      "Accacy on eval_loader set: 52 % [76/144]\n",
      "[117,   20] loss: 0.01507, running_loss: 9.643\n",
      "Accacy on train_loader set: 81 % [940/1152]\n",
      "Accacy on eval_loader set: 52 % [76/144]\n",
      "[118,   20] loss: 0.01470, running_loss: 9.408\n",
      "Accacy on train_loader set: 85 % [981/1152]\n",
      "Accacy on eval_loader set: 52 % [76/144]\n",
      "[119,   20] loss: 0.01533, running_loss: 9.814\n",
      "Accacy on train_loader set: 81 % [938/1152]\n",
      "Accacy on eval_loader set: 47 % [69/144]\n",
      "[120,   20] loss: 0.01511, running_loss: 9.673\n",
      "Accacy on train_loader set: 81 % [944/1152]\n",
      "Accacy on eval_loader set: 50 % [73/144]\n",
      "[121,   20] loss: 0.01458, running_loss: 9.330\n",
      "Accacy on train_loader set: 83 % [967/1152]\n",
      "Accacy on eval_loader set: 56 % [81/144]\n",
      "[122,   20] loss: 0.01392, running_loss: 8.910\n",
      "Accacy on train_loader set: 83 % [960/1152]\n",
      "Accacy on eval_loader set: 56 % [82/144]\n",
      "[123,   20] loss: 0.01353, running_loss: 8.662\n",
      "Accacy on train_loader set: 85 % [987/1152]\n",
      "Accacy on eval_loader set: 53 % [77/144]\n",
      "[124,   20] loss: 0.01489, running_loss: 9.531\n",
      "Accacy on train_loader set: 83 % [963/1152]\n",
      "Accacy on eval_loader set: 59 % [85/144]\n",
      "[125,   20] loss: 0.01481, running_loss: 9.478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 82 % [955/1152]\n",
      "Accacy on eval_loader set: 49 % [71/144]\n",
      "[126,   20] loss: 0.01389, running_loss: 8.890\n",
      "Accacy on train_loader set: 84 % [969/1152]\n",
      "Accacy on eval_loader set: 52 % [75/144]\n",
      "[127,   20] loss: 0.01493, running_loss: 9.553\n",
      "Accacy on train_loader set: 83 % [957/1152]\n",
      "Accacy on eval_loader set: 51 % [74/144]\n",
      "[128,   20] loss: 0.01448, running_loss: 9.269\n",
      "Accacy on train_loader set: 83 % [959/1152]\n",
      "Accacy on eval_loader set: 51 % [74/144]\n",
      "[129,   20] loss: 0.01446, running_loss: 9.256\n",
      "Accacy on train_loader set: 84 % [970/1152]\n",
      "Accacy on eval_loader set: 54 % [79/144]\n",
      "[130,   20] loss: 0.01348, running_loss: 8.628\n",
      "Accacy on train_loader set: 83 % [957/1152]\n",
      "Accacy on eval_loader set: 52 % [75/144]\n",
      "[131,   20] loss: 0.01326, running_loss: 8.487\n",
      "Accacy on train_loader set: 84 % [975/1152]\n",
      "Accacy on eval_loader set: 47 % [69/144]\n",
      "[132,   20] loss: 0.01231, running_loss: 7.882\n",
      "Accacy on train_loader set: 83 % [966/1152]\n",
      "Accacy on eval_loader set: 47 % [68/144]\n",
      "[133,   20] loss: 0.01350, running_loss: 8.638\n",
      "Accacy on train_loader set: 83 % [964/1152]\n",
      "Accacy on eval_loader set: 54 % [79/144]\n",
      "[134,   20] loss: 0.01342, running_loss: 8.589\n",
      "Accacy on train_loader set: 84 % [971/1152]\n",
      "Accacy on eval_loader set: 54 % [79/144]\n",
      "[135,   20] loss: 0.01354, running_loss: 8.666\n",
      "Accacy on train_loader set: 84 % [973/1152]\n",
      "Accacy on eval_loader set: 51 % [74/144]\n",
      "[136,   20] loss: 0.01198, running_loss: 7.670\n",
      "Accacy on train_loader set: 85 % [985/1152]\n",
      "Accacy on eval_loader set: 50 % [73/144]\n",
      "[137,   20] loss: 0.01268, running_loss: 8.117\n",
      "Accacy on train_loader set: 84 % [975/1152]\n",
      "Accacy on eval_loader set: 44 % [64/144]\n",
      "[138,   20] loss: 0.01346, running_loss: 8.617\n",
      "Accacy on train_loader set: 84 % [975/1152]\n",
      "Accacy on eval_loader set: 56 % [81/144]\n",
      "[139,   20] loss: 0.01326, running_loss: 8.484\n",
      "Accacy on train_loader set: 84 % [979/1152]\n",
      "Accacy on eval_loader set: 60 % [87/144]\n",
      "[140,   20] loss: 0.01295, running_loss: 8.289\n",
      "Accacy on train_loader set: 85 % [988/1152]\n",
      "Accacy on eval_loader set: 59 % [85/144]\n",
      "[141,   20] loss: 0.01194, running_loss: 7.644\n",
      "Accacy on train_loader set: 88 % [1017/1152]\n",
      "Accacy on eval_loader set: 50 % [73/144]\n",
      "[142,   20] loss: 0.01322, running_loss: 8.461\n",
      "Accacy on train_loader set: 84 % [972/1152]\n",
      "Accacy on eval_loader set: 46 % [67/144]\n",
      "[143,   20] loss: 0.01329, running_loss: 8.503\n",
      "Accacy on train_loader set: 85 % [987/1152]\n",
      "Accacy on eval_loader set: 54 % [78/144]\n",
      "[144,   20] loss: 0.01108, running_loss: 7.094\n",
      "Accacy on train_loader set: 87 % [1004/1152]\n",
      "Accacy on eval_loader set: 54 % [79/144]\n",
      "[145,   20] loss: 0.01248, running_loss: 7.984\n",
      "Accacy on train_loader set: 84 % [979/1152]\n",
      "Accacy on eval_loader set: 54 % [78/144]\n",
      "[146,   20] loss: 0.01176, running_loss: 7.527\n",
      "Accacy on train_loader set: 86 % [991/1152]\n",
      "Accacy on eval_loader set: 61 % [88/144]\n",
      "[147,   20] loss: 0.01196, running_loss: 7.655\n",
      "Accacy on train_loader set: 85 % [984/1152]\n",
      "Accacy on eval_loader set: 55 % [80/144]\n",
      "[148,   20] loss: 0.01213, running_loss: 7.763\n",
      "Accacy on train_loader set: 84 % [978/1152]\n",
      "Accacy on eval_loader set: 54 % [78/144]\n",
      "[149,   20] loss: 0.01260, running_loss: 8.063\n",
      "Accacy on train_loader set: 85 % [981/1152]\n",
      "Accacy on eval_loader set: 47 % [68/144]\n",
      "[150,   20] loss: 0.01104, running_loss: 7.065\n",
      "Accacy on train_loader set: 87 % [1010/1152]\n",
      "Accacy on eval_loader set: 53 % [77/144]\n",
      "[151,   20] loss: 0.01191, running_loss: 7.624\n",
      "Accacy on train_loader set: 86 % [993/1152]\n",
      "Accacy on eval_loader set: 56 % [82/144]\n",
      "[152,   20] loss: 0.01026, running_loss: 6.564\n",
      "Accacy on train_loader set: 88 % [1015/1152]\n",
      "Accacy on eval_loader set: 52 % [76/144]\n",
      "[153,   20] loss: 0.01079, running_loss: 6.905\n",
      "Accacy on train_loader set: 87 % [1009/1152]\n",
      "Accacy on eval_loader set: 54 % [79/144]\n",
      "[154,   20] loss: 0.01059, running_loss: 6.776\n",
      "Accacy on train_loader set: 87 % [1007/1152]\n",
      "Accacy on eval_loader set: 54 % [79/144]\n",
      "[155,   20] loss: 0.01138, running_loss: 7.282\n",
      "Accacy on train_loader set: 86 % [997/1152]\n",
      "Accacy on eval_loader set: 47 % [69/144]\n",
      "[156,   20] loss: 0.01229, running_loss: 7.864\n",
      "Accacy on train_loader set: 86 % [998/1152]\n",
      "Accacy on eval_loader set: 54 % [79/144]\n",
      "[157,   20] loss: 0.01080, running_loss: 6.915\n",
      "Accacy on train_loader set: 86 % [996/1152]\n",
      "Accacy on eval_loader set: 50 % [73/144]\n",
      "[158,   20] loss: 0.01113, running_loss: 7.124\n",
      "Accacy on train_loader set: 86 % [992/1152]\n",
      "Accacy on eval_loader set: 51 % [74/144]\n",
      "[159,   20] loss: 0.01133, running_loss: 7.251\n",
      "Accacy on train_loader set: 86 % [995/1152]\n",
      "Accacy on eval_loader set: 61 % [88/144]\n",
      "[160,   20] loss: 0.01117, running_loss: 7.147\n",
      "Accacy on train_loader set: 88 % [1019/1152]\n",
      "Accacy on eval_loader set: 55 % [80/144]\n",
      "[161,   20] loss: 0.01151, running_loss: 7.366\n",
      "Accacy on train_loader set: 87 % [1004/1152]\n",
      "Accacy on eval_loader set: 53 % [77/144]\n",
      "[162,   20] loss: 0.01080, running_loss: 6.913\n",
      "Accacy on train_loader set: 88 % [1025/1152]\n",
      "Accacy on eval_loader set: 56 % [81/144]\n",
      "[163,   20] loss: 0.01051, running_loss: 6.724\n",
      "Accacy on train_loader set: 87 % [1004/1152]\n",
      "Accacy on eval_loader set: 59 % [85/144]\n",
      "[164,   20] loss: 0.01065, running_loss: 6.816\n",
      "Accacy on train_loader set: 88 % [1015/1152]\n",
      "Accacy on eval_loader set: 50 % [73/144]\n",
      "[165,   20] loss: 0.01041, running_loss: 6.665\n",
      "Accacy on train_loader set: 87 % [1009/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[166,   20] loss: 0.01056, running_loss: 6.756\n",
      "Accacy on train_loader set: 87 % [1011/1152]\n",
      "Accacy on eval_loader set: 50 % [72/144]\n",
      "[167,   20] loss: 0.01105, running_loss: 7.072\n",
      "Accacy on train_loader set: 88 % [1019/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[168,   20] loss: 0.01154, running_loss: 7.387\n",
      "Accacy on train_loader set: 87 % [1008/1152]\n",
      "Accacy on eval_loader set: 58 % [84/144]\n",
      "[169,   20] loss: 0.01091, running_loss: 6.982\n",
      "Accacy on train_loader set: 86 % [996/1152]\n",
      "Accacy on eval_loader set: 53 % [77/144]\n",
      "[170,   20] loss: 0.00984, running_loss: 6.296\n",
      "Accacy on train_loader set: 88 % [1024/1152]\n",
      "Accacy on eval_loader set: 59 % [85/144]\n",
      "[171,   20] loss: 0.01094, running_loss: 7.002\n",
      "Accacy on train_loader set: 87 % [1013/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[172,   20] loss: 0.01113, running_loss: 7.125\n",
      "Accacy on train_loader set: 87 % [1007/1152]\n",
      "Accacy on eval_loader set: 58 % [84/144]\n",
      "[173,   20] loss: 0.01065, running_loss: 6.816\n",
      "Accacy on train_loader set: 88 % [1020/1152]\n",
      "Accacy on eval_loader set: 49 % [71/144]\n",
      "[174,   20] loss: 0.01200, running_loss: 7.677\n",
      "Accacy on train_loader set: 86 % [997/1152]\n",
      "Accacy on eval_loader set: 52 % [75/144]\n",
      "[175,   20] loss: 0.00902, running_loss: 5.770\n",
      "Accacy on train_loader set: 88 % [1023/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[176,   20] loss: 0.00890, running_loss: 5.699\n",
      "Accacy on train_loader set: 89 % [1034/1152]\n",
      "Accacy on eval_loader set: 59 % [86/144]\n",
      "[177,   20] loss: 0.00962, running_loss: 6.155\n",
      "Accacy on train_loader set: 87 % [1010/1152]\n",
      "Accacy on eval_loader set: 59 % [86/144]\n",
      "[178,   20] loss: 0.01011, running_loss: 6.470\n",
      "Accacy on train_loader set: 88 % [1016/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[179,   20] loss: 0.01044, running_loss: 6.684\n",
      "Accacy on train_loader set: 88 % [1019/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[180,   20] loss: 0.01151, running_loss: 7.366\n",
      "Accacy on train_loader set: 87 % [1008/1152]\n",
      "Accacy on eval_loader set: 52 % [76/144]\n",
      "[181,   20] loss: 0.00937, running_loss: 5.998\n",
      "Accacy on train_loader set: 88 % [1022/1152]\n",
      "Accacy on eval_loader set: 54 % [79/144]\n",
      "[182,   20] loss: 0.00966, running_loss: 6.182\n",
      "Accacy on train_loader set: 89 % [1028/1152]\n",
      "Accacy on eval_loader set: 50 % [72/144]\n",
      "[183,   20] loss: 0.01070, running_loss: 6.849\n",
      "Accacy on train_loader set: 88 % [1016/1152]\n",
      "Accacy on eval_loader set: 56 % [82/144]\n",
      "[184,   20] loss: 0.00885, running_loss: 5.661\n",
      "Accacy on train_loader set: 89 % [1035/1152]\n",
      "Accacy on eval_loader set: 53 % [77/144]\n",
      "[185,   20] loss: 0.00909, running_loss: 5.816\n",
      "Accacy on train_loader set: 88 % [1023/1152]\n",
      "Accacy on eval_loader set: 51 % [74/144]\n",
      "[186,   20] loss: 0.00915, running_loss: 5.855\n",
      "Accacy on train_loader set: 89 % [1035/1152]\n",
      "Accacy on eval_loader set: 57 % [83/144]\n",
      "[187,   20] loss: 0.01005, running_loss: 6.433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 87 % [1013/1152]\n",
      "Accacy on eval_loader set: 54 % [79/144]\n",
      "[188,   20] loss: 0.00972, running_loss: 6.223\n",
      "Accacy on train_loader set: 87 % [1010/1152]\n",
      "Accacy on eval_loader set: 50 % [73/144]\n",
      "[189,   20] loss: 0.00913, running_loss: 5.844\n",
      "Accacy on train_loader set: 89 % [1032/1152]\n",
      "Accacy on eval_loader set: 55 % [80/144]\n",
      "[190,   20] loss: 0.00923, running_loss: 5.908\n",
      "Accacy on train_loader set: 88 % [1023/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[191,   20] loss: 0.00862, running_loss: 5.519\n",
      "Accacy on train_loader set: 90 % [1045/1152]\n",
      "Accacy on eval_loader set: 57 % [83/144]\n",
      "[192,   20] loss: 0.00935, running_loss: 5.982\n",
      "Accacy on train_loader set: 89 % [1033/1152]\n",
      "Accacy on eval_loader set: 47 % [69/144]\n",
      "[193,   20] loss: 0.00747, running_loss: 4.783\n",
      "Accacy on train_loader set: 90 % [1048/1152]\n",
      "Accacy on eval_loader set: 60 % [87/144]\n",
      "[194,   20] loss: 0.00841, running_loss: 5.381\n",
      "Accacy on train_loader set: 90 % [1037/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[195,   20] loss: 0.00881, running_loss: 5.641\n",
      "Accacy on train_loader set: 90 % [1041/1152]\n",
      "Accacy on eval_loader set: 58 % [84/144]\n",
      "[196,   20] loss: 0.00993, running_loss: 6.353\n",
      "Accacy on train_loader set: 89 % [1026/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[197,   20] loss: 0.00808, running_loss: 5.171\n",
      "Accacy on train_loader set: 90 % [1043/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[198,   20] loss: 0.00889, running_loss: 5.692\n",
      "Accacy on train_loader set: 89 % [1027/1152]\n",
      "Accacy on eval_loader set: 56 % [81/144]\n",
      "[199,   20] loss: 0.00915, running_loss: 5.853\n",
      "Accacy on train_loader set: 89 % [1034/1152]\n",
      "Accacy on eval_loader set: 57 % [83/144]\n",
      "[200,   20] loss: 0.00929, running_loss: 5.947\n",
      "Accacy on train_loader set: 90 % [1037/1152]\n",
      "Accacy on eval_loader set: 56 % [81/144]\n",
      "[201,   20] loss: 0.00809, running_loss: 5.178\n",
      "Accacy on train_loader set: 89 % [1032/1152]\n",
      "Accacy on eval_loader set: 56 % [81/144]\n",
      "[202,   20] loss: 0.00906, running_loss: 5.799\n",
      "Accacy on train_loader set: 91 % [1052/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[203,   20] loss: 0.00834, running_loss: 5.339\n",
      "Accacy on train_loader set: 91 % [1050/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[204,   20] loss: 0.00788, running_loss: 5.041\n",
      "Accacy on train_loader set: 91 % [1050/1152]\n",
      "Accacy on eval_loader set: 57 % [83/144]\n",
      "[205,   20] loss: 0.00828, running_loss: 5.301\n",
      "Accacy on train_loader set: 89 % [1031/1152]\n",
      "Accacy on eval_loader set: 54 % [79/144]\n",
      "[206,   20] loss: 0.00884, running_loss: 5.658\n",
      "Accacy on train_loader set: 90 % [1039/1152]\n",
      "Accacy on eval_loader set: 52 % [75/144]\n",
      "[207,   20] loss: 0.00866, running_loss: 5.543\n",
      "Accacy on train_loader set: 91 % [1055/1152]\n",
      "Accacy on eval_loader set: 50 % [72/144]\n",
      "[208,   20] loss: 0.00779, running_loss: 4.987\n",
      "Accacy on train_loader set: 90 % [1047/1152]\n",
      "Accacy on eval_loader set: 58 % [84/144]\n",
      "[209,   20] loss: 0.00801, running_loss: 5.124\n",
      "Accacy on train_loader set: 90 % [1047/1152]\n",
      "Accacy on eval_loader set: 59 % [85/144]\n",
      "[210,   20] loss: 0.00823, running_loss: 5.266\n",
      "Accacy on train_loader set: 91 % [1053/1152]\n",
      "Accacy on eval_loader set: 52 % [75/144]\n",
      "[211,   20] loss: 0.00902, running_loss: 5.770\n",
      "Accacy on train_loader set: 90 % [1039/1152]\n",
      "Accacy on eval_loader set: 60 % [87/144]\n",
      "[212,   20] loss: 0.00725, running_loss: 4.638\n",
      "Accacy on train_loader set: 92 % [1063/1152]\n",
      "Accacy on eval_loader set: 54 % [79/144]\n",
      "[213,   20] loss: 0.00746, running_loss: 4.777\n",
      "Accacy on train_loader set: 91 % [1056/1152]\n",
      "Accacy on eval_loader set: 56 % [81/144]\n",
      "[214,   20] loss: 0.00879, running_loss: 5.623\n",
      "Accacy on train_loader set: 90 % [1045/1152]\n",
      "Accacy on eval_loader set: 59 % [86/144]\n",
      "[215,   20] loss: 0.00832, running_loss: 5.322\n",
      "Accacy on train_loader set: 91 % [1053/1152]\n",
      "Accacy on eval_loader set: 60 % [87/144]\n",
      "[216,   20] loss: 0.00938, running_loss: 6.005\n",
      "Accacy on train_loader set: 91 % [1051/1152]\n",
      "Accacy on eval_loader set: 52 % [76/144]\n",
      "[217,   20] loss: 0.00710, running_loss: 4.543\n",
      "Accacy on train_loader set: 92 % [1064/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[218,   20] loss: 0.00756, running_loss: 4.836\n",
      "Accacy on train_loader set: 92 % [1070/1152]\n",
      "Accacy on eval_loader set: 56 % [82/144]\n",
      "[219,   20] loss: 0.00795, running_loss: 5.090\n",
      "Accacy on train_loader set: 92 % [1068/1152]\n",
      "Accacy on eval_loader set: 60 % [87/144]\n",
      "[220,   20] loss: 0.00769, running_loss: 4.919\n",
      "Accacy on train_loader set: 91 % [1051/1152]\n",
      "Accacy on eval_loader set: 49 % [71/144]\n",
      "[221,   20] loss: 0.00761, running_loss: 4.872\n",
      "Accacy on train_loader set: 91 % [1056/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[222,   20] loss: 0.00762, running_loss: 4.878\n",
      "Accacy on train_loader set: 91 % [1054/1152]\n",
      "Accacy on eval_loader set: 60 % [87/144]\n",
      "[223,   20] loss: 0.00774, running_loss: 4.955\n",
      "Accacy on train_loader set: 90 % [1042/1152]\n",
      "Accacy on eval_loader set: 43 % [63/144]\n",
      "[224,   20] loss: 0.00853, running_loss: 5.461\n",
      "Accacy on train_loader set: 88 % [1024/1152]\n",
      "Accacy on eval_loader set: 58 % [84/144]\n",
      "[225,   20] loss: 0.00789, running_loss: 5.048\n",
      "Accacy on train_loader set: 91 % [1052/1152]\n",
      "Accacy on eval_loader set: 59 % [86/144]\n",
      "[226,   20] loss: 0.00663, running_loss: 4.243\n",
      "Accacy on train_loader set: 91 % [1056/1152]\n",
      "Accacy on eval_loader set: 49 % [71/144]\n",
      "[227,   20] loss: 0.00721, running_loss: 4.613\n",
      "Accacy on train_loader set: 91 % [1057/1152]\n",
      "Accacy on eval_loader set: 59 % [85/144]\n",
      "[228,   20] loss: 0.00759, running_loss: 4.858\n",
      "Accacy on train_loader set: 91 % [1057/1152]\n",
      "Accacy on eval_loader set: 56 % [82/144]\n",
      "[229,   20] loss: 0.00876, running_loss: 5.609\n",
      "Accacy on train_loader set: 90 % [1048/1152]\n",
      "Accacy on eval_loader set: 60 % [87/144]\n",
      "[230,   20] loss: 0.00702, running_loss: 4.490\n",
      "Accacy on train_loader set: 93 % [1073/1152]\n",
      "Accacy on eval_loader set: 53 % [77/144]\n",
      "[231,   20] loss: 0.00820, running_loss: 5.250\n",
      "Accacy on train_loader set: 90 % [1045/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[232,   20] loss: 0.00740, running_loss: 4.735\n",
      "Accacy on train_loader set: 90 % [1044/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[233,   20] loss: 0.00785, running_loss: 5.026\n",
      "Accacy on train_loader set: 91 % [1057/1152]\n",
      "Accacy on eval_loader set: 59 % [86/144]\n",
      "[234,   20] loss: 0.00737, running_loss: 4.716\n",
      "Accacy on train_loader set: 91 % [1058/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[235,   20] loss: 0.00704, running_loss: 4.504\n",
      "Accacy on train_loader set: 92 % [1070/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[236,   20] loss: 0.00678, running_loss: 4.339\n",
      "Accacy on train_loader set: 91 % [1056/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[237,   20] loss: 0.00645, running_loss: 4.130\n",
      "Accacy on train_loader set: 91 % [1059/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[238,   20] loss: 0.00780, running_loss: 4.995\n",
      "Accacy on train_loader set: 92 % [1065/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[239,   20] loss: 0.00608, running_loss: 3.890\n",
      "Accacy on train_loader set: 93 % [1080/1152]\n",
      "Accacy on eval_loader set: 58 % [84/144]\n",
      "[240,   20] loss: 0.00774, running_loss: 4.951\n",
      "Accacy on train_loader set: 91 % [1051/1152]\n",
      "Accacy on eval_loader set: 59 % [86/144]\n",
      "[241,   20] loss: 0.00756, running_loss: 4.836\n",
      "Accacy on train_loader set: 92 % [1069/1152]\n",
      "Accacy on eval_loader set: 57 % [83/144]\n",
      "[242,   20] loss: 0.00717, running_loss: 4.590\n",
      "Accacy on train_loader set: 93 % [1074/1152]\n",
      "Accacy on eval_loader set: 59 % [86/144]\n",
      "[243,   20] loss: 0.00649, running_loss: 4.153\n",
      "Accacy on train_loader set: 93 % [1077/1152]\n",
      "Accacy on eval_loader set: 59 % [86/144]\n",
      "[244,   20] loss: 0.00721, running_loss: 4.616\n",
      "Accacy on train_loader set: 93 % [1077/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[245,   20] loss: 0.00805, running_loss: 5.152\n",
      "Accacy on train_loader set: 91 % [1057/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[246,   20] loss: 0.00594, running_loss: 3.803\n",
      "Accacy on train_loader set: 93 % [1077/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[247,   20] loss: 0.00603, running_loss: 3.856\n",
      "Accacy on train_loader set: 92 % [1067/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[248,   20] loss: 0.00551, running_loss: 3.525\n",
      "Accacy on train_loader set: 93 % [1075/1152]\n",
      "Accacy on eval_loader set: 54 % [78/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249,   20] loss: 0.00706, running_loss: 4.520\n",
      "Accacy on train_loader set: 92 % [1065/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[250,   20] loss: 0.00658, running_loss: 4.209\n",
      "Accacy on train_loader set: 91 % [1059/1152]\n",
      "Accacy on eval_loader set: 56 % [82/144]\n",
      "[251,   20] loss: 0.00571, running_loss: 3.656\n",
      "Accacy on train_loader set: 93 % [1080/1152]\n",
      "Accacy on eval_loader set: 60 % [87/144]\n",
      "[252,   20] loss: 0.00612, running_loss: 3.915\n",
      "Accacy on train_loader set: 94 % [1089/1152]\n",
      "Accacy on eval_loader set: 52 % [76/144]\n",
      "[253,   20] loss: 0.00691, running_loss: 4.425\n",
      "Accacy on train_loader set: 93 % [1073/1152]\n",
      "Accacy on eval_loader set: 59 % [86/144]\n",
      "[254,   20] loss: 0.00612, running_loss: 3.919\n",
      "Accacy on train_loader set: 92 % [1062/1152]\n",
      "Accacy on eval_loader set: 61 % [88/144]\n",
      "[255,   20] loss: 0.00539, running_loss: 3.451\n",
      "Accacy on train_loader set: 94 % [1085/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[256,   20] loss: 0.00607, running_loss: 3.886\n",
      "Accacy on train_loader set: 93 % [1080/1152]\n",
      "Accacy on eval_loader set: 56 % [82/144]\n",
      "[257,   20] loss: 0.00692, running_loss: 4.427\n",
      "Accacy on train_loader set: 93 % [1072/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[258,   20] loss: 0.00653, running_loss: 4.182\n",
      "Accacy on train_loader set: 92 % [1065/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[259,   20] loss: 0.00600, running_loss: 3.840\n",
      "Accacy on train_loader set: 92 % [1069/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[260,   20] loss: 0.00625, running_loss: 3.999\n",
      "Accacy on train_loader set: 92 % [1061/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[261,   20] loss: 0.00587, running_loss: 3.754\n",
      "Accacy on train_loader set: 91 % [1058/1152]\n",
      "Accacy on eval_loader set: 59 % [86/144]\n",
      "[262,   20] loss: 0.00687, running_loss: 4.394\n",
      "Accacy on train_loader set: 92 % [1071/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[263,   20] loss: 0.00597, running_loss: 3.818\n",
      "Accacy on train_loader set: 92 % [1070/1152]\n",
      "Accacy on eval_loader set: 53 % [77/144]\n",
      "[264,   20] loss: 0.00661, running_loss: 4.228\n",
      "Accacy on train_loader set: 92 % [1066/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[265,   20] loss: 0.00616, running_loss: 3.942\n",
      "Accacy on train_loader set: 93 % [1073/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[266,   20] loss: 0.00620, running_loss: 3.966\n",
      "Accacy on train_loader set: 93 % [1081/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[267,   20] loss: 0.00615, running_loss: 3.938\n",
      "Accacy on train_loader set: 92 % [1068/1152]\n",
      "Accacy on eval_loader set: 59 % [85/144]\n",
      "[268,   20] loss: 0.00652, running_loss: 4.170\n",
      "Accacy on train_loader set: 93 % [1074/1152]\n",
      "Accacy on eval_loader set: 56 % [82/144]\n",
      "[269,   20] loss: 0.00667, running_loss: 4.272\n",
      "Accacy on train_loader set: 92 % [1064/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[270,   20] loss: 0.00585, running_loss: 3.744\n",
      "Accacy on train_loader set: 94 % [1083/1152]\n",
      "Accacy on eval_loader set: 54 % [78/144]\n",
      "[271,   20] loss: 0.00704, running_loss: 4.504\n",
      "Accacy on train_loader set: 93 % [1079/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[272,   20] loss: 0.00606, running_loss: 3.879\n",
      "Accacy on train_loader set: 92 % [1067/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[273,   20] loss: 0.00506, running_loss: 3.240\n",
      "Accacy on train_loader set: 95 % [1101/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[274,   20] loss: 0.00648, running_loss: 4.150\n",
      "Accacy on train_loader set: 92 % [1071/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[275,   20] loss: 0.00487, running_loss: 3.117\n",
      "Accacy on train_loader set: 94 % [1087/1152]\n",
      "Accacy on eval_loader set: 54 % [79/144]\n",
      "[276,   20] loss: 0.00621, running_loss: 3.973\n",
      "Accacy on train_loader set: 94 % [1083/1152]\n",
      "Accacy on eval_loader set: 58 % [84/144]\n",
      "[277,   20] loss: 0.00549, running_loss: 3.514\n",
      "Accacy on train_loader set: 93 % [1082/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[278,   20] loss: 0.00714, running_loss: 4.567\n",
      "Accacy on train_loader set: 92 % [1065/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[279,   20] loss: 0.00676, running_loss: 4.324\n",
      "Accacy on train_loader set: 93 % [1078/1152]\n",
      "Accacy on eval_loader set: 56 % [82/144]\n",
      "[280,   20] loss: 0.00609, running_loss: 3.899\n",
      "Accacy on train_loader set: 92 % [1068/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[281,   20] loss: 0.00585, running_loss: 3.746\n",
      "Accacy on train_loader set: 94 % [1083/1152]\n",
      "Accacy on eval_loader set: 57 % [83/144]\n",
      "[282,   20] loss: 0.00680, running_loss: 4.351\n",
      "Accacy on train_loader set: 93 % [1077/1152]\n",
      "Accacy on eval_loader set: 61 % [88/144]\n",
      "[283,   20] loss: 0.00561, running_loss: 3.591\n",
      "Accacy on train_loader set: 93 % [1079/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[284,   20] loss: 0.00498, running_loss: 3.184\n",
      "Accacy on train_loader set: 94 % [1086/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[285,   20] loss: 0.00607, running_loss: 3.888\n",
      "Accacy on train_loader set: 93 % [1078/1152]\n",
      "Accacy on eval_loader set: 60 % [87/144]\n",
      "[286,   20] loss: 0.00538, running_loss: 3.442\n",
      "Accacy on train_loader set: 94 % [1084/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[287,   20] loss: 0.00560, running_loss: 3.585\n",
      "Accacy on train_loader set: 94 % [1087/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[288,   20] loss: 0.00619, running_loss: 3.965\n",
      "Accacy on train_loader set: 94 % [1084/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[289,   20] loss: 0.00592, running_loss: 3.787\n",
      "Accacy on train_loader set: 94 % [1090/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[290,   20] loss: 0.00579, running_loss: 3.705\n",
      "Accacy on train_loader set: 93 % [1081/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[291,   20] loss: 0.00624, running_loss: 3.997\n",
      "Accacy on train_loader set: 94 % [1083/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[292,   20] loss: 0.00650, running_loss: 4.159\n",
      "Accacy on train_loader set: 94 % [1086/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[293,   20] loss: 0.00720, running_loss: 4.611\n",
      "Accacy on train_loader set: 93 % [1076/1152]\n",
      "Accacy on eval_loader set: 61 % [88/144]\n",
      "[294,   20] loss: 0.00581, running_loss: 3.717\n",
      "Accacy on train_loader set: 94 % [1093/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[295,   20] loss: 0.00469, running_loss: 3.004\n",
      "Accacy on train_loader set: 94 % [1093/1152]\n",
      "Accacy on eval_loader set: 59 % [86/144]\n",
      "[296,   20] loss: 0.00522, running_loss: 3.342\n",
      "Accacy on train_loader set: 94 % [1094/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[297,   20] loss: 0.00606, running_loss: 3.878\n",
      "Accacy on train_loader set: 93 % [1081/1152]\n",
      "Accacy on eval_loader set: 60 % [87/144]\n",
      "[298,   20] loss: 0.00557, running_loss: 3.563\n",
      "Accacy on train_loader set: 94 % [1089/1152]\n",
      "Accacy on eval_loader set: 55 % [80/144]\n",
      "[299,   20] loss: 0.00605, running_loss: 3.869\n",
      "Accacy on train_loader set: 93 % [1072/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[300,   20] loss: 0.00544, running_loss: 3.482\n",
      "Accacy on train_loader set: 93 % [1080/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[301,   20] loss: 0.00514, running_loss: 3.288\n",
      "Accacy on train_loader set: 94 % [1090/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[302,   20] loss: 0.00536, running_loss: 3.429\n",
      "Accacy on train_loader set: 94 % [1086/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[303,   20] loss: 0.00518, running_loss: 3.315\n",
      "Accacy on train_loader set: 94 % [1088/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[304,   20] loss: 0.00585, running_loss: 3.743\n",
      "Accacy on train_loader set: 94 % [1087/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[305,   20] loss: 0.00622, running_loss: 3.984\n",
      "Accacy on train_loader set: 93 % [1079/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[306,   20] loss: 0.00543, running_loss: 3.473\n",
      "Accacy on train_loader set: 95 % [1096/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[307,   20] loss: 0.00533, running_loss: 3.411\n",
      "Accacy on train_loader set: 94 % [1088/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[308,   20] loss: 0.00526, running_loss: 3.365\n",
      "Accacy on train_loader set: 95 % [1097/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[309,   20] loss: 0.00489, running_loss: 3.130\n",
      "Accacy on train_loader set: 94 % [1090/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[310,   20] loss: 0.00525, running_loss: 3.359\n",
      "Accacy on train_loader set: 93 % [1082/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[311,   20] loss: 0.00641, running_loss: 4.102\n",
      "Accacy on train_loader set: 93 % [1079/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[312,   20] loss: 0.00486, running_loss: 3.111\n",
      "Accacy on train_loader set: 95 % [1097/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[313,   20] loss: 0.00557, running_loss: 3.565\n",
      "Accacy on train_loader set: 95 % [1097/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[314,   20] loss: 0.00549, running_loss: 3.516\n",
      "Accacy on train_loader set: 94 % [1091/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[315,   20] loss: 0.00613, running_loss: 3.921\n",
      "Accacy on train_loader set: 94 % [1084/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[316,   20] loss: 0.00411, running_loss: 2.627\n",
      "Accacy on train_loader set: 95 % [1099/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[317,   20] loss: 0.00471, running_loss: 3.016\n",
      "Accacy on train_loader set: 95 % [1097/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[318,   20] loss: 0.00503, running_loss: 3.220\n",
      "Accacy on train_loader set: 95 % [1104/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[319,   20] loss: 0.00532, running_loss: 3.407\n",
      "Accacy on train_loader set: 94 % [1089/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[320,   20] loss: 0.00454, running_loss: 2.903\n",
      "Accacy on train_loader set: 95 % [1097/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[321,   20] loss: 0.00537, running_loss: 3.436\n",
      "Accacy on train_loader set: 94 % [1087/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[322,   20] loss: 0.00499, running_loss: 3.190\n",
      "Accacy on train_loader set: 94 % [1092/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[323,   20] loss: 0.00525, running_loss: 3.358\n",
      "Accacy on train_loader set: 94 % [1089/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[324,   20] loss: 0.00431, running_loss: 2.761\n",
      "Accacy on train_loader set: 94 % [1092/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[325,   20] loss: 0.00470, running_loss: 3.007\n",
      "Accacy on train_loader set: 95 % [1097/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[326,   20] loss: 0.00425, running_loss: 2.719\n",
      "Accacy on train_loader set: 95 % [1104/1152]\n",
      "Accacy on eval_loader set: 60 % [87/144]\n",
      "[327,   20] loss: 0.00476, running_loss: 3.045\n",
      "Accacy on train_loader set: 95 % [1095/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[328,   20] loss: 0.00555, running_loss: 3.554\n",
      "Accacy on train_loader set: 94 % [1090/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[329,   20] loss: 0.00448, running_loss: 2.868\n",
      "Accacy on train_loader set: 95 % [1100/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[330,   20] loss: 0.00464, running_loss: 2.971\n",
      "Accacy on train_loader set: 93 % [1082/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[331,   20] loss: 0.00421, running_loss: 2.696\n",
      "Accacy on train_loader set: 94 % [1092/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[332,   20] loss: 0.00517, running_loss: 3.306\n",
      "Accacy on train_loader set: 94 % [1088/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[333,   20] loss: 0.00531, running_loss: 3.396\n",
      "Accacy on train_loader set: 94 % [1091/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[334,   20] loss: 0.00460, running_loss: 2.946\n",
      "Accacy on train_loader set: 95 % [1102/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[335,   20] loss: 0.00450, running_loss: 2.883\n",
      "Accacy on train_loader set: 95 % [1100/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[336,   20] loss: 0.00436, running_loss: 2.790\n",
      "Accacy on train_loader set: 95 % [1100/1152]\n",
      "Accacy on eval_loader set: 60 % [87/144]\n",
      "[337,   20] loss: 0.00493, running_loss: 3.152\n",
      "Accacy on train_loader set: 94 % [1086/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[338,   20] loss: 0.00480, running_loss: 3.070\n",
      "Accacy on train_loader set: 95 % [1099/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[339,   20] loss: 0.00368, running_loss: 2.357\n",
      "Accacy on train_loader set: 96 % [1114/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[340,   20] loss: 0.00479, running_loss: 3.063\n",
      "Accacy on train_loader set: 95 % [1099/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[341,   20] loss: 0.00416, running_loss: 2.664\n",
      "Accacy on train_loader set: 95 % [1098/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[342,   20] loss: 0.00437, running_loss: 2.794\n",
      "Accacy on train_loader set: 96 % [1108/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[343,   20] loss: 0.00414, running_loss: 2.647\n",
      "Accacy on train_loader set: 95 % [1101/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[344,   20] loss: 0.00470, running_loss: 3.011\n",
      "Accacy on train_loader set: 95 % [1096/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[345,   20] loss: 0.00400, running_loss: 2.562\n",
      "Accacy on train_loader set: 95 % [1098/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[346,   20] loss: 0.00517, running_loss: 3.307\n",
      "Accacy on train_loader set: 94 % [1092/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[347,   20] loss: 0.00385, running_loss: 2.464\n",
      "Accacy on train_loader set: 96 % [1109/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[348,   20] loss: 0.00451, running_loss: 2.884\n",
      "Accacy on train_loader set: 93 % [1081/1152]\n",
      "Accacy on eval_loader set: 61 % [88/144]\n",
      "[349,   20] loss: 0.00453, running_loss: 2.896\n",
      "Accacy on train_loader set: 94 % [1093/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[350,   20] loss: 0.00394, running_loss: 2.520\n",
      "Accacy on train_loader set: 95 % [1103/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[351,   20] loss: 0.00421, running_loss: 2.696\n",
      "Accacy on train_loader set: 95 % [1098/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[352,   20] loss: 0.00462, running_loss: 2.957\n",
      "Accacy on train_loader set: 94 % [1089/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[353,   20] loss: 0.00443, running_loss: 2.835\n",
      "Accacy on train_loader set: 96 % [1109/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[354,   20] loss: 0.00419, running_loss: 2.684\n",
      "Accacy on train_loader set: 96 % [1108/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[355,   20] loss: 0.00415, running_loss: 2.657\n",
      "Accacy on train_loader set: 95 % [1099/1152]\n",
      "Accacy on eval_loader set: 56 % [82/144]\n",
      "[356,   20] loss: 0.00376, running_loss: 2.406\n",
      "Accacy on train_loader set: 96 % [1107/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[357,   20] loss: 0.00392, running_loss: 2.512\n",
      "Accacy on train_loader set: 95 % [1101/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[358,   20] loss: 0.00424, running_loss: 2.715\n",
      "Accacy on train_loader set: 95 % [1100/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[359,   20] loss: 0.00440, running_loss: 2.819\n",
      "Accacy on train_loader set: 96 % [1108/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[360,   20] loss: 0.00473, running_loss: 3.026\n",
      "Accacy on train_loader set: 94 % [1090/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[361,   20] loss: 0.00432, running_loss: 2.765\n",
      "Accacy on train_loader set: 95 % [1104/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[362,   20] loss: 0.00475, running_loss: 3.037\n",
      "Accacy on train_loader set: 94 % [1089/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[363,   20] loss: 0.00375, running_loss: 2.401\n",
      "Accacy on train_loader set: 95 % [1105/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[364,   20] loss: 0.00390, running_loss: 2.499\n",
      "Accacy on train_loader set: 96 % [1107/1152]\n",
      "Accacy on eval_loader set: 59 % [85/144]\n",
      "[365,   20] loss: 0.00517, running_loss: 3.312\n",
      "Accacy on train_loader set: 94 % [1087/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[366,   20] loss: 0.00446, running_loss: 2.855\n",
      "Accacy on train_loader set: 96 % [1106/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[367,   20] loss: 0.00421, running_loss: 2.693\n",
      "Accacy on train_loader set: 96 % [1111/1152]\n",
      "Accacy on eval_loader set: 61 % [88/144]\n",
      "[368,   20] loss: 0.00350, running_loss: 2.241\n",
      "Accacy on train_loader set: 96 % [1109/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[369,   20] loss: 0.00412, running_loss: 2.635\n",
      "Accacy on train_loader set: 96 % [1110/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[370,   20] loss: 0.00448, running_loss: 2.870\n",
      "Accacy on train_loader set: 95 % [1098/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[371,   20] loss: 0.00324, running_loss: 2.074\n",
      "Accacy on train_loader set: 95 % [1100/1152]\n",
      "Accacy on eval_loader set: 61 % [88/144]\n",
      "[372,   20] loss: 0.00341, running_loss: 2.185\n",
      "Accacy on train_loader set: 95 % [1099/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[373,   20] loss: 0.00415, running_loss: 2.658\n",
      "Accacy on train_loader set: 95 % [1096/1152]\n",
      "Accacy on eval_loader set: 61 % [88/144]\n",
      "[374,   20] loss: 0.00430, running_loss: 2.755\n",
      "Accacy on train_loader set: 95 % [1104/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[375,   20] loss: 0.00454, running_loss: 2.909\n",
      "Accacy on train_loader set: 95 % [1101/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[376,   20] loss: 0.00425, running_loss: 2.720\n",
      "Accacy on train_loader set: 95 % [1104/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[377,   20] loss: 0.00374, running_loss: 2.391\n",
      "Accacy on train_loader set: 95 % [1105/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[378,   20] loss: 0.00367, running_loss: 2.347\n",
      "Accacy on train_loader set: 95 % [1105/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[379,   20] loss: 0.00355, running_loss: 2.273\n",
      "Accacy on train_loader set: 96 % [1112/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[380,   20] loss: 0.00354, running_loss: 2.265\n",
      "Accacy on train_loader set: 95 % [1101/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[381,   20] loss: 0.00436, running_loss: 2.793\n",
      "Accacy on train_loader set: 95 % [1103/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[382,   20] loss: 0.00366, running_loss: 2.345\n",
      "Accacy on train_loader set: 96 % [1113/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[383,   20] loss: 0.00390, running_loss: 2.495\n",
      "Accacy on train_loader set: 95 % [1098/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[384,   20] loss: 0.00346, running_loss: 2.214\n",
      "Accacy on train_loader set: 96 % [1116/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[385,   20] loss: 0.00409, running_loss: 2.617\n",
      "Accacy on train_loader set: 96 % [1112/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[386,   20] loss: 0.00354, running_loss: 2.265\n",
      "Accacy on train_loader set: 96 % [1108/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[387,   20] loss: 0.00516, running_loss: 3.301\n",
      "Accacy on train_loader set: 95 % [1095/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[388,   20] loss: 0.00451, running_loss: 2.888\n",
      "Accacy on train_loader set: 95 % [1102/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[389,   20] loss: 0.00338, running_loss: 2.165\n",
      "Accacy on train_loader set: 96 % [1110/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[390,   20] loss: 0.00430, running_loss: 2.750\n",
      "Accacy on train_loader set: 96 % [1111/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[391,   20] loss: 0.00425, running_loss: 2.717\n",
      "Accacy on train_loader set: 95 % [1103/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[392,   20] loss: 0.00330, running_loss: 2.109\n",
      "Accacy on train_loader set: 96 % [1108/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[393,   20] loss: 0.00355, running_loss: 2.273\n",
      "Accacy on train_loader set: 97 % [1120/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[394,   20] loss: 0.00373, running_loss: 2.387\n",
      "Accacy on train_loader set: 96 % [1110/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[395,   20] loss: 0.00385, running_loss: 2.465\n",
      "Accacy on train_loader set: 97 % [1119/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[396,   20] loss: 0.00423, running_loss: 2.704\n",
      "Accacy on train_loader set: 96 % [1106/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[397,   20] loss: 0.00328, running_loss: 2.102\n",
      "Accacy on train_loader set: 97 % [1119/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[398,   20] loss: 0.00386, running_loss: 2.468\n",
      "Accacy on train_loader set: 96 % [1112/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[399,   20] loss: 0.00367, running_loss: 2.346\n",
      "Accacy on train_loader set: 95 % [1104/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[400,   20] loss: 0.00358, running_loss: 2.291\n",
      "Accacy on train_loader set: 96 % [1114/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[401,   20] loss: 0.00357, running_loss: 2.282\n",
      "Accacy on train_loader set: 96 % [1108/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[402,   20] loss: 0.00427, running_loss: 2.734\n",
      "Accacy on train_loader set: 95 % [1102/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[403,   20] loss: 0.00362, running_loss: 2.315\n",
      "Accacy on train_loader set: 95 % [1102/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[404,   20] loss: 0.00368, running_loss: 2.354\n",
      "Accacy on train_loader set: 96 % [1111/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[405,   20] loss: 0.00360, running_loss: 2.304\n",
      "Accacy on train_loader set: 96 % [1112/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[406,   20] loss: 0.00314, running_loss: 2.009\n",
      "Accacy on train_loader set: 97 % [1119/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[407,   20] loss: 0.00375, running_loss: 2.401\n",
      "Accacy on train_loader set: 96 % [1107/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[408,   20] loss: 0.00336, running_loss: 2.152\n",
      "Accacy on train_loader set: 96 % [1108/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[409,   20] loss: 0.00308, running_loss: 1.971\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[410,   20] loss: 0.00336, running_loss: 2.150\n",
      "Accacy on train_loader set: 96 % [1117/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[411,   20] loss: 0.00365, running_loss: 2.335\n",
      "Accacy on train_loader set: 96 % [1112/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[412,   20] loss: 0.00316, running_loss: 2.023\n",
      "Accacy on train_loader set: 96 % [1112/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[413,   20] loss: 0.00292, running_loss: 1.866\n",
      "Accacy on train_loader set: 96 % [1117/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[414,   20] loss: 0.00376, running_loss: 2.409\n",
      "Accacy on train_loader set: 96 % [1109/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[415,   20] loss: 0.00375, running_loss: 2.403\n",
      "Accacy on train_loader set: 96 % [1109/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[416,   20] loss: 0.00340, running_loss: 2.174\n",
      "Accacy on train_loader set: 96 % [1109/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[417,   20] loss: 0.00315, running_loss: 2.015\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[418,   20] loss: 0.00385, running_loss: 2.461\n",
      "Accacy on train_loader set: 96 % [1111/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[419,   20] loss: 0.00387, running_loss: 2.475\n",
      "Accacy on train_loader set: 96 % [1113/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[420,   20] loss: 0.00356, running_loss: 2.279\n",
      "Accacy on train_loader set: 95 % [1099/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[421,   20] loss: 0.00413, running_loss: 2.644\n",
      "Accacy on train_loader set: 95 % [1104/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[422,   20] loss: 0.00350, running_loss: 2.237\n",
      "Accacy on train_loader set: 96 % [1112/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[423,   20] loss: 0.00403, running_loss: 2.576\n",
      "Accacy on train_loader set: 96 % [1111/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[424,   20] loss: 0.00310, running_loss: 1.982\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[425,   20] loss: 0.00369, running_loss: 2.361\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[426,   20] loss: 0.00411, running_loss: 2.632\n",
      "Accacy on train_loader set: 95 % [1100/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[427,   20] loss: 0.00424, running_loss: 2.714\n",
      "Accacy on train_loader set: 96 % [1113/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[428,   20] loss: 0.00326, running_loss: 2.088\n",
      "Accacy on train_loader set: 96 % [1117/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[429,   20] loss: 0.00311, running_loss: 1.990\n",
      "Accacy on train_loader set: 96 % [1117/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[430,   20] loss: 0.00359, running_loss: 2.295\n",
      "Accacy on train_loader set: 96 % [1111/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[431,   20] loss: 0.00286, running_loss: 1.829\n",
      "Accacy on train_loader set: 97 % [1118/1152]\n",
      "Accacy on eval_loader set: 61 % [88/144]\n",
      "[432,   20] loss: 0.00351, running_loss: 2.249\n",
      "Accacy on train_loader set: 96 % [1111/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[433,   20] loss: 0.00314, running_loss: 2.010\n",
      "Accacy on train_loader set: 96 % [1116/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[434,   20] loss: 0.00401, running_loss: 2.569\n",
      "Accacy on train_loader set: 96 % [1109/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[435,   20] loss: 0.00368, running_loss: 2.354\n",
      "Accacy on train_loader set: 96 % [1112/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[436,   20] loss: 0.00266, running_loss: 1.702\n",
      "Accacy on train_loader set: 97 % [1118/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[437,   20] loss: 0.00268, running_loss: 1.717\n",
      "Accacy on train_loader set: 97 % [1119/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[438,   20] loss: 0.00408, running_loss: 2.614\n",
      "Accacy on train_loader set: 96 % [1107/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[439,   20] loss: 0.00304, running_loss: 1.948\n",
      "Accacy on train_loader set: 96 % [1114/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[440,   20] loss: 0.00344, running_loss: 2.201\n",
      "Accacy on train_loader set: 96 % [1111/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[441,   20] loss: 0.00313, running_loss: 2.002\n",
      "Accacy on train_loader set: 97 % [1118/1152]\n",
      "Accacy on eval_loader set: 59 % [85/144]\n",
      "[442,   20] loss: 0.00313, running_loss: 2.002\n",
      "Accacy on train_loader set: 96 % [1107/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[443,   20] loss: 0.00346, running_loss: 2.216\n",
      "Accacy on train_loader set: 96 % [1115/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[444,   20] loss: 0.00298, running_loss: 1.910\n",
      "Accacy on train_loader set: 95 % [1104/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[445,   20] loss: 0.00434, running_loss: 2.779\n",
      "Accacy on train_loader set: 96 % [1110/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[446,   20] loss: 0.00292, running_loss: 1.871\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[447,   20] loss: 0.00341, running_loss: 2.182\n",
      "Accacy on train_loader set: 96 % [1106/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[448,   20] loss: 0.00287, running_loss: 1.835\n",
      "Accacy on train_loader set: 97 % [1118/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[449,   20] loss: 0.00298, running_loss: 1.906\n",
      "Accacy on train_loader set: 97 % [1118/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[450,   20] loss: 0.00352, running_loss: 2.252\n",
      "Accacy on train_loader set: 96 % [1116/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[451,   20] loss: 0.00282, running_loss: 1.807\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[452,   20] loss: 0.00303, running_loss: 1.940\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[453,   20] loss: 0.00299, running_loss: 1.911\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[454,   20] loss: 0.00250, running_loss: 1.601\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[455,   20] loss: 0.00370, running_loss: 2.371\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[456,   20] loss: 0.00261, running_loss: 1.671\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[457,   20] loss: 0.00327, running_loss: 2.091\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[458,   20] loss: 0.00307, running_loss: 1.963\n",
      "Accacy on train_loader set: 97 % [1118/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[459,   20] loss: 0.00349, running_loss: 2.236\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[460,   20] loss: 0.00264, running_loss: 1.689\n",
      "Accacy on train_loader set: 97 % [1119/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[461,   20] loss: 0.00233, running_loss: 1.488\n",
      "Accacy on train_loader set: 96 % [1117/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[462,   20] loss: 0.00254, running_loss: 1.624\n",
      "Accacy on train_loader set: 97 % [1120/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[463,   20] loss: 0.00310, running_loss: 1.984\n",
      "Accacy on train_loader set: 97 % [1118/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[464,   20] loss: 0.00352, running_loss: 2.256\n",
      "Accacy on train_loader set: 96 % [1114/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[465,   20] loss: 0.00221, running_loss: 1.417\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[466,   20] loss: 0.00343, running_loss: 2.194\n",
      "Accacy on train_loader set: 97 % [1128/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[467,   20] loss: 0.00337, running_loss: 2.154\n",
      "Accacy on train_loader set: 97 % [1123/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[468,   20] loss: 0.00322, running_loss: 2.059\n",
      "Accacy on train_loader set: 97 % [1119/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[469,   20] loss: 0.00280, running_loss: 1.792\n",
      "Accacy on train_loader set: 97 % [1126/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[470,   20] loss: 0.00300, running_loss: 1.923\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[471,   20] loss: 0.00270, running_loss: 1.727\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[472,   20] loss: 0.00261, running_loss: 1.669\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[473,   20] loss: 0.00278, running_loss: 1.781\n",
      "Accacy on train_loader set: 97 % [1123/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[474,   20] loss: 0.00308, running_loss: 1.968\n",
      "Accacy on train_loader set: 97 % [1118/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[475,   20] loss: 0.00249, running_loss: 1.596\n",
      "Accacy on train_loader set: 97 % [1118/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[476,   20] loss: 0.00343, running_loss: 2.192\n",
      "Accacy on train_loader set: 96 % [1117/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[477,   20] loss: 0.00338, running_loss: 2.165\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[478,   20] loss: 0.00354, running_loss: 2.267\n",
      "Accacy on train_loader set: 96 % [1112/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[479,   20] loss: 0.00285, running_loss: 1.821\n",
      "Accacy on train_loader set: 96 % [1112/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[480,   20] loss: 0.00232, running_loss: 1.482\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[481,   20] loss: 0.00226, running_loss: 1.449\n",
      "Accacy on train_loader set: 97 % [1127/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[482,   20] loss: 0.00286, running_loss: 1.832\n",
      "Accacy on train_loader set: 97 % [1123/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[483,   20] loss: 0.00266, running_loss: 1.700\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[484,   20] loss: 0.00262, running_loss: 1.676\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[485,   20] loss: 0.00333, running_loss: 2.128\n",
      "Accacy on train_loader set: 96 % [1112/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[486,   20] loss: 0.00375, running_loss: 2.398\n",
      "Accacy on train_loader set: 95 % [1104/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[487,   20] loss: 0.00231, running_loss: 1.477\n",
      "Accacy on train_loader set: 97 % [1126/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[488,   20] loss: 0.00293, running_loss: 1.874\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[489,   20] loss: 0.00275, running_loss: 1.759\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[490,   20] loss: 0.00282, running_loss: 1.807\n",
      "Accacy on train_loader set: 97 % [1119/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[491,   20] loss: 0.00218, running_loss: 1.397\n",
      "Accacy on train_loader set: 96 % [1116/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[492,   20] loss: 0.00261, running_loss: 1.667\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[493,   20] loss: 0.00300, running_loss: 1.922\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[494,   20] loss: 0.00255, running_loss: 1.635\n",
      "Accacy on train_loader set: 97 % [1119/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[495,   20] loss: 0.00202, running_loss: 1.296\n",
      "Accacy on train_loader set: 97 % [1127/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[496,   20] loss: 0.00269, running_loss: 1.721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 96 % [1112/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[497,   20] loss: 0.00279, running_loss: 1.785\n",
      "Accacy on train_loader set: 97 % [1128/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[498,   20] loss: 0.00222, running_loss: 1.419\n",
      "Accacy on train_loader set: 97 % [1127/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[499,   20] loss: 0.00237, running_loss: 1.518\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[500,   20] loss: 0.00279, running_loss: 1.786\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[501,   20] loss: 0.00293, running_loss: 1.876\n",
      "Accacy on train_loader set: 97 % [1120/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[502,   20] loss: 0.00289, running_loss: 1.849\n",
      "Accacy on train_loader set: 97 % [1120/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[503,   20] loss: 0.00270, running_loss: 1.726\n",
      "Accacy on train_loader set: 97 % [1120/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[504,   20] loss: 0.00245, running_loss: 1.567\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[505,   20] loss: 0.00205, running_loss: 1.315\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[506,   20] loss: 0.00246, running_loss: 1.578\n",
      "Accacy on train_loader set: 97 % [1123/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[507,   20] loss: 0.00335, running_loss: 2.141\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[508,   20] loss: 0.00231, running_loss: 1.480\n",
      "Accacy on train_loader set: 97 % [1126/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[509,   20] loss: 0.00254, running_loss: 1.627\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[510,   20] loss: 0.00309, running_loss: 1.978\n",
      "Accacy on train_loader set: 97 % [1126/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[511,   20] loss: 0.00207, running_loss: 1.325\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[512,   20] loss: 0.00245, running_loss: 1.568\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[513,   20] loss: 0.00234, running_loss: 1.501\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[514,   20] loss: 0.00184, running_loss: 1.176\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[515,   20] loss: 0.00284, running_loss: 1.821\n",
      "Accacy on train_loader set: 97 % [1118/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[516,   20] loss: 0.00193, running_loss: 1.238\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[517,   20] loss: 0.00284, running_loss: 1.821\n",
      "Accacy on train_loader set: 97 % [1127/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[518,   20] loss: 0.00171, running_loss: 1.093\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[519,   20] loss: 0.00318, running_loss: 2.035\n",
      "Accacy on train_loader set: 96 % [1113/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[520,   20] loss: 0.00203, running_loss: 1.299\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[521,   20] loss: 0.00285, running_loss: 1.824\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[522,   20] loss: 0.00244, running_loss: 1.559\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[523,   20] loss: 0.00319, running_loss: 2.044\n",
      "Accacy on train_loader set: 96 % [1116/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[524,   20] loss: 0.00288, running_loss: 1.843\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[525,   20] loss: 0.00273, running_loss: 1.745\n",
      "Accacy on train_loader set: 97 % [1123/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[526,   20] loss: 0.00219, running_loss: 1.404\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[527,   20] loss: 0.00260, running_loss: 1.665\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[528,   20] loss: 0.00242, running_loss: 1.550\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[529,   20] loss: 0.00219, running_loss: 1.401\n",
      "Accacy on train_loader set: 97 % [1128/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[530,   20] loss: 0.00236, running_loss: 1.514\n",
      "Accacy on train_loader set: 97 % [1126/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[531,   20] loss: 0.00265, running_loss: 1.694\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[532,   20] loss: 0.00188, running_loss: 1.203\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[533,   20] loss: 0.00243, running_loss: 1.556\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[534,   20] loss: 0.00234, running_loss: 1.501\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[535,   20] loss: 0.00254, running_loss: 1.628\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[536,   20] loss: 0.00253, running_loss: 1.619\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 61 % [88/144]\n",
      "[537,   20] loss: 0.00309, running_loss: 1.978\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[538,   20] loss: 0.00210, running_loss: 1.346\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[539,   20] loss: 0.00241, running_loss: 1.541\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[540,   20] loss: 0.00236, running_loss: 1.513\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[541,   20] loss: 0.00287, running_loss: 1.838\n",
      "Accacy on train_loader set: 96 % [1116/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[542,   20] loss: 0.00353, running_loss: 2.258\n",
      "Accacy on train_loader set: 96 % [1110/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[543,   20] loss: 0.00248, running_loss: 1.586\n",
      "Accacy on train_loader set: 97 % [1120/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[544,   20] loss: 0.00263, running_loss: 1.682\n",
      "Accacy on train_loader set: 96 % [1117/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[545,   20] loss: 0.00240, running_loss: 1.534\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[546,   20] loss: 0.00234, running_loss: 1.497\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[547,   20] loss: 0.00274, running_loss: 1.754\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[548,   20] loss: 0.00201, running_loss: 1.284\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[549,   20] loss: 0.00291, running_loss: 1.864\n",
      "Accacy on train_loader set: 97 % [1120/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[550,   20] loss: 0.00354, running_loss: 2.268\n",
      "Accacy on train_loader set: 97 % [1120/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[551,   20] loss: 0.00206, running_loss: 1.321\n",
      "Accacy on train_loader set: 97 % [1123/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[552,   20] loss: 0.00272, running_loss: 1.743\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[553,   20] loss: 0.00235, running_loss: 1.505\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[554,   20] loss: 0.00267, running_loss: 1.711\n",
      "Accacy on train_loader set: 97 % [1119/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[555,   20] loss: 0.00280, running_loss: 1.792\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[556,   20] loss: 0.00213, running_loss: 1.362\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[557,   20] loss: 0.00308, running_loss: 1.970\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[558,   20] loss: 0.00237, running_loss: 1.516\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[559,   20] loss: 0.00210, running_loss: 1.344\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[560,   20] loss: 0.00262, running_loss: 1.677\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[561,   20] loss: 0.00197, running_loss: 1.258\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[562,   20] loss: 0.00281, running_loss: 1.801\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[563,   20] loss: 0.00199, running_loss: 1.271\n",
      "Accacy on train_loader set: 97 % [1128/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[564,   20] loss: 0.00307, running_loss: 1.967\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[565,   20] loss: 0.00259, running_loss: 1.659\n",
      "Accacy on train_loader set: 97 % [1128/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[566,   20] loss: 0.00268, running_loss: 1.714\n",
      "Accacy on train_loader set: 97 % [1127/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[567,   20] loss: 0.00255, running_loss: 1.632\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[568,   20] loss: 0.00189, running_loss: 1.211\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[569,   20] loss: 0.00215, running_loss: 1.376\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[570,   20] loss: 0.00216, running_loss: 1.382\n",
      "Accacy on train_loader set: 97 % [1127/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[571,   20] loss: 0.00184, running_loss: 1.175\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[572,   20] loss: 0.00251, running_loss: 1.605\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[573,   20] loss: 0.00195, running_loss: 1.248\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[574,   20] loss: 0.00220, running_loss: 1.408\n",
      "Accacy on train_loader set: 97 % [1123/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[575,   20] loss: 0.00230, running_loss: 1.471\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[576,   20] loss: 0.00195, running_loss: 1.248\n",
      "Accacy on train_loader set: 97 % [1118/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[577,   20] loss: 0.00183, running_loss: 1.170\n",
      "Accacy on train_loader set: 97 % [1123/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[578,   20] loss: 0.00233, running_loss: 1.492\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[579,   20] loss: 0.00203, running_loss: 1.297\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[580,   20] loss: 0.00213, running_loss: 1.364\n",
      "Accacy on train_loader set: 97 % [1126/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[581,   20] loss: 0.00235, running_loss: 1.505\n",
      "Accacy on train_loader set: 97 % [1120/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[582,   20] loss: 0.00259, running_loss: 1.656\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[583,   20] loss: 0.00256, running_loss: 1.639\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[584,   20] loss: 0.00228, running_loss: 1.460\n",
      "Accacy on train_loader set: 97 % [1121/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[585,   20] loss: 0.00182, running_loss: 1.166\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[586,   20] loss: 0.00187, running_loss: 1.196\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[587,   20] loss: 0.00236, running_loss: 1.508\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[588,   20] loss: 0.00204, running_loss: 1.308\n",
      "Accacy on train_loader set: 97 % [1123/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[589,   20] loss: 0.00240, running_loss: 1.537\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[590,   20] loss: 0.00276, running_loss: 1.768\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[591,   20] loss: 0.00236, running_loss: 1.508\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[592,   20] loss: 0.00234, running_loss: 1.496\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[593,   20] loss: 0.00237, running_loss: 1.519\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[594,   20] loss: 0.00223, running_loss: 1.430\n",
      "Accacy on train_loader set: 97 % [1128/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[595,   20] loss: 0.00234, running_loss: 1.498\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[596,   20] loss: 0.00262, running_loss: 1.680\n",
      "Accacy on train_loader set: 96 % [1111/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[597,   20] loss: 0.00274, running_loss: 1.757\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[598,   20] loss: 0.00225, running_loss: 1.442\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[599,   20] loss: 0.00211, running_loss: 1.350\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[600,   20] loss: 0.00295, running_loss: 1.888\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[601,   20] loss: 0.00227, running_loss: 1.451\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[602,   20] loss: 0.00300, running_loss: 1.921\n",
      "Accacy on train_loader set: 97 % [1123/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[603,   20] loss: 0.00168, running_loss: 1.078\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[604,   20] loss: 0.00183, running_loss: 1.169\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[605,   20] loss: 0.00206, running_loss: 1.320\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[606,   20] loss: 0.00230, running_loss: 1.473\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[607,   20] loss: 0.00221, running_loss: 1.415\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[608,   20] loss: 0.00177, running_loss: 1.135\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[609,   20] loss: 0.00278, running_loss: 1.780\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[610,   20] loss: 0.00198, running_loss: 1.267\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[611,   20] loss: 0.00186, running_loss: 1.192\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[612,   20] loss: 0.00219, running_loss: 1.402\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[613,   20] loss: 0.00185, running_loss: 1.184\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[614,   20] loss: 0.00190, running_loss: 1.216\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[615,   20] loss: 0.00206, running_loss: 1.319\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[616,   20] loss: 0.00269, running_loss: 1.720\n",
      "Accacy on train_loader set: 97 % [1127/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[617,   20] loss: 0.00193, running_loss: 1.232\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[618,   20] loss: 0.00211, running_loss: 1.350\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[619,   20] loss: 0.00183, running_loss: 1.173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[620,   20] loss: 0.00205, running_loss: 1.315\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[621,   20] loss: 0.00267, running_loss: 1.708\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[622,   20] loss: 0.00220, running_loss: 1.406\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[623,   20] loss: 0.00210, running_loss: 1.345\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[624,   20] loss: 0.00195, running_loss: 1.246\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[625,   20] loss: 0.00189, running_loss: 1.207\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[626,   20] loss: 0.00205, running_loss: 1.310\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[627,   20] loss: 0.00213, running_loss: 1.362\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[628,   20] loss: 0.00233, running_loss: 1.493\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[629,   20] loss: 0.00186, running_loss: 1.193\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[630,   20] loss: 0.00187, running_loss: 1.195\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[631,   20] loss: 0.00208, running_loss: 1.333\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[632,   20] loss: 0.00161, running_loss: 1.030\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[633,   20] loss: 0.00223, running_loss: 1.427\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[634,   20] loss: 0.00231, running_loss: 1.481\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[635,   20] loss: 0.00256, running_loss: 1.638\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[636,   20] loss: 0.00220, running_loss: 1.408\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[637,   20] loss: 0.00209, running_loss: 1.335\n",
      "Accacy on train_loader set: 97 % [1128/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[638,   20] loss: 0.00160, running_loss: 1.023\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[639,   20] loss: 0.00148, running_loss: 0.947\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[640,   20] loss: 0.00193, running_loss: 1.233\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[641,   20] loss: 0.00238, running_loss: 1.524\n",
      "Accacy on train_loader set: 97 % [1128/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[642,   20] loss: 0.00158, running_loss: 1.010\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[643,   20] loss: 0.00159, running_loss: 1.020\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[644,   20] loss: 0.00203, running_loss: 1.299\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[645,   20] loss: 0.00171, running_loss: 1.091\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[646,   20] loss: 0.00176, running_loss: 1.127\n",
      "Accacy on train_loader set: 97 % [1123/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[647,   20] loss: 0.00264, running_loss: 1.691\n",
      "Accacy on train_loader set: 97 % [1126/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[648,   20] loss: 0.00216, running_loss: 1.382\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[649,   20] loss: 0.00209, running_loss: 1.339\n",
      "Accacy on train_loader set: 97 % [1127/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[650,   20] loss: 0.00169, running_loss: 1.081\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[651,   20] loss: 0.00205, running_loss: 1.309\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[652,   20] loss: 0.00213, running_loss: 1.365\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[653,   20] loss: 0.00155, running_loss: 0.995\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[654,   20] loss: 0.00201, running_loss: 1.288\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[655,   20] loss: 0.00210, running_loss: 1.346\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[656,   20] loss: 0.00189, running_loss: 1.209\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[657,   20] loss: 0.00153, running_loss: 0.981\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[658,   20] loss: 0.00216, running_loss: 1.381\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[659,   20] loss: 0.00165, running_loss: 1.057\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[660,   20] loss: 0.00187, running_loss: 1.194\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[661,   20] loss: 0.00188, running_loss: 1.201\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[662,   20] loss: 0.00221, running_loss: 1.416\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[663,   20] loss: 0.00201, running_loss: 1.288\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[664,   20] loss: 0.00132, running_loss: 0.844\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[665,   20] loss: 0.00180, running_loss: 1.151\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[666,   20] loss: 0.00172, running_loss: 1.098\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[667,   20] loss: 0.00217, running_loss: 1.387\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[668,   20] loss: 0.00177, running_loss: 1.131\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[669,   20] loss: 0.00168, running_loss: 1.073\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[670,   20] loss: 0.00188, running_loss: 1.204\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[671,   20] loss: 0.00203, running_loss: 1.298\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[672,   20] loss: 0.00160, running_loss: 1.022\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[673,   20] loss: 0.00243, running_loss: 1.554\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[674,   20] loss: 0.00160, running_loss: 1.026\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[675,   20] loss: 0.00268, running_loss: 1.714\n",
      "Accacy on train_loader set: 97 % [1123/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[676,   20] loss: 0.00194, running_loss: 1.241\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[677,   20] loss: 0.00177, running_loss: 1.136\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[678,   20] loss: 0.00215, running_loss: 1.375\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[679,   20] loss: 0.00237, running_loss: 1.515\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[680,   20] loss: 0.00262, running_loss: 1.675\n",
      "Accacy on train_loader set: 97 % [1128/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[681,   20] loss: 0.00256, running_loss: 1.637\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[682,   20] loss: 0.00137, running_loss: 0.875\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[683,   20] loss: 0.00203, running_loss: 1.296\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[684,   20] loss: 0.00181, running_loss: 1.158\n",
      "Accacy on train_loader set: 97 % [1128/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[685,   20] loss: 0.00222, running_loss: 1.420\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[686,   20] loss: 0.00202, running_loss: 1.292\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[687,   20] loss: 0.00138, running_loss: 0.882\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[688,   20] loss: 0.00148, running_loss: 0.944\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[689,   20] loss: 0.00227, running_loss: 1.451\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[690,   20] loss: 0.00211, running_loss: 1.353\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[691,   20] loss: 0.00225, running_loss: 1.440\n",
      "Accacy on train_loader set: 97 % [1124/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[692,   20] loss: 0.00158, running_loss: 1.013\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[693,   20] loss: 0.00165, running_loss: 1.059\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[694,   20] loss: 0.00223, running_loss: 1.428\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 59 % [86/144]\n",
      "[695,   20] loss: 0.00186, running_loss: 1.192\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[696,   20] loss: 0.00156, running_loss: 1.000\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[697,   20] loss: 0.00141, running_loss: 0.905\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[698,   20] loss: 0.00180, running_loss: 1.152\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[699,   20] loss: 0.00151, running_loss: 0.968\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[700,   20] loss: 0.00176, running_loss: 1.125\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[701,   20] loss: 0.00143, running_loss: 0.915\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[702,   20] loss: 0.00178, running_loss: 1.136\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[703,   20] loss: 0.00151, running_loss: 0.968\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[704,   20] loss: 0.00173, running_loss: 1.105\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[705,   20] loss: 0.00223, running_loss: 1.429\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[706,   20] loss: 0.00204, running_loss: 1.304\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[707,   20] loss: 0.00191, running_loss: 1.223\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[708,   20] loss: 0.00190, running_loss: 1.219\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[709,   20] loss: 0.00214, running_loss: 1.371\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[710,   20] loss: 0.00205, running_loss: 1.312\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[711,   20] loss: 0.00170, running_loss: 1.088\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[712,   20] loss: 0.00180, running_loss: 1.154\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[713,   20] loss: 0.00202, running_loss: 1.293\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[714,   20] loss: 0.00176, running_loss: 1.129\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[715,   20] loss: 0.00154, running_loss: 0.985\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[716,   20] loss: 0.00200, running_loss: 1.277\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[717,   20] loss: 0.00217, running_loss: 1.388\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[718,   20] loss: 0.00163, running_loss: 1.045\n",
      "Accacy on train_loader set: 97 % [1126/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[719,   20] loss: 0.00195, running_loss: 1.247\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[720,   20] loss: 0.00150, running_loss: 0.960\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[721,   20] loss: 0.00187, running_loss: 1.198\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[722,   20] loss: 0.00148, running_loss: 0.945\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[723,   20] loss: 0.00153, running_loss: 0.977\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[724,   20] loss: 0.00139, running_loss: 0.890\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[725,   20] loss: 0.00171, running_loss: 1.095\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[726,   20] loss: 0.00174, running_loss: 1.113\n",
      "Accacy on train_loader set: 97 % [1128/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[727,   20] loss: 0.00200, running_loss: 1.280\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[728,   20] loss: 0.00190, running_loss: 1.219\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[729,   20] loss: 0.00151, running_loss: 0.965\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[730,   20] loss: 0.00157, running_loss: 1.003\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[731,   20] loss: 0.00154, running_loss: 0.986\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[732,   20] loss: 0.00185, running_loss: 1.187\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[733,   20] loss: 0.00198, running_loss: 1.266\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[734,   20] loss: 0.00201, running_loss: 1.284\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[735,   20] loss: 0.00163, running_loss: 1.042\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[736,   20] loss: 0.00171, running_loss: 1.094\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[737,   20] loss: 0.00222, running_loss: 1.424\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[738,   20] loss: 0.00184, running_loss: 1.178\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[739,   20] loss: 0.00158, running_loss: 1.012\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[740,   20] loss: 0.00155, running_loss: 0.991\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[741,   20] loss: 0.00223, running_loss: 1.426\n",
      "Accacy on train_loader set: 97 % [1123/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[742,   20] loss: 0.00160, running_loss: 1.027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[743,   20] loss: 0.00178, running_loss: 1.138\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[744,   20] loss: 0.00152, running_loss: 0.972\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[745,   20] loss: 0.00193, running_loss: 1.232\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[746,   20] loss: 0.00172, running_loss: 1.103\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[747,   20] loss: 0.00227, running_loss: 1.454\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[748,   20] loss: 0.00179, running_loss: 1.144\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[749,   20] loss: 0.00185, running_loss: 1.181\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[750,   20] loss: 0.00175, running_loss: 1.120\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[751,   20] loss: 0.00147, running_loss: 0.941\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[752,   20] loss: 0.00176, running_loss: 1.125\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[753,   20] loss: 0.00184, running_loss: 1.178\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[754,   20] loss: 0.00139, running_loss: 0.889\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[755,   20] loss: 0.00183, running_loss: 1.174\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[756,   20] loss: 0.00125, running_loss: 0.803\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[757,   20] loss: 0.00134, running_loss: 0.859\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[758,   20] loss: 0.00164, running_loss: 1.048\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[759,   20] loss: 0.00170, running_loss: 1.090\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[760,   20] loss: 0.00140, running_loss: 0.895\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[761,   20] loss: 0.00198, running_loss: 1.265\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[762,   20] loss: 0.00138, running_loss: 0.885\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[763,   20] loss: 0.00149, running_loss: 0.951\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[764,   20] loss: 0.00136, running_loss: 0.871\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[765,   20] loss: 0.00238, running_loss: 1.522\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[766,   20] loss: 0.00174, running_loss: 1.114\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[767,   20] loss: 0.00150, running_loss: 0.957\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[768,   20] loss: 0.00183, running_loss: 1.173\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[769,   20] loss: 0.00229, running_loss: 1.466\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[770,   20] loss: 0.00153, running_loss: 0.980\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[771,   20] loss: 0.00157, running_loss: 1.006\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[772,   20] loss: 0.00191, running_loss: 1.224\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[773,   20] loss: 0.00122, running_loss: 0.782\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[774,   20] loss: 0.00174, running_loss: 1.113\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[775,   20] loss: 0.00159, running_loss: 1.018\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[776,   20] loss: 0.00140, running_loss: 0.897\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[777,   20] loss: 0.00130, running_loss: 0.835\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[778,   20] loss: 0.00159, running_loss: 1.017\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[779,   20] loss: 0.00142, running_loss: 0.906\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[780,   20] loss: 0.00167, running_loss: 1.072\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[781,   20] loss: 0.00154, running_loss: 0.986\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[782,   20] loss: 0.00180, running_loss: 1.153\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[783,   20] loss: 0.00181, running_loss: 1.159\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[784,   20] loss: 0.00110, running_loss: 0.701\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[785,   20] loss: 0.00138, running_loss: 0.885\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[786,   20] loss: 0.00167, running_loss: 1.072\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[787,   20] loss: 0.00182, running_loss: 1.167\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[788,   20] loss: 0.00168, running_loss: 1.078\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[789,   20] loss: 0.00197, running_loss: 1.263\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[790,   20] loss: 0.00205, running_loss: 1.312\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[791,   20] loss: 0.00181, running_loss: 1.157\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[792,   20] loss: 0.00185, running_loss: 1.182\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[793,   20] loss: 0.00202, running_loss: 1.293\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[794,   20] loss: 0.00199, running_loss: 1.271\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[795,   20] loss: 0.00203, running_loss: 1.301\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[796,   20] loss: 0.00171, running_loss: 1.097\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[797,   20] loss: 0.00187, running_loss: 1.197\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[798,   20] loss: 0.00141, running_loss: 0.903\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[799,   20] loss: 0.00239, running_loss: 1.531\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[800,   20] loss: 0.00178, running_loss: 1.136\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[801,   20] loss: 0.00226, running_loss: 1.446\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[802,   20] loss: 0.00118, running_loss: 0.756\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[803,   20] loss: 0.00162, running_loss: 1.037\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[804,   20] loss: 0.00152, running_loss: 0.975\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[805,   20] loss: 0.00109, running_loss: 0.700\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[806,   20] loss: 0.00131, running_loss: 0.841\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[807,   20] loss: 0.00166, running_loss: 1.062\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[808,   20] loss: 0.00219, running_loss: 1.401\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[809,   20] loss: 0.00110, running_loss: 0.706\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[810,   20] loss: 0.00109, running_loss: 0.700\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[811,   20] loss: 0.00149, running_loss: 0.956\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[812,   20] loss: 0.00167, running_loss: 1.067\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[813,   20] loss: 0.00167, running_loss: 1.070\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[814,   20] loss: 0.00135, running_loss: 0.865\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[815,   20] loss: 0.00189, running_loss: 1.212\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[816,   20] loss: 0.00133, running_loss: 0.848\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[817,   20] loss: 0.00180, running_loss: 1.152\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[818,   20] loss: 0.00131, running_loss: 0.836\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[819,   20] loss: 0.00113, running_loss: 0.724\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[820,   20] loss: 0.00159, running_loss: 1.020\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[821,   20] loss: 0.00212, running_loss: 1.355\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[822,   20] loss: 0.00158, running_loss: 1.011\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[823,   20] loss: 0.00140, running_loss: 0.898\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[824,   20] loss: 0.00127, running_loss: 0.811\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[825,   20] loss: 0.00132, running_loss: 0.842\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[826,   20] loss: 0.00137, running_loss: 0.878\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[827,   20] loss: 0.00167, running_loss: 1.066\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[828,   20] loss: 0.00184, running_loss: 1.174\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[829,   20] loss: 0.00133, running_loss: 0.851\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[830,   20] loss: 0.00116, running_loss: 0.745\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[831,   20] loss: 0.00174, running_loss: 1.111\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[832,   20] loss: 0.00130, running_loss: 0.834\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[833,   20] loss: 0.00110, running_loss: 0.704\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[834,   20] loss: 0.00138, running_loss: 0.882\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[835,   20] loss: 0.00176, running_loss: 1.129\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[836,   20] loss: 0.00152, running_loss: 0.970\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[837,   20] loss: 0.00191, running_loss: 1.222\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[838,   20] loss: 0.00157, running_loss: 1.004\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[839,   20] loss: 0.00168, running_loss: 1.073\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[840,   20] loss: 0.00136, running_loss: 0.871\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[841,   20] loss: 0.00158, running_loss: 1.008\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[842,   20] loss: 0.00131, running_loss: 0.837\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[843,   20] loss: 0.00179, running_loss: 1.144\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[844,   20] loss: 0.00177, running_loss: 1.131\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[845,   20] loss: 0.00169, running_loss: 1.082\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[846,   20] loss: 0.00183, running_loss: 1.168\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[847,   20] loss: 0.00118, running_loss: 0.758\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[848,   20] loss: 0.00133, running_loss: 0.849\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[849,   20] loss: 0.00170, running_loss: 1.088\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[850,   20] loss: 0.00128, running_loss: 0.820\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[851,   20] loss: 0.00128, running_loss: 0.816\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[852,   20] loss: 0.00154, running_loss: 0.984\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[853,   20] loss: 0.00266, running_loss: 1.702\n",
      "Accacy on train_loader set: 97 % [1125/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[854,   20] loss: 0.00153, running_loss: 0.976\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[855,   20] loss: 0.00187, running_loss: 1.196\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[856,   20] loss: 0.00128, running_loss: 0.817\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[857,   20] loss: 0.00152, running_loss: 0.974\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[858,   20] loss: 0.00127, running_loss: 0.813\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[859,   20] loss: 0.00158, running_loss: 1.011\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[860,   20] loss: 0.00128, running_loss: 0.821\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[861,   20] loss: 0.00150, running_loss: 0.961\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[862,   20] loss: 0.00124, running_loss: 0.793\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[863,   20] loss: 0.00103, running_loss: 0.661\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[864,   20] loss: 0.00178, running_loss: 1.142\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[865,   20] loss: 0.00157, running_loss: 1.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[866,   20] loss: 0.00156, running_loss: 1.002\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[867,   20] loss: 0.00206, running_loss: 1.316\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[868,   20] loss: 0.00153, running_loss: 0.980\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[869,   20] loss: 0.00109, running_loss: 0.696\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[870,   20] loss: 0.00191, running_loss: 1.222\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[871,   20] loss: 0.00140, running_loss: 0.895\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[872,   20] loss: 0.00166, running_loss: 1.060\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[873,   20] loss: 0.00166, running_loss: 1.062\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[874,   20] loss: 0.00114, running_loss: 0.727\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[875,   20] loss: 0.00112, running_loss: 0.719\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[876,   20] loss: 0.00187, running_loss: 1.198\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[877,   20] loss: 0.00112, running_loss: 0.717\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[878,   20] loss: 0.00152, running_loss: 0.975\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[879,   20] loss: 0.00102, running_loss: 0.651\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[880,   20] loss: 0.00179, running_loss: 1.144\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[881,   20] loss: 0.00176, running_loss: 1.127\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[882,   20] loss: 0.00111, running_loss: 0.710\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[883,   20] loss: 0.00139, running_loss: 0.886\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[884,   20] loss: 0.00085, running_loss: 0.545\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[885,   20] loss: 0.00195, running_loss: 1.245\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[886,   20] loss: 0.00176, running_loss: 1.128\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[887,   20] loss: 0.00175, running_loss: 1.122\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[888,   20] loss: 0.00175, running_loss: 1.121\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[889,   20] loss: 0.00132, running_loss: 0.844\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[890,   20] loss: 0.00127, running_loss: 0.815\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[891,   20] loss: 0.00113, running_loss: 0.723\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[892,   20] loss: 0.00172, running_loss: 1.099\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[893,   20] loss: 0.00170, running_loss: 1.090\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[894,   20] loss: 0.00142, running_loss: 0.910\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[895,   20] loss: 0.00178, running_loss: 1.137\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[896,   20] loss: 0.00124, running_loss: 0.796\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[897,   20] loss: 0.00161, running_loss: 1.028\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[898,   20] loss: 0.00159, running_loss: 1.020\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[899,   20] loss: 0.00184, running_loss: 1.180\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[900,   20] loss: 0.00213, running_loss: 1.360\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[901,   20] loss: 0.00139, running_loss: 0.887\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[902,   20] loss: 0.00149, running_loss: 0.951\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[903,   20] loss: 0.00096, running_loss: 0.617\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[904,   20] loss: 0.00157, running_loss: 1.002\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[905,   20] loss: 0.00147, running_loss: 0.943\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[906,   20] loss: 0.00135, running_loss: 0.867\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[907,   20] loss: 0.00187, running_loss: 1.199\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[908,   20] loss: 0.00114, running_loss: 0.731\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[909,   20] loss: 0.00118, running_loss: 0.758\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[910,   20] loss: 0.00152, running_loss: 0.976\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[911,   20] loss: 0.00140, running_loss: 0.897\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[912,   20] loss: 0.00148, running_loss: 0.947\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[913,   20] loss: 0.00136, running_loss: 0.872\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[914,   20] loss: 0.00153, running_loss: 0.981\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[915,   20] loss: 0.00106, running_loss: 0.678\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[916,   20] loss: 0.00155, running_loss: 0.993\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[917,   20] loss: 0.00106, running_loss: 0.681\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[918,   20] loss: 0.00142, running_loss: 0.906\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[919,   20] loss: 0.00123, running_loss: 0.785\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[920,   20] loss: 0.00156, running_loss: 0.999\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[921,   20] loss: 0.00153, running_loss: 0.977\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[922,   20] loss: 0.00110, running_loss: 0.705\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[923,   20] loss: 0.00129, running_loss: 0.823\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[924,   20] loss: 0.00098, running_loss: 0.630\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[925,   20] loss: 0.00128, running_loss: 0.819\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[926,   20] loss: 0.00114, running_loss: 0.727\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[927,   20] loss: 0.00139, running_loss: 0.888\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[928,   20] loss: 0.00145, running_loss: 0.930\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[929,   20] loss: 0.00140, running_loss: 0.897\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[930,   20] loss: 0.00097, running_loss: 0.619\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[931,   20] loss: 0.00149, running_loss: 0.956\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[932,   20] loss: 0.00134, running_loss: 0.858\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[933,   20] loss: 0.00110, running_loss: 0.704\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[934,   20] loss: 0.00126, running_loss: 0.808\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[935,   20] loss: 0.00129, running_loss: 0.828\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[936,   20] loss: 0.00143, running_loss: 0.918\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[937,   20] loss: 0.00163, running_loss: 1.041\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[938,   20] loss: 0.00143, running_loss: 0.917\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[939,   20] loss: 0.00129, running_loss: 0.827\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[940,   20] loss: 0.00159, running_loss: 1.015\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[941,   20] loss: 0.00135, running_loss: 0.864\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[942,   20] loss: 0.00145, running_loss: 0.931\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[943,   20] loss: 0.00175, running_loss: 1.119\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[944,   20] loss: 0.00183, running_loss: 1.169\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[945,   20] loss: 0.00153, running_loss: 0.981\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[946,   20] loss: 0.00136, running_loss: 0.872\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[947,   20] loss: 0.00151, running_loss: 0.966\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[948,   20] loss: 0.00153, running_loss: 0.980\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[949,   20] loss: 0.00203, running_loss: 1.298\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[950,   20] loss: 0.00146, running_loss: 0.933\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[951,   20] loss: 0.00160, running_loss: 1.024\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[952,   20] loss: 0.00157, running_loss: 1.007\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[953,   20] loss: 0.00136, running_loss: 0.871\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[954,   20] loss: 0.00147, running_loss: 0.943\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[955,   20] loss: 0.00091, running_loss: 0.584\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[956,   20] loss: 0.00140, running_loss: 0.896\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[957,   20] loss: 0.00132, running_loss: 0.846\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[958,   20] loss: 0.00112, running_loss: 0.717\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[959,   20] loss: 0.00102, running_loss: 0.652\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[960,   20] loss: 0.00184, running_loss: 1.180\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[961,   20] loss: 0.00107, running_loss: 0.685\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[962,   20] loss: 0.00155, running_loss: 0.993\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[963,   20] loss: 0.00107, running_loss: 0.686\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[964,   20] loss: 0.00143, running_loss: 0.917\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[965,   20] loss: 0.00143, running_loss: 0.913\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[966,   20] loss: 0.00182, running_loss: 1.162\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[967,   20] loss: 0.00160, running_loss: 1.024\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[968,   20] loss: 0.00126, running_loss: 0.807\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[969,   20] loss: 0.00115, running_loss: 0.738\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[970,   20] loss: 0.00136, running_loss: 0.871\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[971,   20] loss: 0.00106, running_loss: 0.680\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[972,   20] loss: 0.00112, running_loss: 0.717\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[973,   20] loss: 0.00164, running_loss: 1.049\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[974,   20] loss: 0.00116, running_loss: 0.742\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[975,   20] loss: 0.00139, running_loss: 0.891\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[976,   20] loss: 0.00149, running_loss: 0.956\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[977,   20] loss: 0.00175, running_loss: 1.121\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[978,   20] loss: 0.00106, running_loss: 0.679\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[979,   20] loss: 0.00140, running_loss: 0.897\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[980,   20] loss: 0.00159, running_loss: 1.015\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[981,   20] loss: 0.00111, running_loss: 0.712\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[982,   20] loss: 0.00117, running_loss: 0.748\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[983,   20] loss: 0.00159, running_loss: 1.016\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[984,   20] loss: 0.00159, running_loss: 1.017\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[985,   20] loss: 0.00168, running_loss: 1.077\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[986,   20] loss: 0.00207, running_loss: 1.326\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[987,   20] loss: 0.00137, running_loss: 0.876\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[988,   20] loss: 0.00114, running_loss: 0.728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[989,   20] loss: 0.00112, running_loss: 0.720\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[990,   20] loss: 0.00146, running_loss: 0.934\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[991,   20] loss: 0.00132, running_loss: 0.844\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[992,   20] loss: 0.00091, running_loss: 0.579\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[993,   20] loss: 0.00109, running_loss: 0.699\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[994,   20] loss: 0.00198, running_loss: 1.266\n",
      "Accacy on train_loader set: 97 % [1122/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[995,   20] loss: 0.00152, running_loss: 0.974\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[996,   20] loss: 0.00120, running_loss: 0.768\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[997,   20] loss: 0.00142, running_loss: 0.910\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[998,   20] loss: 0.00132, running_loss: 0.846\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[999,   20] loss: 0.00115, running_loss: 0.737\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1000,   20] loss: 0.00166, running_loss: 1.063\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1001,   20] loss: 0.00121, running_loss: 0.776\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1002,   20] loss: 0.00142, running_loss: 0.910\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1003,   20] loss: 0.00118, running_loss: 0.758\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1004,   20] loss: 0.00130, running_loss: 0.831\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1005,   20] loss: 0.00140, running_loss: 0.896\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1006,   20] loss: 0.00168, running_loss: 1.076\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1007,   20] loss: 0.00207, running_loss: 1.324\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1008,   20] loss: 0.00122, running_loss: 0.780\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1009,   20] loss: 0.00124, running_loss: 0.796\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1010,   20] loss: 0.00179, running_loss: 1.143\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[1011,   20] loss: 0.00133, running_loss: 0.849\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1012,   20] loss: 0.00131, running_loss: 0.837\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1013,   20] loss: 0.00101, running_loss: 0.645\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1014,   20] loss: 0.00109, running_loss: 0.698\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1015,   20] loss: 0.00144, running_loss: 0.921\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1016,   20] loss: 0.00125, running_loss: 0.802\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1017,   20] loss: 0.00126, running_loss: 0.807\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1018,   20] loss: 0.00144, running_loss: 0.921\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1019,   20] loss: 0.00155, running_loss: 0.992\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1020,   20] loss: 0.00101, running_loss: 0.649\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1021,   20] loss: 0.00080, running_loss: 0.510\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1022,   20] loss: 0.00119, running_loss: 0.765\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1023,   20] loss: 0.00125, running_loss: 0.803\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1024,   20] loss: 0.00115, running_loss: 0.733\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1025,   20] loss: 0.00162, running_loss: 1.035\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1026,   20] loss: 0.00156, running_loss: 0.999\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1027,   20] loss: 0.00132, running_loss: 0.843\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1028,   20] loss: 0.00109, running_loss: 0.696\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[1029,   20] loss: 0.00140, running_loss: 0.899\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1030,   20] loss: 0.00106, running_loss: 0.681\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1031,   20] loss: 0.00108, running_loss: 0.694\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1032,   20] loss: 0.00162, running_loss: 1.034\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1033,   20] loss: 0.00127, running_loss: 0.813\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1034,   20] loss: 0.00137, running_loss: 0.878\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[1035,   20] loss: 0.00124, running_loss: 0.791\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1036,   20] loss: 0.00095, running_loss: 0.609\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1037,   20] loss: 0.00097, running_loss: 0.623\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1038,   20] loss: 0.00148, running_loss: 0.949\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1039,   20] loss: 0.00129, running_loss: 0.825\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1040,   20] loss: 0.00140, running_loss: 0.893\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1041,   20] loss: 0.00156, running_loss: 0.996\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1042,   20] loss: 0.00125, running_loss: 0.801\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1043,   20] loss: 0.00165, running_loss: 1.055\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1044,   20] loss: 0.00119, running_loss: 0.764\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1045,   20] loss: 0.00153, running_loss: 0.978\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[1046,   20] loss: 0.00091, running_loss: 0.580\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1047,   20] loss: 0.00121, running_loss: 0.774\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1048,   20] loss: 0.00175, running_loss: 1.117\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1049,   20] loss: 0.00106, running_loss: 0.678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1050,   20] loss: 0.00152, running_loss: 0.973\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1051,   20] loss: 0.00145, running_loss: 0.929\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[1052,   20] loss: 0.00106, running_loss: 0.677\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1053,   20] loss: 0.00158, running_loss: 1.011\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1054,   20] loss: 0.00152, running_loss: 0.974\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1055,   20] loss: 0.00170, running_loss: 1.091\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1056,   20] loss: 0.00130, running_loss: 0.830\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1057,   20] loss: 0.00151, running_loss: 0.967\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1058,   20] loss: 0.00155, running_loss: 0.994\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1059,   20] loss: 0.00127, running_loss: 0.810\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1060,   20] loss: 0.00152, running_loss: 0.974\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[1061,   20] loss: 0.00136, running_loss: 0.873\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1062,   20] loss: 0.00158, running_loss: 1.013\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1063,   20] loss: 0.00136, running_loss: 0.868\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1064,   20] loss: 0.00146, running_loss: 0.937\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1065,   20] loss: 0.00131, running_loss: 0.841\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1066,   20] loss: 0.00127, running_loss: 0.811\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[1067,   20] loss: 0.00107, running_loss: 0.687\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1068,   20] loss: 0.00159, running_loss: 1.016\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1069,   20] loss: 0.00127, running_loss: 0.813\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1070,   20] loss: 0.00125, running_loss: 0.799\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1071,   20] loss: 0.00143, running_loss: 0.913\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1072,   20] loss: 0.00112, running_loss: 0.717\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1073,   20] loss: 0.00150, running_loss: 0.959\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1074,   20] loss: 0.00112, running_loss: 0.718\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1075,   20] loss: 0.00140, running_loss: 0.893\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[1076,   20] loss: 0.00121, running_loss: 0.772\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1077,   20] loss: 0.00141, running_loss: 0.902\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1078,   20] loss: 0.00094, running_loss: 0.603\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1079,   20] loss: 0.00149, running_loss: 0.952\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1080,   20] loss: 0.00134, running_loss: 0.858\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1081,   20] loss: 0.00186, running_loss: 1.190\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1082,   20] loss: 0.00179, running_loss: 1.144\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1083,   20] loss: 0.00108, running_loss: 0.694\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1084,   20] loss: 0.00143, running_loss: 0.918\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1085,   20] loss: 0.00189, running_loss: 1.206\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1086,   20] loss: 0.00084, running_loss: 0.535\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1087,   20] loss: 0.00111, running_loss: 0.710\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1088,   20] loss: 0.00175, running_loss: 1.123\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1089,   20] loss: 0.00127, running_loss: 0.814\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1090,   20] loss: 0.00155, running_loss: 0.992\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1091,   20] loss: 0.00119, running_loss: 0.764\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1092,   20] loss: 0.00134, running_loss: 0.858\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[1093,   20] loss: 0.00144, running_loss: 0.921\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1094,   20] loss: 0.00155, running_loss: 0.990\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1095,   20] loss: 0.00131, running_loss: 0.838\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1096,   20] loss: 0.00123, running_loss: 0.787\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1097,   20] loss: 0.00160, running_loss: 1.021\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1098,   20] loss: 0.00106, running_loss: 0.676\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1099,   20] loss: 0.00134, running_loss: 0.856\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[1100,   20] loss: 0.00141, running_loss: 0.904\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1101,   20] loss: 0.00118, running_loss: 0.754\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1102,   20] loss: 0.00101, running_loss: 0.649\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1103,   20] loss: 0.00112, running_loss: 0.718\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1104,   20] loss: 0.00091, running_loss: 0.580\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1105,   20] loss: 0.00125, running_loss: 0.799\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1106,   20] loss: 0.00129, running_loss: 0.828\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1107,   20] loss: 0.00103, running_loss: 0.659\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1108,   20] loss: 0.00130, running_loss: 0.830\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1109,   20] loss: 0.00135, running_loss: 0.864\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1110,   20] loss: 0.00133, running_loss: 0.854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1111,   20] loss: 0.00110, running_loss: 0.701\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[1112,   20] loss: 0.00166, running_loss: 1.063\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1113,   20] loss: 0.00120, running_loss: 0.769\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1114,   20] loss: 0.00092, running_loss: 0.586\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1115,   20] loss: 0.00129, running_loss: 0.826\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1116,   20] loss: 0.00092, running_loss: 0.587\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1117,   20] loss: 0.00118, running_loss: 0.757\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1118,   20] loss: 0.00089, running_loss: 0.568\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1119,   20] loss: 0.00091, running_loss: 0.581\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[1120,   20] loss: 0.00138, running_loss: 0.881\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[1121,   20] loss: 0.00111, running_loss: 0.712\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1122,   20] loss: 0.00169, running_loss: 1.080\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1123,   20] loss: 0.00111, running_loss: 0.711\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1124,   20] loss: 0.00121, running_loss: 0.775\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1125,   20] loss: 0.00154, running_loss: 0.987\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1126,   20] loss: 0.00154, running_loss: 0.988\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1127,   20] loss: 0.00154, running_loss: 0.983\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[1128,   20] loss: 0.00113, running_loss: 0.720\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1129,   20] loss: 0.00081, running_loss: 0.517\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1130,   20] loss: 0.00100, running_loss: 0.639\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1131,   20] loss: 0.00135, running_loss: 0.861\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[1132,   20] loss: 0.00130, running_loss: 0.835\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1133,   20] loss: 0.00126, running_loss: 0.809\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1134,   20] loss: 0.00135, running_loss: 0.863\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1135,   20] loss: 0.00095, running_loss: 0.609\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1136,   20] loss: 0.00098, running_loss: 0.628\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1137,   20] loss: 0.00111, running_loss: 0.712\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[1138,   20] loss: 0.00112, running_loss: 0.719\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1139,   20] loss: 0.00124, running_loss: 0.792\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1140,   20] loss: 0.00107, running_loss: 0.683\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1141,   20] loss: 0.00117, running_loss: 0.746\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1142,   20] loss: 0.00152, running_loss: 0.971\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1143,   20] loss: 0.00214, running_loss: 1.372\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[1144,   20] loss: 0.00150, running_loss: 0.962\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1145,   20] loss: 0.00118, running_loss: 0.756\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1146,   20] loss: 0.00110, running_loss: 0.703\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1147,   20] loss: 0.00144, running_loss: 0.921\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1148,   20] loss: 0.00089, running_loss: 0.571\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1149,   20] loss: 0.00119, running_loss: 0.759\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1150,   20] loss: 0.00130, running_loss: 0.829\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1151,   20] loss: 0.00109, running_loss: 0.698\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1152,   20] loss: 0.00146, running_loss: 0.932\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1153,   20] loss: 0.00126, running_loss: 0.807\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1154,   20] loss: 0.00122, running_loss: 0.783\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1155,   20] loss: 0.00185, running_loss: 1.185\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1156,   20] loss: 0.00122, running_loss: 0.778\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1157,   20] loss: 0.00141, running_loss: 0.905\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1158,   20] loss: 0.00166, running_loss: 1.061\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1159,   20] loss: 0.00126, running_loss: 0.805\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1160,   20] loss: 0.00096, running_loss: 0.615\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1161,   20] loss: 0.00111, running_loss: 0.714\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1162,   20] loss: 0.00151, running_loss: 0.968\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1163,   20] loss: 0.00134, running_loss: 0.855\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1164,   20] loss: 0.00145, running_loss: 0.925\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1165,   20] loss: 0.00093, running_loss: 0.596\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1166,   20] loss: 0.00111, running_loss: 0.712\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1167,   20] loss: 0.00157, running_loss: 1.006\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1168,   20] loss: 0.00180, running_loss: 1.153\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1169,   20] loss: 0.00116, running_loss: 0.742\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1170,   20] loss: 0.00127, running_loss: 0.812\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1171,   20] loss: 0.00124, running_loss: 0.791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1172,   20] loss: 0.00136, running_loss: 0.873\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1173,   20] loss: 0.00193, running_loss: 1.235\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1174,   20] loss: 0.00107, running_loss: 0.684\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1175,   20] loss: 0.00102, running_loss: 0.655\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1176,   20] loss: 0.00107, running_loss: 0.682\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1177,   20] loss: 0.00105, running_loss: 0.672\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1178,   20] loss: 0.00109, running_loss: 0.696\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[1179,   20] loss: 0.00142, running_loss: 0.910\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1180,   20] loss: 0.00138, running_loss: 0.883\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1181,   20] loss: 0.00119, running_loss: 0.762\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1182,   20] loss: 0.00122, running_loss: 0.779\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1183,   20] loss: 0.00146, running_loss: 0.932\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1184,   20] loss: 0.00096, running_loss: 0.616\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1185,   20] loss: 0.00116, running_loss: 0.740\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1186,   20] loss: 0.00090, running_loss: 0.579\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1187,   20] loss: 0.00111, running_loss: 0.713\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1188,   20] loss: 0.00093, running_loss: 0.593\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1189,   20] loss: 0.00110, running_loss: 0.704\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1190,   20] loss: 0.00138, running_loss: 0.886\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1191,   20] loss: 0.00129, running_loss: 0.828\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1192,   20] loss: 0.00127, running_loss: 0.815\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1193,   20] loss: 0.00113, running_loss: 0.723\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1194,   20] loss: 0.00169, running_loss: 1.084\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1195,   20] loss: 0.00122, running_loss: 0.780\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[1196,   20] loss: 0.00111, running_loss: 0.711\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1197,   20] loss: 0.00157, running_loss: 1.003\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1198,   20] loss: 0.00149, running_loss: 0.953\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1199,   20] loss: 0.00141, running_loss: 0.901\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1200,   20] loss: 0.00137, running_loss: 0.874\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1201,   20] loss: 0.00089, running_loss: 0.572\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1202,   20] loss: 0.00126, running_loss: 0.808\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1203,   20] loss: 0.00124, running_loss: 0.795\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1204,   20] loss: 0.00135, running_loss: 0.863\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1205,   20] loss: 0.00072, running_loss: 0.458\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1206,   20] loss: 0.00144, running_loss: 0.920\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1207,   20] loss: 0.00134, running_loss: 0.860\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1208,   20] loss: 0.00121, running_loss: 0.776\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1209,   20] loss: 0.00106, running_loss: 0.679\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1210,   20] loss: 0.00156, running_loss: 1.000\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[1211,   20] loss: 0.00100, running_loss: 0.643\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1212,   20] loss: 0.00082, running_loss: 0.526\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1213,   20] loss: 0.00095, running_loss: 0.609\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1214,   20] loss: 0.00161, running_loss: 1.027\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1215,   20] loss: 0.00101, running_loss: 0.647\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1216,   20] loss: 0.00121, running_loss: 0.772\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1217,   20] loss: 0.00118, running_loss: 0.755\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1218,   20] loss: 0.00095, running_loss: 0.610\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1219,   20] loss: 0.00141, running_loss: 0.903\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1220,   20] loss: 0.00096, running_loss: 0.614\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[1221,   20] loss: 0.00141, running_loss: 0.900\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1222,   20] loss: 0.00128, running_loss: 0.816\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1223,   20] loss: 0.00113, running_loss: 0.726\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1224,   20] loss: 0.00096, running_loss: 0.616\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1225,   20] loss: 0.00105, running_loss: 0.675\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1226,   20] loss: 0.00069, running_loss: 0.440\n",
      "Accacy on train_loader set: 99 % [1151/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1227,   20] loss: 0.00134, running_loss: 0.861\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1228,   20] loss: 0.00088, running_loss: 0.565\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1229,   20] loss: 0.00119, running_loss: 0.761\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1230,   20] loss: 0.00138, running_loss: 0.882\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1231,   20] loss: 0.00097, running_loss: 0.624\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1232,   20] loss: 0.00126, running_loss: 0.804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[1233,   20] loss: 0.00154, running_loss: 0.985\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1234,   20] loss: 0.00103, running_loss: 0.661\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1235,   20] loss: 0.00117, running_loss: 0.750\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1236,   20] loss: 0.00144, running_loss: 0.920\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1237,   20] loss: 0.00136, running_loss: 0.871\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1238,   20] loss: 0.00114, running_loss: 0.732\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1239,   20] loss: 0.00197, running_loss: 1.258\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1240,   20] loss: 0.00183, running_loss: 1.173\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1241,   20] loss: 0.00153, running_loss: 0.980\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1242,   20] loss: 0.00131, running_loss: 0.842\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1243,   20] loss: 0.00171, running_loss: 1.097\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1244,   20] loss: 0.00131, running_loss: 0.837\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1245,   20] loss: 0.00144, running_loss: 0.921\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1246,   20] loss: 0.00124, running_loss: 0.793\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1247,   20] loss: 0.00147, running_loss: 0.943\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1248,   20] loss: 0.00124, running_loss: 0.795\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1249,   20] loss: 0.00134, running_loss: 0.859\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1250,   20] loss: 0.00146, running_loss: 0.937\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1251,   20] loss: 0.00125, running_loss: 0.803\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1252,   20] loss: 0.00142, running_loss: 0.912\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[1253,   20] loss: 0.00086, running_loss: 0.548\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1254,   20] loss: 0.00131, running_loss: 0.840\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1255,   20] loss: 0.00117, running_loss: 0.746\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1256,   20] loss: 0.00097, running_loss: 0.621\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1257,   20] loss: 0.00092, running_loss: 0.586\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1258,   20] loss: 0.00097, running_loss: 0.618\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1259,   20] loss: 0.00184, running_loss: 1.180\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1260,   20] loss: 0.00118, running_loss: 0.752\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1261,   20] loss: 0.00136, running_loss: 0.869\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1262,   20] loss: 0.00147, running_loss: 0.938\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1263,   20] loss: 0.00112, running_loss: 0.717\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1264,   20] loss: 0.00113, running_loss: 0.722\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1265,   20] loss: 0.00113, running_loss: 0.724\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1266,   20] loss: 0.00122, running_loss: 0.782\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1267,   20] loss: 0.00085, running_loss: 0.541\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1268,   20] loss: 0.00129, running_loss: 0.826\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[1269,   20] loss: 0.00109, running_loss: 0.699\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1270,   20] loss: 0.00127, running_loss: 0.813\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1271,   20] loss: 0.00097, running_loss: 0.621\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1272,   20] loss: 0.00097, running_loss: 0.619\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1273,   20] loss: 0.00087, running_loss: 0.556\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1274,   20] loss: 0.00142, running_loss: 0.910\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1275,   20] loss: 0.00116, running_loss: 0.744\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1276,   20] loss: 0.00111, running_loss: 0.708\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1277,   20] loss: 0.00117, running_loss: 0.750\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1278,   20] loss: 0.00131, running_loss: 0.841\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1279,   20] loss: 0.00105, running_loss: 0.674\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1280,   20] loss: 0.00127, running_loss: 0.815\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1281,   20] loss: 0.00095, running_loss: 0.607\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1282,   20] loss: 0.00150, running_loss: 0.959\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1283,   20] loss: 0.00148, running_loss: 0.944\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[1284,   20] loss: 0.00102, running_loss: 0.655\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1285,   20] loss: 0.00118, running_loss: 0.754\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1286,   20] loss: 0.00138, running_loss: 0.883\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1287,   20] loss: 0.00077, running_loss: 0.491\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1288,   20] loss: 0.00116, running_loss: 0.740\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1289,   20] loss: 0.00147, running_loss: 0.942\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1290,   20] loss: 0.00189, running_loss: 1.208\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1291,   20] loss: 0.00109, running_loss: 0.698\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1292,   20] loss: 0.00157, running_loss: 1.006\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1293,   20] loss: 0.00115, running_loss: 0.739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1294,   20] loss: 0.00167, running_loss: 1.072\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1295,   20] loss: 0.00147, running_loss: 0.943\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1296,   20] loss: 0.00119, running_loss: 0.761\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1297,   20] loss: 0.00086, running_loss: 0.549\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1298,   20] loss: 0.00086, running_loss: 0.553\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1299,   20] loss: 0.00094, running_loss: 0.603\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1300,   20] loss: 0.00110, running_loss: 0.706\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1301,   20] loss: 0.00123, running_loss: 0.786\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[1302,   20] loss: 0.00136, running_loss: 0.871\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1303,   20] loss: 0.00166, running_loss: 1.060\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1304,   20] loss: 0.00141, running_loss: 0.900\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1305,   20] loss: 0.00167, running_loss: 1.069\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1306,   20] loss: 0.00189, running_loss: 1.207\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1307,   20] loss: 0.00124, running_loss: 0.796\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1308,   20] loss: 0.00128, running_loss: 0.821\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1309,   20] loss: 0.00138, running_loss: 0.885\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1310,   20] loss: 0.00112, running_loss: 0.714\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1311,   20] loss: 0.00113, running_loss: 0.720\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1312,   20] loss: 0.00138, running_loss: 0.882\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1313,   20] loss: 0.00124, running_loss: 0.795\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1314,   20] loss: 0.00119, running_loss: 0.760\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1315,   20] loss: 0.00149, running_loss: 0.955\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1316,   20] loss: 0.00128, running_loss: 0.820\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1317,   20] loss: 0.00101, running_loss: 0.646\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1318,   20] loss: 0.00172, running_loss: 1.100\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1319,   20] loss: 0.00121, running_loss: 0.775\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1320,   20] loss: 0.00146, running_loss: 0.932\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1321,   20] loss: 0.00108, running_loss: 0.689\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1322,   20] loss: 0.00114, running_loss: 0.729\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[1323,   20] loss: 0.00187, running_loss: 1.194\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1324,   20] loss: 0.00131, running_loss: 0.838\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1325,   20] loss: 0.00129, running_loss: 0.824\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1326,   20] loss: 0.00111, running_loss: 0.711\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1327,   20] loss: 0.00109, running_loss: 0.695\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[1328,   20] loss: 0.00112, running_loss: 0.715\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1329,   20] loss: 0.00119, running_loss: 0.764\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[1330,   20] loss: 0.00126, running_loss: 0.805\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1331,   20] loss: 0.00178, running_loss: 1.136\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1332,   20] loss: 0.00083, running_loss: 0.530\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[1333,   20] loss: 0.00152, running_loss: 0.972\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1334,   20] loss: 0.00090, running_loss: 0.574\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1335,   20] loss: 0.00105, running_loss: 0.672\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1336,   20] loss: 0.00091, running_loss: 0.584\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[1337,   20] loss: 0.00124, running_loss: 0.796\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1338,   20] loss: 0.00126, running_loss: 0.805\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 79 % [115/144]\n",
      "[1339,   20] loss: 0.00140, running_loss: 0.894\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1340,   20] loss: 0.00171, running_loss: 1.094\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1341,   20] loss: 0.00126, running_loss: 0.804\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1342,   20] loss: 0.00149, running_loss: 0.952\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1343,   20] loss: 0.00097, running_loss: 0.618\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1344,   20] loss: 0.00100, running_loss: 0.643\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1345,   20] loss: 0.00103, running_loss: 0.656\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1346,   20] loss: 0.00160, running_loss: 1.025\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1347,   20] loss: 0.00096, running_loss: 0.613\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1348,   20] loss: 0.00173, running_loss: 1.110\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1349,   20] loss: 0.00122, running_loss: 0.784\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1350,   20] loss: 0.00138, running_loss: 0.881\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[1351,   20] loss: 0.00135, running_loss: 0.865\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1352,   20] loss: 0.00107, running_loss: 0.684\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[1353,   20] loss: 0.00151, running_loss: 0.964\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1354,   20] loss: 0.00141, running_loss: 0.904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1355,   20] loss: 0.00134, running_loss: 0.855\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1356,   20] loss: 0.00101, running_loss: 0.646\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1357,   20] loss: 0.00088, running_loss: 0.561\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1358,   20] loss: 0.00115, running_loss: 0.734\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1359,   20] loss: 0.00153, running_loss: 0.977\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1360,   20] loss: 0.00108, running_loss: 0.690\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1361,   20] loss: 0.00121, running_loss: 0.774\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1362,   20] loss: 0.00075, running_loss: 0.478\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1363,   20] loss: 0.00142, running_loss: 0.909\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1364,   20] loss: 0.00135, running_loss: 0.863\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1365,   20] loss: 0.00132, running_loss: 0.844\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1366,   20] loss: 0.00098, running_loss: 0.629\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1367,   20] loss: 0.00132, running_loss: 0.843\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1368,   20] loss: 0.00107, running_loss: 0.682\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1369,   20] loss: 0.00111, running_loss: 0.711\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1370,   20] loss: 0.00116, running_loss: 0.744\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1371,   20] loss: 0.00130, running_loss: 0.831\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1372,   20] loss: 0.00149, running_loss: 0.954\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 63 % [91/144]\n",
      "[1373,   20] loss: 0.00095, running_loss: 0.607\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[1374,   20] loss: 0.00098, running_loss: 0.627\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1375,   20] loss: 0.00149, running_loss: 0.951\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1376,   20] loss: 0.00101, running_loss: 0.647\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1377,   20] loss: 0.00102, running_loss: 0.653\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1378,   20] loss: 0.00158, running_loss: 1.011\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1379,   20] loss: 0.00124, running_loss: 0.794\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[1380,   20] loss: 0.00117, running_loss: 0.747\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1381,   20] loss: 0.00149, running_loss: 0.957\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1382,   20] loss: 0.00097, running_loss: 0.623\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[1383,   20] loss: 0.00113, running_loss: 0.722\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1384,   20] loss: 0.00131, running_loss: 0.839\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1385,   20] loss: 0.00126, running_loss: 0.808\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1386,   20] loss: 0.00129, running_loss: 0.827\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1387,   20] loss: 0.00175, running_loss: 1.117\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1388,   20] loss: 0.00163, running_loss: 1.043\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1389,   20] loss: 0.00093, running_loss: 0.592\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1390,   20] loss: 0.00132, running_loss: 0.846\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[1391,   20] loss: 0.00101, running_loss: 0.649\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1392,   20] loss: 0.00127, running_loss: 0.813\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1393,   20] loss: 0.00129, running_loss: 0.828\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1394,   20] loss: 0.00140, running_loss: 0.893\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1395,   20] loss: 0.00144, running_loss: 0.925\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1396,   20] loss: 0.00135, running_loss: 0.863\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1397,   20] loss: 0.00117, running_loss: 0.747\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1398,   20] loss: 0.00124, running_loss: 0.795\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1399,   20] loss: 0.00116, running_loss: 0.740\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1400,   20] loss: 0.00079, running_loss: 0.506\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1401,   20] loss: 0.00105, running_loss: 0.674\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1402,   20] loss: 0.00130, running_loss: 0.834\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1403,   20] loss: 0.00190, running_loss: 1.216\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1404,   20] loss: 0.00095, running_loss: 0.607\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[1405,   20] loss: 0.00080, running_loss: 0.510\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1406,   20] loss: 0.00180, running_loss: 1.154\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1407,   20] loss: 0.00076, running_loss: 0.489\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1408,   20] loss: 0.00136, running_loss: 0.869\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[1409,   20] loss: 0.00126, running_loss: 0.809\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1410,   20] loss: 0.00134, running_loss: 0.858\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1411,   20] loss: 0.00109, running_loss: 0.696\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1412,   20] loss: 0.00085, running_loss: 0.541\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[1413,   20] loss: 0.00170, running_loss: 1.088\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1414,   20] loss: 0.00193, running_loss: 1.236\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1415,   20] loss: 0.00109, running_loss: 0.699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[1416,   20] loss: 0.00117, running_loss: 0.747\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1417,   20] loss: 0.00205, running_loss: 1.314\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1418,   20] loss: 0.00089, running_loss: 0.572\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1419,   20] loss: 0.00087, running_loss: 0.558\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1420,   20] loss: 0.00115, running_loss: 0.734\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1421,   20] loss: 0.00100, running_loss: 0.642\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1422,   20] loss: 0.00117, running_loss: 0.751\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1423,   20] loss: 0.00105, running_loss: 0.672\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1424,   20] loss: 0.00119, running_loss: 0.759\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1425,   20] loss: 0.00158, running_loss: 1.009\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1426,   20] loss: 0.00147, running_loss: 0.943\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1427,   20] loss: 0.00132, running_loss: 0.845\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1428,   20] loss: 0.00118, running_loss: 0.757\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1429,   20] loss: 0.00131, running_loss: 0.837\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1430,   20] loss: 0.00089, running_loss: 0.571\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1431,   20] loss: 0.00102, running_loss: 0.653\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1432,   20] loss: 0.00125, running_loss: 0.797\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1433,   20] loss: 0.00108, running_loss: 0.690\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1434,   20] loss: 0.00097, running_loss: 0.622\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1435,   20] loss: 0.00120, running_loss: 0.768\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1436,   20] loss: 0.00111, running_loss: 0.710\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1437,   20] loss: 0.00122, running_loss: 0.782\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1438,   20] loss: 0.00101, running_loss: 0.645\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1439,   20] loss: 0.00099, running_loss: 0.633\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1440,   20] loss: 0.00147, running_loss: 0.944\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1441,   20] loss: 0.00093, running_loss: 0.598\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[1442,   20] loss: 0.00086, running_loss: 0.553\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1443,   20] loss: 0.00117, running_loss: 0.747\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[1444,   20] loss: 0.00133, running_loss: 0.851\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1445,   20] loss: 0.00089, running_loss: 0.569\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1446,   20] loss: 0.00096, running_loss: 0.617\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1447,   20] loss: 0.00167, running_loss: 1.066\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1448,   20] loss: 0.00105, running_loss: 0.675\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1449,   20] loss: 0.00129, running_loss: 0.823\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1450,   20] loss: 0.00095, running_loss: 0.608\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1451,   20] loss: 0.00105, running_loss: 0.672\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1452,   20] loss: 0.00112, running_loss: 0.718\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1453,   20] loss: 0.00132, running_loss: 0.842\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1454,   20] loss: 0.00140, running_loss: 0.894\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1455,   20] loss: 0.00097, running_loss: 0.623\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1456,   20] loss: 0.00094, running_loss: 0.605\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1457,   20] loss: 0.00106, running_loss: 0.677\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1458,   20] loss: 0.00125, running_loss: 0.802\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1459,   20] loss: 0.00126, running_loss: 0.806\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1460,   20] loss: 0.00149, running_loss: 0.952\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1461,   20] loss: 0.00149, running_loss: 0.952\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1462,   20] loss: 0.00120, running_loss: 0.767\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1463,   20] loss: 0.00119, running_loss: 0.759\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 79 % [115/144]\n",
      "[1464,   20] loss: 0.00112, running_loss: 0.714\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1465,   20] loss: 0.00140, running_loss: 0.895\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1466,   20] loss: 0.00109, running_loss: 0.694\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[1467,   20] loss: 0.00190, running_loss: 1.219\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1468,   20] loss: 0.00128, running_loss: 0.817\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1469,   20] loss: 0.00130, running_loss: 0.832\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1470,   20] loss: 0.00142, running_loss: 0.912\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1471,   20] loss: 0.00112, running_loss: 0.718\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1472,   20] loss: 0.00106, running_loss: 0.681\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[1473,   20] loss: 0.00119, running_loss: 0.762\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1474,   20] loss: 0.00132, running_loss: 0.845\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1475,   20] loss: 0.00189, running_loss: 1.208\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1476,   20] loss: 0.00188, running_loss: 1.201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1477,   20] loss: 0.00192, running_loss: 1.229\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1478,   20] loss: 0.00095, running_loss: 0.607\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[1479,   20] loss: 0.00106, running_loss: 0.680\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1480,   20] loss: 0.00109, running_loss: 0.694\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1481,   20] loss: 0.00118, running_loss: 0.752\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1482,   20] loss: 0.00133, running_loss: 0.853\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1483,   20] loss: 0.00113, running_loss: 0.723\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1484,   20] loss: 0.00116, running_loss: 0.743\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1485,   20] loss: 0.00156, running_loss: 0.998\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1486,   20] loss: 0.00089, running_loss: 0.570\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1487,   20] loss: 0.00109, running_loss: 0.698\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1488,   20] loss: 0.00164, running_loss: 1.051\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1489,   20] loss: 0.00118, running_loss: 0.755\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1490,   20] loss: 0.00124, running_loss: 0.793\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1491,   20] loss: 0.00106, running_loss: 0.678\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[1492,   20] loss: 0.00094, running_loss: 0.604\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1493,   20] loss: 0.00117, running_loss: 0.750\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1494,   20] loss: 0.00119, running_loss: 0.761\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1495,   20] loss: 0.00106, running_loss: 0.679\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1496,   20] loss: 0.00089, running_loss: 0.568\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1497,   20] loss: 0.00092, running_loss: 0.590\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1498,   20] loss: 0.00122, running_loss: 0.782\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1499,   20] loss: 0.00088, running_loss: 0.565\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1500,   20] loss: 0.00111, running_loss: 0.710\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    max_correct_rate=0.0\n",
    "    for epoch in range(1500):\n",
    "        train(epoch)\n",
    "        correct_rate=validate('eval_loader')\n",
    "        if max_correct_rate < correct_rate:\n",
    "            max_correct_rate = correct_rate\n",
    "            saveModel(model_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f1db0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7986111111111112"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4311cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   20] loss: 0.00098, running_loss: 0.627\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[2,   20] loss: 0.00125, running_loss: 0.802\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[3,   20] loss: 0.00129, running_loss: 0.828\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[4,   20] loss: 0.00165, running_loss: 1.059\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[5,   20] loss: 0.00097, running_loss: 0.619\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[6,   20] loss: 0.00181, running_loss: 1.161\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[7,   20] loss: 0.00095, running_loss: 0.605\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[8,   20] loss: 0.00136, running_loss: 0.873\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[9,   20] loss: 0.00139, running_loss: 0.888\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[10,   20] loss: 0.00152, running_loss: 0.975\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[11,   20] loss: 0.00122, running_loss: 0.778\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[12,   20] loss: 0.00117, running_loss: 0.748\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[13,   20] loss: 0.00097, running_loss: 0.624\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[14,   20] loss: 0.00137, running_loss: 0.878\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[15,   20] loss: 0.00114, running_loss: 0.731\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[16,   20] loss: 0.00106, running_loss: 0.682\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[17,   20] loss: 0.00147, running_loss: 0.941\n",
      "Accacy on train_loader set: 98 % [1131/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[18,   20] loss: 0.00098, running_loss: 0.624\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[19,   20] loss: 0.00091, running_loss: 0.586\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[20,   20] loss: 0.00076, running_loss: 0.484\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[21,   20] loss: 0.00125, running_loss: 0.803\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[22,   20] loss: 0.00118, running_loss: 0.756\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[23,   20] loss: 0.00068, running_loss: 0.436\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[24,   20] loss: 0.00101, running_loss: 0.649\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[25,   20] loss: 0.00141, running_loss: 0.904\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[26,   20] loss: 0.00171, running_loss: 1.091\n",
      "Accacy on train_loader set: 97 % [1127/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[27,   20] loss: 0.00122, running_loss: 0.782\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[28,   20] loss: 0.00141, running_loss: 0.900\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[29,   20] loss: 0.00117, running_loss: 0.747\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[30,   20] loss: 0.00079, running_loss: 0.505\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[31,   20] loss: 0.00103, running_loss: 0.657\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[32,   20] loss: 0.00117, running_loss: 0.748\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[33,   20] loss: 0.00113, running_loss: 0.721\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[34,   20] loss: 0.00121, running_loss: 0.777\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[35,   20] loss: 0.00131, running_loss: 0.839\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[36,   20] loss: 0.00120, running_loss: 0.770\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[37,   20] loss: 0.00119, running_loss: 0.760\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[38,   20] loss: 0.00081, running_loss: 0.520\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[39,   20] loss: 0.00103, running_loss: 0.658\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[40,   20] loss: 0.00111, running_loss: 0.708\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[41,   20] loss: 0.00169, running_loss: 1.082\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[42,   20] loss: 0.00141, running_loss: 0.900\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[43,   20] loss: 0.00129, running_loss: 0.824\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[44,   20] loss: 0.00141, running_loss: 0.905\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[45,   20] loss: 0.00114, running_loss: 0.730\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[46,   20] loss: 0.00131, running_loss: 0.839\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[47,   20] loss: 0.00085, running_loss: 0.544\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[48,   20] loss: 0.00100, running_loss: 0.637\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[49,   20] loss: 0.00115, running_loss: 0.734\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[50,   20] loss: 0.00152, running_loss: 0.973\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[51,   20] loss: 0.00124, running_loss: 0.795\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[52,   20] loss: 0.00104, running_loss: 0.665\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[53,   20] loss: 0.00140, running_loss: 0.897\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[54,   20] loss: 0.00103, running_loss: 0.656\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[55,   20] loss: 0.00109, running_loss: 0.695\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[56,   20] loss: 0.00142, running_loss: 0.906\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[57,   20] loss: 0.00112, running_loss: 0.719\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[58,   20] loss: 0.00164, running_loss: 1.047\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[59,   20] loss: 0.00145, running_loss: 0.931\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[60,   20] loss: 0.00118, running_loss: 0.752\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[61,   20] loss: 0.00129, running_loss: 0.825\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[62,   20] loss: 0.00115, running_loss: 0.739\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63,   20] loss: 0.00108, running_loss: 0.689\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[64,   20] loss: 0.00159, running_loss: 1.016\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[65,   20] loss: 0.00095, running_loss: 0.609\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[66,   20] loss: 0.00073, running_loss: 0.464\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[67,   20] loss: 0.00101, running_loss: 0.648\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[68,   20] loss: 0.00090, running_loss: 0.578\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[69,   20] loss: 0.00086, running_loss: 0.550\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[70,   20] loss: 0.00070, running_loss: 0.449\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[71,   20] loss: 0.00096, running_loss: 0.616\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[72,   20] loss: 0.00077, running_loss: 0.493\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[73,   20] loss: 0.00132, running_loss: 0.844\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[74,   20] loss: 0.00148, running_loss: 0.945\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[75,   20] loss: 0.00081, running_loss: 0.519\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[76,   20] loss: 0.00112, running_loss: 0.714\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[77,   20] loss: 0.00120, running_loss: 0.770\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[78,   20] loss: 0.00144, running_loss: 0.923\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[79,   20] loss: 0.00105, running_loss: 0.675\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[80,   20] loss: 0.00126, running_loss: 0.806\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[81,   20] loss: 0.00075, running_loss: 0.480\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[82,   20] loss: 0.00111, running_loss: 0.709\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[83,   20] loss: 0.00105, running_loss: 0.674\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[84,   20] loss: 0.00099, running_loss: 0.636\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[85,   20] loss: 0.00102, running_loss: 0.652\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[86,   20] loss: 0.00114, running_loss: 0.731\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[87,   20] loss: 0.00084, running_loss: 0.541\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[88,   20] loss: 0.00140, running_loss: 0.895\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[89,   20] loss: 0.00097, running_loss: 0.619\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[90,   20] loss: 0.00114, running_loss: 0.727\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[91,   20] loss: 0.00155, running_loss: 0.992\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[92,   20] loss: 0.00111, running_loss: 0.713\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[93,   20] loss: 0.00097, running_loss: 0.623\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[94,   20] loss: 0.00143, running_loss: 0.913\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[95,   20] loss: 0.00144, running_loss: 0.924\n",
      "Accacy on train_loader set: 98 % [1130/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[96,   20] loss: 0.00122, running_loss: 0.783\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[97,   20] loss: 0.00202, running_loss: 1.295\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[98,   20] loss: 0.00141, running_loss: 0.900\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[99,   20] loss: 0.00138, running_loss: 0.884\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[100,   20] loss: 0.00109, running_loss: 0.698\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[101,   20] loss: 0.00143, running_loss: 0.912\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[102,   20] loss: 0.00114, running_loss: 0.730\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[103,   20] loss: 0.00134, running_loss: 0.860\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[104,   20] loss: 0.00076, running_loss: 0.489\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[105,   20] loss: 0.00138, running_loss: 0.881\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[106,   20] loss: 0.00103, running_loss: 0.657\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[107,   20] loss: 0.00106, running_loss: 0.680\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[108,   20] loss: 0.00125, running_loss: 0.798\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[109,   20] loss: 0.00101, running_loss: 0.648\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[110,   20] loss: 0.00204, running_loss: 1.305\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[111,   20] loss: 0.00087, running_loss: 0.556\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[112,   20] loss: 0.00079, running_loss: 0.505\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[113,   20] loss: 0.00148, running_loss: 0.947\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[114,   20] loss: 0.00116, running_loss: 0.743\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[115,   20] loss: 0.00121, running_loss: 0.777\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[116,   20] loss: 0.00121, running_loss: 0.771\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[117,   20] loss: 0.00075, running_loss: 0.480\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[118,   20] loss: 0.00091, running_loss: 0.584\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[119,   20] loss: 0.00159, running_loss: 1.016\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[120,   20] loss: 0.00095, running_loss: 0.605\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[121,   20] loss: 0.00113, running_loss: 0.722\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[122,   20] loss: 0.00085, running_loss: 0.545\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[123,   20] loss: 0.00132, running_loss: 0.844\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[124,   20] loss: 0.00115, running_loss: 0.737\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125,   20] loss: 0.00111, running_loss: 0.713\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[126,   20] loss: 0.00110, running_loss: 0.703\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[127,   20] loss: 0.00077, running_loss: 0.495\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[128,   20] loss: 0.00097, running_loss: 0.623\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[129,   20] loss: 0.00108, running_loss: 0.690\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[130,   20] loss: 0.00127, running_loss: 0.814\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[131,   20] loss: 0.00127, running_loss: 0.810\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[132,   20] loss: 0.00115, running_loss: 0.737\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[133,   20] loss: 0.00108, running_loss: 0.690\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[134,   20] loss: 0.00087, running_loss: 0.557\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[135,   20] loss: 0.00125, running_loss: 0.798\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[136,   20] loss: 0.00128, running_loss: 0.821\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[137,   20] loss: 0.00110, running_loss: 0.707\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[138,   20] loss: 0.00123, running_loss: 0.788\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[139,   20] loss: 0.00176, running_loss: 1.129\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[140,   20] loss: 0.00103, running_loss: 0.658\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[141,   20] loss: 0.00107, running_loss: 0.687\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[142,   20] loss: 0.00108, running_loss: 0.694\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[143,   20] loss: 0.00123, running_loss: 0.790\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[144,   20] loss: 0.00109, running_loss: 0.695\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[145,   20] loss: 0.00097, running_loss: 0.618\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[146,   20] loss: 0.00102, running_loss: 0.653\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[147,   20] loss: 0.00131, running_loss: 0.836\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[148,   20] loss: 0.00178, running_loss: 1.138\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[149,   20] loss: 0.00098, running_loss: 0.629\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[150,   20] loss: 0.00099, running_loss: 0.632\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[151,   20] loss: 0.00125, running_loss: 0.801\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[152,   20] loss: 0.00136, running_loss: 0.870\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[153,   20] loss: 0.00102, running_loss: 0.653\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[154,   20] loss: 0.00142, running_loss: 0.906\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[155,   20] loss: 0.00140, running_loss: 0.897\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[156,   20] loss: 0.00081, running_loss: 0.517\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[157,   20] loss: 0.00100, running_loss: 0.643\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[158,   20] loss: 0.00128, running_loss: 0.822\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[159,   20] loss: 0.00119, running_loss: 0.764\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[160,   20] loss: 0.00099, running_loss: 0.633\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[161,   20] loss: 0.00137, running_loss: 0.876\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[162,   20] loss: 0.00145, running_loss: 0.928\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[163,   20] loss: 0.00078, running_loss: 0.498\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[164,   20] loss: 0.00136, running_loss: 0.871\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[165,   20] loss: 0.00146, running_loss: 0.934\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[166,   20] loss: 0.00138, running_loss: 0.886\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[167,   20] loss: 0.00108, running_loss: 0.694\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[168,   20] loss: 0.00119, running_loss: 0.764\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[169,   20] loss: 0.00147, running_loss: 0.944\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[170,   20] loss: 0.00114, running_loss: 0.728\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[171,   20] loss: 0.00089, running_loss: 0.567\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[172,   20] loss: 0.00085, running_loss: 0.541\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[173,   20] loss: 0.00127, running_loss: 0.814\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[174,   20] loss: 0.00182, running_loss: 1.162\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[175,   20] loss: 0.00128, running_loss: 0.819\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[176,   20] loss: 0.00088, running_loss: 0.561\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[177,   20] loss: 0.00119, running_loss: 0.763\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[178,   20] loss: 0.00168, running_loss: 1.078\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[179,   20] loss: 0.00100, running_loss: 0.641\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[180,   20] loss: 0.00125, running_loss: 0.799\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[181,   20] loss: 0.00115, running_loss: 0.737\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[182,   20] loss: 0.00136, running_loss: 0.867\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[183,   20] loss: 0.00115, running_loss: 0.737\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[184,   20] loss: 0.00108, running_loss: 0.690\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[185,   20] loss: 0.00155, running_loss: 0.992\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[186,   20] loss: 0.00123, running_loss: 0.786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[187,   20] loss: 0.00117, running_loss: 0.750\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[188,   20] loss: 0.00102, running_loss: 0.655\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[189,   20] loss: 0.00127, running_loss: 0.812\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[190,   20] loss: 0.00101, running_loss: 0.648\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[191,   20] loss: 0.00171, running_loss: 1.092\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[192,   20] loss: 0.00111, running_loss: 0.709\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[193,   20] loss: 0.00089, running_loss: 0.567\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[194,   20] loss: 0.00088, running_loss: 0.565\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[195,   20] loss: 0.00129, running_loss: 0.824\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[196,   20] loss: 0.00119, running_loss: 0.760\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[197,   20] loss: 0.00099, running_loss: 0.631\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[198,   20] loss: 0.00133, running_loss: 0.852\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[199,   20] loss: 0.00096, running_loss: 0.612\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[200,   20] loss: 0.00119, running_loss: 0.761\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[201,   20] loss: 0.00123, running_loss: 0.786\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[202,   20] loss: 0.00101, running_loss: 0.644\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[203,   20] loss: 0.00106, running_loss: 0.676\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[204,   20] loss: 0.00112, running_loss: 0.717\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[205,   20] loss: 0.00130, running_loss: 0.834\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[206,   20] loss: 0.00084, running_loss: 0.539\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[207,   20] loss: 0.00122, running_loss: 0.779\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[208,   20] loss: 0.00142, running_loss: 0.908\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[209,   20] loss: 0.00118, running_loss: 0.752\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[210,   20] loss: 0.00103, running_loss: 0.662\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[211,   20] loss: 0.00129, running_loss: 0.825\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[212,   20] loss: 0.00102, running_loss: 0.653\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[213,   20] loss: 0.00145, running_loss: 0.929\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[214,   20] loss: 0.00151, running_loss: 0.964\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[215,   20] loss: 0.00150, running_loss: 0.958\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[216,   20] loss: 0.00109, running_loss: 0.698\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[217,   20] loss: 0.00093, running_loss: 0.596\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[218,   20] loss: 0.00137, running_loss: 0.876\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[219,   20] loss: 0.00097, running_loss: 0.621\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[220,   20] loss: 0.00092, running_loss: 0.590\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[221,   20] loss: 0.00091, running_loss: 0.585\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[222,   20] loss: 0.00139, running_loss: 0.887\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[223,   20] loss: 0.00077, running_loss: 0.491\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[224,   20] loss: 0.00149, running_loss: 0.955\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[225,   20] loss: 0.00127, running_loss: 0.815\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[226,   20] loss: 0.00113, running_loss: 0.722\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[227,   20] loss: 0.00107, running_loss: 0.686\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[228,   20] loss: 0.00110, running_loss: 0.704\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[229,   20] loss: 0.00112, running_loss: 0.719\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[230,   20] loss: 0.00123, running_loss: 0.789\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[231,   20] loss: 0.00112, running_loss: 0.720\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[232,   20] loss: 0.00124, running_loss: 0.792\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[233,   20] loss: 0.00128, running_loss: 0.818\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[234,   20] loss: 0.00121, running_loss: 0.776\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[235,   20] loss: 0.00178, running_loss: 1.140\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[236,   20] loss: 0.00124, running_loss: 0.796\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[237,   20] loss: 0.00124, running_loss: 0.792\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[238,   20] loss: 0.00099, running_loss: 0.634\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[239,   20] loss: 0.00137, running_loss: 0.874\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[240,   20] loss: 0.00087, running_loss: 0.559\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[241,   20] loss: 0.00085, running_loss: 0.545\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[242,   20] loss: 0.00132, running_loss: 0.844\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[243,   20] loss: 0.00128, running_loss: 0.817\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[244,   20] loss: 0.00105, running_loss: 0.670\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[245,   20] loss: 0.00098, running_loss: 0.624\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[246,   20] loss: 0.00076, running_loss: 0.485\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[247,   20] loss: 0.00118, running_loss: 0.754\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[248,   20] loss: 0.00096, running_loss: 0.615\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[249,   20] loss: 0.00135, running_loss: 0.866\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[250,   20] loss: 0.00097, running_loss: 0.618\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[251,   20] loss: 0.00125, running_loss: 0.797\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[252,   20] loss: 0.00096, running_loss: 0.614\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[253,   20] loss: 0.00102, running_loss: 0.650\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[254,   20] loss: 0.00083, running_loss: 0.532\n",
      "Accacy on train_loader set: 99 % [1151/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[255,   20] loss: 0.00117, running_loss: 0.751\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[256,   20] loss: 0.00147, running_loss: 0.940\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[257,   20] loss: 0.00121, running_loss: 0.774\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[258,   20] loss: 0.00103, running_loss: 0.657\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[259,   20] loss: 0.00119, running_loss: 0.763\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[260,   20] loss: 0.00144, running_loss: 0.923\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[261,   20] loss: 0.00117, running_loss: 0.749\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[262,   20] loss: 0.00082, running_loss: 0.526\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[263,   20] loss: 0.00106, running_loss: 0.680\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[264,   20] loss: 0.00094, running_loss: 0.604\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[265,   20] loss: 0.00112, running_loss: 0.720\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[266,   20] loss: 0.00105, running_loss: 0.674\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[267,   20] loss: 0.00106, running_loss: 0.679\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[268,   20] loss: 0.00172, running_loss: 1.104\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[269,   20] loss: 0.00100, running_loss: 0.638\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[270,   20] loss: 0.00118, running_loss: 0.758\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[271,   20] loss: 0.00104, running_loss: 0.667\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[272,   20] loss: 0.00120, running_loss: 0.771\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[273,   20] loss: 0.00115, running_loss: 0.737\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[274,   20] loss: 0.00108, running_loss: 0.690\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[275,   20] loss: 0.00089, running_loss: 0.572\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[276,   20] loss: 0.00092, running_loss: 0.589\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[277,   20] loss: 0.00063, running_loss: 0.401\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[278,   20] loss: 0.00102, running_loss: 0.656\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[279,   20] loss: 0.00081, running_loss: 0.518\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[280,   20] loss: 0.00126, running_loss: 0.808\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[281,   20] loss: 0.00119, running_loss: 0.763\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[282,   20] loss: 0.00144, running_loss: 0.924\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[283,   20] loss: 0.00104, running_loss: 0.666\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[284,   20] loss: 0.00086, running_loss: 0.548\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[285,   20] loss: 0.00147, running_loss: 0.942\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[286,   20] loss: 0.00119, running_loss: 0.764\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[287,   20] loss: 0.00110, running_loss: 0.703\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[288,   20] loss: 0.00119, running_loss: 0.760\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[289,   20] loss: 0.00106, running_loss: 0.676\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[290,   20] loss: 0.00086, running_loss: 0.551\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[291,   20] loss: 0.00146, running_loss: 0.936\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[292,   20] loss: 0.00090, running_loss: 0.577\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[293,   20] loss: 0.00107, running_loss: 0.685\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[294,   20] loss: 0.00114, running_loss: 0.728\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[295,   20] loss: 0.00103, running_loss: 0.659\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[296,   20] loss: 0.00141, running_loss: 0.900\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[297,   20] loss: 0.00109, running_loss: 0.695\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[298,   20] loss: 0.00138, running_loss: 0.884\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[299,   20] loss: 0.00144, running_loss: 0.922\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[300,   20] loss: 0.00131, running_loss: 0.841\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[301,   20] loss: 0.00122, running_loss: 0.781\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[302,   20] loss: 0.00106, running_loss: 0.676\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[303,   20] loss: 0.00107, running_loss: 0.684\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[304,   20] loss: 0.00115, running_loss: 0.734\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[305,   20] loss: 0.00100, running_loss: 0.638\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[306,   20] loss: 0.00132, running_loss: 0.846\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[307,   20] loss: 0.00131, running_loss: 0.840\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[308,   20] loss: 0.00128, running_loss: 0.821\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[309,   20] loss: 0.00087, running_loss: 0.554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[310,   20] loss: 0.00161, running_loss: 1.028\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[311,   20] loss: 0.00105, running_loss: 0.674\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[312,   20] loss: 0.00093, running_loss: 0.594\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[313,   20] loss: 0.00070, running_loss: 0.450\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[314,   20] loss: 0.00087, running_loss: 0.554\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[315,   20] loss: 0.00122, running_loss: 0.780\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[316,   20] loss: 0.00107, running_loss: 0.683\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[317,   20] loss: 0.00099, running_loss: 0.632\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[318,   20] loss: 0.00092, running_loss: 0.591\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[319,   20] loss: 0.00092, running_loss: 0.591\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[320,   20] loss: 0.00075, running_loss: 0.478\n",
      "Accacy on train_loader set: 99 % [1150/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[321,   20] loss: 0.00084, running_loss: 0.536\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[322,   20] loss: 0.00121, running_loss: 0.771\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[323,   20] loss: 0.00076, running_loss: 0.487\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[324,   20] loss: 0.00130, running_loss: 0.831\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[325,   20] loss: 0.00193, running_loss: 1.237\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[326,   20] loss: 0.00111, running_loss: 0.713\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[327,   20] loss: 0.00103, running_loss: 0.658\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[328,   20] loss: 0.00097, running_loss: 0.622\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[329,   20] loss: 0.00128, running_loss: 0.818\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[330,   20] loss: 0.00101, running_loss: 0.647\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[331,   20] loss: 0.00097, running_loss: 0.623\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[332,   20] loss: 0.00063, running_loss: 0.406\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[333,   20] loss: 0.00110, running_loss: 0.703\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[334,   20] loss: 0.00107, running_loss: 0.685\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[335,   20] loss: 0.00167, running_loss: 1.069\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[336,   20] loss: 0.00098, running_loss: 0.628\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[337,   20] loss: 0.00124, running_loss: 0.792\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[338,   20] loss: 0.00118, running_loss: 0.752\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[339,   20] loss: 0.00112, running_loss: 0.717\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[340,   20] loss: 0.00143, running_loss: 0.914\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[341,   20] loss: 0.00110, running_loss: 0.704\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[342,   20] loss: 0.00106, running_loss: 0.681\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[343,   20] loss: 0.00092, running_loss: 0.586\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[344,   20] loss: 0.00132, running_loss: 0.844\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[345,   20] loss: 0.00091, running_loss: 0.583\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[346,   20] loss: 0.00082, running_loss: 0.527\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[347,   20] loss: 0.00141, running_loss: 0.904\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[348,   20] loss: 0.00075, running_loss: 0.481\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[349,   20] loss: 0.00076, running_loss: 0.487\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[350,   20] loss: 0.00130, running_loss: 0.834\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[351,   20] loss: 0.00101, running_loss: 0.649\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[352,   20] loss: 0.00070, running_loss: 0.451\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[353,   20] loss: 0.00147, running_loss: 0.942\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[354,   20] loss: 0.00091, running_loss: 0.584\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[355,   20] loss: 0.00113, running_loss: 0.726\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[356,   20] loss: 0.00085, running_loss: 0.544\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[357,   20] loss: 0.00132, running_loss: 0.842\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[358,   20] loss: 0.00083, running_loss: 0.528\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[359,   20] loss: 0.00085, running_loss: 0.546\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[360,   20] loss: 0.00090, running_loss: 0.574\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[361,   20] loss: 0.00078, running_loss: 0.498\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[362,   20] loss: 0.00103, running_loss: 0.661\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[363,   20] loss: 0.00116, running_loss: 0.741\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[364,   20] loss: 0.00147, running_loss: 0.942\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[365,   20] loss: 0.00106, running_loss: 0.681\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[366,   20] loss: 0.00109, running_loss: 0.699\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[367,   20] loss: 0.00129, running_loss: 0.825\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[368,   20] loss: 0.00106, running_loss: 0.676\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[369,   20] loss: 0.00080, running_loss: 0.510\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[370,   20] loss: 0.00096, running_loss: 0.614\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[371,   20] loss: 0.00071, running_loss: 0.455\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[372,   20] loss: 0.00123, running_loss: 0.790\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[373,   20] loss: 0.00124, running_loss: 0.795\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[374,   20] loss: 0.00076, running_loss: 0.483\n",
      "Accacy on train_loader set: 99 % [1150/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[375,   20] loss: 0.00128, running_loss: 0.817\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[376,   20] loss: 0.00103, running_loss: 0.662\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[377,   20] loss: 0.00085, running_loss: 0.544\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[378,   20] loss: 0.00126, running_loss: 0.804\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[379,   20] loss: 0.00081, running_loss: 0.520\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[380,   20] loss: 0.00184, running_loss: 1.176\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[381,   20] loss: 0.00103, running_loss: 0.658\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[382,   20] loss: 0.00088, running_loss: 0.565\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[383,   20] loss: 0.00116, running_loss: 0.744\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[384,   20] loss: 0.00089, running_loss: 0.568\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[385,   20] loss: 0.00087, running_loss: 0.557\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[386,   20] loss: 0.00111, running_loss: 0.711\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[387,   20] loss: 0.00105, running_loss: 0.672\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[388,   20] loss: 0.00148, running_loss: 0.945\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[389,   20] loss: 0.00094, running_loss: 0.603\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[390,   20] loss: 0.00101, running_loss: 0.648\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[391,   20] loss: 0.00090, running_loss: 0.575\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[392,   20] loss: 0.00107, running_loss: 0.687\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[393,   20] loss: 0.00094, running_loss: 0.600\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[394,   20] loss: 0.00108, running_loss: 0.691\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[395,   20] loss: 0.00100, running_loss: 0.639\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[396,   20] loss: 0.00103, running_loss: 0.661\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[397,   20] loss: 0.00090, running_loss: 0.575\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[398,   20] loss: 0.00168, running_loss: 1.075\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[399,   20] loss: 0.00153, running_loss: 0.978\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[400,   20] loss: 0.00092, running_loss: 0.590\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[401,   20] loss: 0.00084, running_loss: 0.538\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[402,   20] loss: 0.00098, running_loss: 0.625\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[403,   20] loss: 0.00091, running_loss: 0.580\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[404,   20] loss: 0.00082, running_loss: 0.526\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[405,   20] loss: 0.00077, running_loss: 0.494\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[406,   20] loss: 0.00070, running_loss: 0.450\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[407,   20] loss: 0.00165, running_loss: 1.057\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[408,   20] loss: 0.00141, running_loss: 0.903\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[409,   20] loss: 0.00100, running_loss: 0.641\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[410,   20] loss: 0.00128, running_loss: 0.821\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[411,   20] loss: 0.00106, running_loss: 0.679\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[412,   20] loss: 0.00105, running_loss: 0.669\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[413,   20] loss: 0.00086, running_loss: 0.552\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[414,   20] loss: 0.00084, running_loss: 0.536\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[415,   20] loss: 0.00127, running_loss: 0.814\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 65 % [95/144]\n",
      "[416,   20] loss: 0.00105, running_loss: 0.672\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[417,   20] loss: 0.00108, running_loss: 0.691\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[418,   20] loss: 0.00131, running_loss: 0.840\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[419,   20] loss: 0.00061, running_loss: 0.392\n",
      "Accacy on train_loader set: 99 % [1150/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[420,   20] loss: 0.00147, running_loss: 0.942\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[421,   20] loss: 0.00096, running_loss: 0.615\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[422,   20] loss: 0.00108, running_loss: 0.692\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[423,   20] loss: 0.00094, running_loss: 0.600\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[424,   20] loss: 0.00099, running_loss: 0.633\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[425,   20] loss: 0.00148, running_loss: 0.947\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[426,   20] loss: 0.00101, running_loss: 0.647\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[427,   20] loss: 0.00145, running_loss: 0.931\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[428,   20] loss: 0.00142, running_loss: 0.908\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[429,   20] loss: 0.00130, running_loss: 0.835\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[430,   20] loss: 0.00105, running_loss: 0.674\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[431,   20] loss: 0.00148, running_loss: 0.945\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[432,   20] loss: 0.00119, running_loss: 0.762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[433,   20] loss: 0.00072, running_loss: 0.459\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[434,   20] loss: 0.00090, running_loss: 0.575\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[435,   20] loss: 0.00131, running_loss: 0.837\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[436,   20] loss: 0.00137, running_loss: 0.879\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[437,   20] loss: 0.00123, running_loss: 0.789\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[438,   20] loss: 0.00148, running_loss: 0.949\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[439,   20] loss: 0.00128, running_loss: 0.818\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[440,   20] loss: 0.00101, running_loss: 0.646\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[441,   20] loss: 0.00088, running_loss: 0.562\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[442,   20] loss: 0.00070, running_loss: 0.450\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[443,   20] loss: 0.00094, running_loss: 0.599\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[444,   20] loss: 0.00116, running_loss: 0.744\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[445,   20] loss: 0.00140, running_loss: 0.896\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[446,   20] loss: 0.00073, running_loss: 0.470\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[447,   20] loss: 0.00097, running_loss: 0.619\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[448,   20] loss: 0.00105, running_loss: 0.672\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[449,   20] loss: 0.00153, running_loss: 0.976\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[450,   20] loss: 0.00152, running_loss: 0.975\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[451,   20] loss: 0.00079, running_loss: 0.505\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[452,   20] loss: 0.00113, running_loss: 0.726\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[453,   20] loss: 0.00079, running_loss: 0.505\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[454,   20] loss: 0.00143, running_loss: 0.913\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[455,   20] loss: 0.00120, running_loss: 0.769\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[456,   20] loss: 0.00143, running_loss: 0.916\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[457,   20] loss: 0.00097, running_loss: 0.619\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[458,   20] loss: 0.00148, running_loss: 0.948\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[459,   20] loss: 0.00113, running_loss: 0.720\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[460,   20] loss: 0.00109, running_loss: 0.699\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[461,   20] loss: 0.00069, running_loss: 0.441\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[462,   20] loss: 0.00113, running_loss: 0.721\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[463,   20] loss: 0.00101, running_loss: 0.644\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[464,   20] loss: 0.00137, running_loss: 0.878\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[465,   20] loss: 0.00119, running_loss: 0.765\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[466,   20] loss: 0.00152, running_loss: 0.974\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[467,   20] loss: 0.00115, running_loss: 0.738\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[468,   20] loss: 0.00084, running_loss: 0.537\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[469,   20] loss: 0.00095, running_loss: 0.606\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[470,   20] loss: 0.00093, running_loss: 0.597\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[471,   20] loss: 0.00145, running_loss: 0.929\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[472,   20] loss: 0.00114, running_loss: 0.732\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[473,   20] loss: 0.00138, running_loss: 0.881\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[474,   20] loss: 0.00095, running_loss: 0.607\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[475,   20] loss: 0.00143, running_loss: 0.916\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[476,   20] loss: 0.00110, running_loss: 0.702\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 66 % [96/144]\n",
      "[477,   20] loss: 0.00102, running_loss: 0.654\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[478,   20] loss: 0.00071, running_loss: 0.455\n",
      "Accacy on train_loader set: 99 % [1150/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[479,   20] loss: 0.00077, running_loss: 0.491\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[480,   20] loss: 0.00113, running_loss: 0.725\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[481,   20] loss: 0.00179, running_loss: 1.145\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[482,   20] loss: 0.00117, running_loss: 0.748\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[483,   20] loss: 0.00128, running_loss: 0.821\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[484,   20] loss: 0.00144, running_loss: 0.922\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[485,   20] loss: 0.00099, running_loss: 0.633\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[486,   20] loss: 0.00128, running_loss: 0.819\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[487,   20] loss: 0.00088, running_loss: 0.562\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[488,   20] loss: 0.00108, running_loss: 0.694\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[489,   20] loss: 0.00096, running_loss: 0.613\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[490,   20] loss: 0.00091, running_loss: 0.585\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[491,   20] loss: 0.00138, running_loss: 0.882\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[492,   20] loss: 0.00156, running_loss: 0.998\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[493,   20] loss: 0.00093, running_loss: 0.598\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[494,   20] loss: 0.00165, running_loss: 1.054\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[495,   20] loss: 0.00134, running_loss: 0.857\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[496,   20] loss: 0.00144, running_loss: 0.921\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[497,   20] loss: 0.00123, running_loss: 0.787\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[498,   20] loss: 0.00098, running_loss: 0.625\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[499,   20] loss: 0.00109, running_loss: 0.697\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[500,   20] loss: 0.00096, running_loss: 0.617\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[501,   20] loss: 0.00082, running_loss: 0.522\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[502,   20] loss: 0.00088, running_loss: 0.565\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[503,   20] loss: 0.00111, running_loss: 0.712\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[504,   20] loss: 0.00086, running_loss: 0.551\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[505,   20] loss: 0.00126, running_loss: 0.805\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[506,   20] loss: 0.00084, running_loss: 0.538\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[507,   20] loss: 0.00086, running_loss: 0.551\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[508,   20] loss: 0.00086, running_loss: 0.549\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[509,   20] loss: 0.00128, running_loss: 0.822\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[510,   20] loss: 0.00080, running_loss: 0.512\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[511,   20] loss: 0.00110, running_loss: 0.701\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[512,   20] loss: 0.00100, running_loss: 0.643\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[513,   20] loss: 0.00105, running_loss: 0.671\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[514,   20] loss: 0.00087, running_loss: 0.557\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[515,   20] loss: 0.00113, running_loss: 0.726\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[516,   20] loss: 0.00097, running_loss: 0.619\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[517,   20] loss: 0.00092, running_loss: 0.588\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[518,   20] loss: 0.00113, running_loss: 0.726\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[519,   20] loss: 0.00127, running_loss: 0.811\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[520,   20] loss: 0.00111, running_loss: 0.709\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[521,   20] loss: 0.00120, running_loss: 0.766\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[522,   20] loss: 0.00117, running_loss: 0.749\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[523,   20] loss: 0.00081, running_loss: 0.517\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[524,   20] loss: 0.00074, running_loss: 0.472\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[525,   20] loss: 0.00083, running_loss: 0.533\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 80 % [116/144]\n",
      "[526,   20] loss: 0.00100, running_loss: 0.643\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[527,   20] loss: 0.00081, running_loss: 0.519\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[528,   20] loss: 0.00110, running_loss: 0.707\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[529,   20] loss: 0.00108, running_loss: 0.693\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[530,   20] loss: 0.00130, running_loss: 0.835\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[531,   20] loss: 0.00106, running_loss: 0.679\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[532,   20] loss: 0.00138, running_loss: 0.882\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[533,   20] loss: 0.00111, running_loss: 0.709\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[534,   20] loss: 0.00106, running_loss: 0.678\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[535,   20] loss: 0.00123, running_loss: 0.784\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[536,   20] loss: 0.00132, running_loss: 0.844\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[537,   20] loss: 0.00067, running_loss: 0.432\n",
      "Accacy on train_loader set: 99 % [1151/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[538,   20] loss: 0.00069, running_loss: 0.441\n",
      "Accacy on train_loader set: 99 % [1150/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[539,   20] loss: 0.00114, running_loss: 0.730\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[540,   20] loss: 0.00088, running_loss: 0.566\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[541,   20] loss: 0.00124, running_loss: 0.795\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[542,   20] loss: 0.00114, running_loss: 0.732\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[543,   20] loss: 0.00093, running_loss: 0.598\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[544,   20] loss: 0.00093, running_loss: 0.593\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[545,   20] loss: 0.00098, running_loss: 0.629\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[546,   20] loss: 0.00124, running_loss: 0.791\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[547,   20] loss: 0.00112, running_loss: 0.714\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[548,   20] loss: 0.00135, running_loss: 0.866\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[549,   20] loss: 0.00087, running_loss: 0.555\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[550,   20] loss: 0.00123, running_loss: 0.786\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[551,   20] loss: 0.00143, running_loss: 0.913\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[552,   20] loss: 0.00131, running_loss: 0.837\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[553,   20] loss: 0.00105, running_loss: 0.675\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 62 % [90/144]\n",
      "[554,   20] loss: 0.00076, running_loss: 0.484\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[555,   20] loss: 0.00101, running_loss: 0.644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[556,   20] loss: 0.00104, running_loss: 0.667\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[557,   20] loss: 0.00083, running_loss: 0.529\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[558,   20] loss: 0.00157, running_loss: 1.005\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[559,   20] loss: 0.00090, running_loss: 0.578\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[560,   20] loss: 0.00134, running_loss: 0.858\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[561,   20] loss: 0.00107, running_loss: 0.683\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[562,   20] loss: 0.00102, running_loss: 0.655\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[563,   20] loss: 0.00121, running_loss: 0.773\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[564,   20] loss: 0.00107, running_loss: 0.686\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[565,   20] loss: 0.00137, running_loss: 0.878\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[566,   20] loss: 0.00113, running_loss: 0.724\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[567,   20] loss: 0.00096, running_loss: 0.617\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[568,   20] loss: 0.00093, running_loss: 0.597\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[569,   20] loss: 0.00119, running_loss: 0.760\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[570,   20] loss: 0.00111, running_loss: 0.711\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[571,   20] loss: 0.00082, running_loss: 0.524\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[572,   20] loss: 0.00089, running_loss: 0.567\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[573,   20] loss: 0.00062, running_loss: 0.398\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[574,   20] loss: 0.00113, running_loss: 0.725\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[575,   20] loss: 0.00096, running_loss: 0.614\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[576,   20] loss: 0.00076, running_loss: 0.488\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[577,   20] loss: 0.00093, running_loss: 0.597\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[578,   20] loss: 0.00116, running_loss: 0.745\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[579,   20] loss: 0.00086, running_loss: 0.548\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[580,   20] loss: 0.00117, running_loss: 0.746\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[581,   20] loss: 0.00108, running_loss: 0.688\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[582,   20] loss: 0.00102, running_loss: 0.655\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[583,   20] loss: 0.00125, running_loss: 0.801\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[584,   20] loss: 0.00098, running_loss: 0.625\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[585,   20] loss: 0.00093, running_loss: 0.593\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[586,   20] loss: 0.00105, running_loss: 0.671\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[587,   20] loss: 0.00148, running_loss: 0.950\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[588,   20] loss: 0.00122, running_loss: 0.784\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[589,   20] loss: 0.00080, running_loss: 0.514\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[590,   20] loss: 0.00099, running_loss: 0.636\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[591,   20] loss: 0.00121, running_loss: 0.771\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[592,   20] loss: 0.00111, running_loss: 0.710\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[593,   20] loss: 0.00166, running_loss: 1.064\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[594,   20] loss: 0.00115, running_loss: 0.737\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[595,   20] loss: 0.00083, running_loss: 0.528\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[596,   20] loss: 0.00149, running_loss: 0.955\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[597,   20] loss: 0.00101, running_loss: 0.644\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[598,   20] loss: 0.00088, running_loss: 0.561\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[599,   20] loss: 0.00060, running_loss: 0.386\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[600,   20] loss: 0.00142, running_loss: 0.912\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[601,   20] loss: 0.00090, running_loss: 0.573\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 63 % [92/144]\n",
      "[602,   20] loss: 0.00105, running_loss: 0.671\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[603,   20] loss: 0.00114, running_loss: 0.732\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[604,   20] loss: 0.00122, running_loss: 0.779\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[605,   20] loss: 0.00109, running_loss: 0.695\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[606,   20] loss: 0.00150, running_loss: 0.959\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[607,   20] loss: 0.00096, running_loss: 0.615\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[608,   20] loss: 0.00133, running_loss: 0.848\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[609,   20] loss: 0.00117, running_loss: 0.748\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[610,   20] loss: 0.00115, running_loss: 0.738\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[611,   20] loss: 0.00133, running_loss: 0.849\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[612,   20] loss: 0.00077, running_loss: 0.494\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[613,   20] loss: 0.00079, running_loss: 0.508\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 81 % [117/144]\n",
      "[614,   20] loss: 0.00082, running_loss: 0.526\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[615,   20] loss: 0.00149, running_loss: 0.956\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[616,   20] loss: 0.00089, running_loss: 0.568\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[617,   20] loss: 0.00088, running_loss: 0.565\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[618,   20] loss: 0.00084, running_loss: 0.536\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[619,   20] loss: 0.00130, running_loss: 0.831\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[620,   20] loss: 0.00096, running_loss: 0.615\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[621,   20] loss: 0.00069, running_loss: 0.444\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[622,   20] loss: 0.00083, running_loss: 0.534\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[623,   20] loss: 0.00092, running_loss: 0.587\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[624,   20] loss: 0.00125, running_loss: 0.800\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[625,   20] loss: 0.00166, running_loss: 1.065\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[626,   20] loss: 0.00118, running_loss: 0.753\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[627,   20] loss: 0.00131, running_loss: 0.839\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[628,   20] loss: 0.00067, running_loss: 0.431\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[629,   20] loss: 0.00115, running_loss: 0.735\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[630,   20] loss: 0.00073, running_loss: 0.465\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 80 % [116/144]\n",
      "[631,   20] loss: 0.00084, running_loss: 0.537\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[632,   20] loss: 0.00108, running_loss: 0.689\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[633,   20] loss: 0.00120, running_loss: 0.768\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[634,   20] loss: 0.00133, running_loss: 0.850\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[635,   20] loss: 0.00154, running_loss: 0.983\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[636,   20] loss: 0.00132, running_loss: 0.842\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[637,   20] loss: 0.00102, running_loss: 0.655\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[638,   20] loss: 0.00087, running_loss: 0.555\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[639,   20] loss: 0.00118, running_loss: 0.758\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 79 % [115/144]\n",
      "[640,   20] loss: 0.00119, running_loss: 0.763\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[641,   20] loss: 0.00119, running_loss: 0.762\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[642,   20] loss: 0.00125, running_loss: 0.799\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[643,   20] loss: 0.00100, running_loss: 0.642\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[644,   20] loss: 0.00128, running_loss: 0.817\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[645,   20] loss: 0.00091, running_loss: 0.584\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[646,   20] loss: 0.00107, running_loss: 0.685\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[647,   20] loss: 0.00099, running_loss: 0.631\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[648,   20] loss: 0.00082, running_loss: 0.523\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[649,   20] loss: 0.00094, running_loss: 0.602\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 80 % [116/144]\n",
      "[650,   20] loss: 0.00098, running_loss: 0.630\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[651,   20] loss: 0.00073, running_loss: 0.465\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[652,   20] loss: 0.00143, running_loss: 0.914\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[653,   20] loss: 0.00076, running_loss: 0.487\n",
      "Accacy on train_loader set: 99 % [1151/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[654,   20] loss: 0.00063, running_loss: 0.402\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[655,   20] loss: 0.00110, running_loss: 0.704\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[656,   20] loss: 0.00106, running_loss: 0.676\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[657,   20] loss: 0.00074, running_loss: 0.474\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[658,   20] loss: 0.00104, running_loss: 0.669\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 80 % [116/144]\n",
      "[659,   20] loss: 0.00097, running_loss: 0.624\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[660,   20] loss: 0.00100, running_loss: 0.638\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[661,   20] loss: 0.00070, running_loss: 0.449\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[662,   20] loss: 0.00077, running_loss: 0.490\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[663,   20] loss: 0.00102, running_loss: 0.653\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[664,   20] loss: 0.00071, running_loss: 0.457\n",
      "Accacy on train_loader set: 99 % [1150/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[665,   20] loss: 0.00106, running_loss: 0.678\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[666,   20] loss: 0.00090, running_loss: 0.575\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[667,   20] loss: 0.00101, running_loss: 0.647\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[668,   20] loss: 0.00098, running_loss: 0.625\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[669,   20] loss: 0.00096, running_loss: 0.614\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[670,   20] loss: 0.00076, running_loss: 0.486\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[671,   20] loss: 0.00072, running_loss: 0.462\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[672,   20] loss: 0.00067, running_loss: 0.430\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[673,   20] loss: 0.00068, running_loss: 0.438\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[674,   20] loss: 0.00079, running_loss: 0.505\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[675,   20] loss: 0.00072, running_loss: 0.461\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[676,   20] loss: 0.00087, running_loss: 0.558\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[677,   20] loss: 0.00077, running_loss: 0.490\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[678,   20] loss: 0.00082, running_loss: 0.528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[679,   20] loss: 0.00138, running_loss: 0.881\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[680,   20] loss: 0.00076, running_loss: 0.486\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[681,   20] loss: 0.00089, running_loss: 0.571\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[682,   20] loss: 0.00092, running_loss: 0.591\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[683,   20] loss: 0.00070, running_loss: 0.445\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[684,   20] loss: 0.00095, running_loss: 0.608\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[685,   20] loss: 0.00118, running_loss: 0.756\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[686,   20] loss: 0.00084, running_loss: 0.536\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[687,   20] loss: 0.00098, running_loss: 0.627\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[688,   20] loss: 0.00114, running_loss: 0.732\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[689,   20] loss: 0.00105, running_loss: 0.669\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[690,   20] loss: 0.00119, running_loss: 0.760\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[691,   20] loss: 0.00105, running_loss: 0.669\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[692,   20] loss: 0.00094, running_loss: 0.602\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[693,   20] loss: 0.00152, running_loss: 0.975\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[694,   20] loss: 0.00107, running_loss: 0.683\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[695,   20] loss: 0.00099, running_loss: 0.635\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[696,   20] loss: 0.00101, running_loss: 0.648\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[697,   20] loss: 0.00134, running_loss: 0.858\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 65 % [94/144]\n",
      "[698,   20] loss: 0.00130, running_loss: 0.831\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[699,   20] loss: 0.00133, running_loss: 0.851\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[700,   20] loss: 0.00107, running_loss: 0.685\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[701,   20] loss: 0.00100, running_loss: 0.643\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[702,   20] loss: 0.00101, running_loss: 0.644\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[703,   20] loss: 0.00168, running_loss: 1.073\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[704,   20] loss: 0.00124, running_loss: 0.797\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[705,   20] loss: 0.00104, running_loss: 0.665\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[706,   20] loss: 0.00082, running_loss: 0.522\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[707,   20] loss: 0.00129, running_loss: 0.828\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[708,   20] loss: 0.00063, running_loss: 0.406\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[709,   20] loss: 0.00124, running_loss: 0.791\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[710,   20] loss: 0.00084, running_loss: 0.540\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[711,   20] loss: 0.00101, running_loss: 0.644\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[712,   20] loss: 0.00112, running_loss: 0.715\n",
      "Accacy on train_loader set: 98 % [1134/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[713,   20] loss: 0.00097, running_loss: 0.618\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[714,   20] loss: 0.00145, running_loss: 0.927\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[715,   20] loss: 0.00141, running_loss: 0.901\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[716,   20] loss: 0.00161, running_loss: 1.031\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[717,   20] loss: 0.00133, running_loss: 0.850\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 79 % [115/144]\n",
      "[718,   20] loss: 0.00162, running_loss: 1.039\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[719,   20] loss: 0.00125, running_loss: 0.797\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[720,   20] loss: 0.00107, running_loss: 0.688\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[721,   20] loss: 0.00157, running_loss: 1.004\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[722,   20] loss: 0.00160, running_loss: 1.023\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[723,   20] loss: 0.00104, running_loss: 0.667\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 80 % [116/144]\n",
      "[724,   20] loss: 0.00094, running_loss: 0.602\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[725,   20] loss: 0.00108, running_loss: 0.689\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[726,   20] loss: 0.00093, running_loss: 0.596\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[727,   20] loss: 0.00086, running_loss: 0.548\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[728,   20] loss: 0.00109, running_loss: 0.696\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[729,   20] loss: 0.00137, running_loss: 0.874\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[730,   20] loss: 0.00108, running_loss: 0.689\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[731,   20] loss: 0.00084, running_loss: 0.537\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[732,   20] loss: 0.00112, running_loss: 0.717\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[733,   20] loss: 0.00148, running_loss: 0.944\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[734,   20] loss: 0.00081, running_loss: 0.516\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[735,   20] loss: 0.00110, running_loss: 0.704\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[736,   20] loss: 0.00092, running_loss: 0.586\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[737,   20] loss: 0.00123, running_loss: 0.789\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[738,   20] loss: 0.00080, running_loss: 0.510\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[739,   20] loss: 0.00094, running_loss: 0.604\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[740,   20] loss: 0.00152, running_loss: 0.974\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[741,   20] loss: 0.00119, running_loss: 0.763\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[742,   20] loss: 0.00085, running_loss: 0.541\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[743,   20] loss: 0.00121, running_loss: 0.776\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 56 % [82/144]\n",
      "[744,   20] loss: 0.00125, running_loss: 0.799\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[745,   20] loss: 0.00080, running_loss: 0.511\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[746,   20] loss: 0.00117, running_loss: 0.747\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[747,   20] loss: 0.00082, running_loss: 0.527\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[748,   20] loss: 0.00121, running_loss: 0.773\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[749,   20] loss: 0.00111, running_loss: 0.708\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 79 % [115/144]\n",
      "[750,   20] loss: 0.00109, running_loss: 0.699\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[751,   20] loss: 0.00082, running_loss: 0.528\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[752,   20] loss: 0.00087, running_loss: 0.556\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[753,   20] loss: 0.00159, running_loss: 1.019\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[754,   20] loss: 0.00150, running_loss: 0.961\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[755,   20] loss: 0.00120, running_loss: 0.765\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[756,   20] loss: 0.00081, running_loss: 0.520\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[757,   20] loss: 0.00150, running_loss: 0.959\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 80 % [116/144]\n",
      "[758,   20] loss: 0.00145, running_loss: 0.929\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[759,   20] loss: 0.00093, running_loss: 0.597\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[760,   20] loss: 0.00126, running_loss: 0.804\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[761,   20] loss: 0.00087, running_loss: 0.556\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[762,   20] loss: 0.00070, running_loss: 0.450\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[763,   20] loss: 0.00119, running_loss: 0.765\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[764,   20] loss: 0.00135, running_loss: 0.862\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[765,   20] loss: 0.00092, running_loss: 0.592\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[766,   20] loss: 0.00072, running_loss: 0.461\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[767,   20] loss: 0.00123, running_loss: 0.784\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[768,   20] loss: 0.00073, running_loss: 0.467\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[769,   20] loss: 0.00118, running_loss: 0.757\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[770,   20] loss: 0.00140, running_loss: 0.898\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 81 % [117/144]\n",
      "[771,   20] loss: 0.00084, running_loss: 0.538\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[772,   20] loss: 0.00078, running_loss: 0.498\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[773,   20] loss: 0.00085, running_loss: 0.547\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[774,   20] loss: 0.00081, running_loss: 0.516\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[775,   20] loss: 0.00105, running_loss: 0.672\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[776,   20] loss: 0.00136, running_loss: 0.869\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[777,   20] loss: 0.00087, running_loss: 0.558\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[778,   20] loss: 0.00077, running_loss: 0.492\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[779,   20] loss: 0.00124, running_loss: 0.792\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[780,   20] loss: 0.00090, running_loss: 0.579\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[781,   20] loss: 0.00131, running_loss: 0.839\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 80 % [116/144]\n",
      "[782,   20] loss: 0.00099, running_loss: 0.636\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[783,   20] loss: 0.00142, running_loss: 0.909\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[784,   20] loss: 0.00106, running_loss: 0.680\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[785,   20] loss: 0.00137, running_loss: 0.874\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[786,   20] loss: 0.00118, running_loss: 0.757\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[787,   20] loss: 0.00095, running_loss: 0.607\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 79 % [115/144]\n",
      "[788,   20] loss: 0.00089, running_loss: 0.569\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[789,   20] loss: 0.00075, running_loss: 0.483\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[790,   20] loss: 0.00097, running_loss: 0.622\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[791,   20] loss: 0.00124, running_loss: 0.792\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 80 % [116/144]\n",
      "[792,   20] loss: 0.00104, running_loss: 0.669\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[793,   20] loss: 0.00060, running_loss: 0.385\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[794,   20] loss: 0.00147, running_loss: 0.943\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[795,   20] loss: 0.00062, running_loss: 0.400\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[796,   20] loss: 0.00087, running_loss: 0.555\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[797,   20] loss: 0.00085, running_loss: 0.541\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[798,   20] loss: 0.00110, running_loss: 0.703\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[799,   20] loss: 0.00083, running_loss: 0.531\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[800,   20] loss: 0.00110, running_loss: 0.707\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[801,   20] loss: 0.00123, running_loss: 0.786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[802,   20] loss: 0.00117, running_loss: 0.746\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[803,   20] loss: 0.00097, running_loss: 0.621\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[804,   20] loss: 0.00078, running_loss: 0.500\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 80 % [116/144]\n",
      "[805,   20] loss: 0.00114, running_loss: 0.726\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[806,   20] loss: 0.00127, running_loss: 0.812\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[807,   20] loss: 0.00124, running_loss: 0.795\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[808,   20] loss: 0.00082, running_loss: 0.524\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[809,   20] loss: 0.00069, running_loss: 0.441\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[810,   20] loss: 0.00110, running_loss: 0.704\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[811,   20] loss: 0.00122, running_loss: 0.779\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[812,   20] loss: 0.00132, running_loss: 0.846\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[813,   20] loss: 0.00081, running_loss: 0.517\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[814,   20] loss: 0.00099, running_loss: 0.633\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[815,   20] loss: 0.00139, running_loss: 0.892\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[816,   20] loss: 0.00094, running_loss: 0.599\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[817,   20] loss: 0.00131, running_loss: 0.837\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[818,   20] loss: 0.00116, running_loss: 0.743\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[819,   20] loss: 0.00097, running_loss: 0.620\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[820,   20] loss: 0.00076, running_loss: 0.487\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[821,   20] loss: 0.00119, running_loss: 0.762\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[822,   20] loss: 0.00175, running_loss: 1.121\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[823,   20] loss: 0.00122, running_loss: 0.782\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 81 % [117/144]\n",
      "[824,   20] loss: 0.00080, running_loss: 0.510\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[825,   20] loss: 0.00077, running_loss: 0.491\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[826,   20] loss: 0.00105, running_loss: 0.670\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[827,   20] loss: 0.00087, running_loss: 0.557\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[828,   20] loss: 0.00123, running_loss: 0.787\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[829,   20] loss: 0.00084, running_loss: 0.537\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[830,   20] loss: 0.00094, running_loss: 0.599\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[831,   20] loss: 0.00141, running_loss: 0.900\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[832,   20] loss: 0.00097, running_loss: 0.619\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[833,   20] loss: 0.00149, running_loss: 0.953\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[834,   20] loss: 0.00084, running_loss: 0.534\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[835,   20] loss: 0.00076, running_loss: 0.486\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 79 % [115/144]\n",
      "[836,   20] loss: 0.00096, running_loss: 0.616\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[837,   20] loss: 0.00085, running_loss: 0.544\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[838,   20] loss: 0.00097, running_loss: 0.620\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[839,   20] loss: 0.00071, running_loss: 0.455\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[840,   20] loss: 0.00130, running_loss: 0.830\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[841,   20] loss: 0.00111, running_loss: 0.711\n",
      "Accacy on train_loader set: 98 % [1133/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[842,   20] loss: 0.00182, running_loss: 1.165\n",
      "Accacy on train_loader set: 98 % [1132/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[843,   20] loss: 0.00102, running_loss: 0.655\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[844,   20] loss: 0.00090, running_loss: 0.575\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[845,   20] loss: 0.00095, running_loss: 0.608\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 81 % [117/144]\n",
      "[846,   20] loss: 0.00125, running_loss: 0.802\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[847,   20] loss: 0.00110, running_loss: 0.701\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[848,   20] loss: 0.00095, running_loss: 0.606\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[849,   20] loss: 0.00146, running_loss: 0.935\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[850,   20] loss: 0.00103, running_loss: 0.659\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[851,   20] loss: 0.00117, running_loss: 0.748\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[852,   20] loss: 0.00073, running_loss: 0.468\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[853,   20] loss: 0.00108, running_loss: 0.689\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 64 % [93/144]\n",
      "[854,   20] loss: 0.00123, running_loss: 0.785\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[855,   20] loss: 0.00070, running_loss: 0.448\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[856,   20] loss: 0.00097, running_loss: 0.619\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[857,   20] loss: 0.00083, running_loss: 0.528\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[858,   20] loss: 0.00096, running_loss: 0.617\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[859,   20] loss: 0.00121, running_loss: 0.771\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[860,   20] loss: 0.00095, running_loss: 0.606\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 80 % [116/144]\n",
      "[861,   20] loss: 0.00108, running_loss: 0.692\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[862,   20] loss: 0.00135, running_loss: 0.866\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[863,   20] loss: 0.00097, running_loss: 0.619\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[864,   20] loss: 0.00099, running_loss: 0.636\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[865,   20] loss: 0.00070, running_loss: 0.447\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[866,   20] loss: 0.00130, running_loss: 0.833\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[867,   20] loss: 0.00069, running_loss: 0.443\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[868,   20] loss: 0.00100, running_loss: 0.642\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 80 % [116/144]\n",
      "[869,   20] loss: 0.00075, running_loss: 0.477\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[870,   20] loss: 0.00097, running_loss: 0.624\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[871,   20] loss: 0.00101, running_loss: 0.645\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[872,   20] loss: 0.00116, running_loss: 0.745\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[873,   20] loss: 0.00121, running_loss: 0.774\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[874,   20] loss: 0.00107, running_loss: 0.684\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[875,   20] loss: 0.00135, running_loss: 0.867\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[876,   20] loss: 0.00093, running_loss: 0.596\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[877,   20] loss: 0.00129, running_loss: 0.823\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[878,   20] loss: 0.00100, running_loss: 0.638\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[879,   20] loss: 0.00095, running_loss: 0.606\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[880,   20] loss: 0.00138, running_loss: 0.885\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 79 % [114/144]\n",
      "[881,   20] loss: 0.00116, running_loss: 0.745\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[882,   20] loss: 0.00085, running_loss: 0.544\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[883,   20] loss: 0.00128, running_loss: 0.819\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[884,   20] loss: 0.00100, running_loss: 0.641\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[885,   20] loss: 0.00081, running_loss: 0.521\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[886,   20] loss: 0.00153, running_loss: 0.977\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[887,   20] loss: 0.00126, running_loss: 0.807\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[888,   20] loss: 0.00085, running_loss: 0.546\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[889,   20] loss: 0.00110, running_loss: 0.701\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[890,   20] loss: 0.00091, running_loss: 0.581\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 79 % [115/144]\n",
      "[891,   20] loss: 0.00109, running_loss: 0.700\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[892,   20] loss: 0.00124, running_loss: 0.795\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[893,   20] loss: 0.00096, running_loss: 0.616\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[894,   20] loss: 0.00110, running_loss: 0.701\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[895,   20] loss: 0.00077, running_loss: 0.493\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[896,   20] loss: 0.00105, running_loss: 0.671\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[897,   20] loss: 0.00090, running_loss: 0.578\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[898,   20] loss: 0.00085, running_loss: 0.546\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[899,   20] loss: 0.00119, running_loss: 0.763\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[900,   20] loss: 0.00097, running_loss: 0.618\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[901,   20] loss: 0.00115, running_loss: 0.737\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[902,   20] loss: 0.00134, running_loss: 0.857\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[903,   20] loss: 0.00092, running_loss: 0.590\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[904,   20] loss: 0.00079, running_loss: 0.507\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[905,   20] loss: 0.00098, running_loss: 0.627\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[906,   20] loss: 0.00069, running_loss: 0.445\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[907,   20] loss: 0.00076, running_loss: 0.486\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[908,   20] loss: 0.00092, running_loss: 0.586\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[909,   20] loss: 0.00125, running_loss: 0.800\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[910,   20] loss: 0.00122, running_loss: 0.781\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[911,   20] loss: 0.00107, running_loss: 0.686\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[912,   20] loss: 0.00134, running_loss: 0.856\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[913,   20] loss: 0.00097, running_loss: 0.620\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[914,   20] loss: 0.00086, running_loss: 0.551\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[915,   20] loss: 0.00157, running_loss: 1.004\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[916,   20] loss: 0.00076, running_loss: 0.486\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[917,   20] loss: 0.00090, running_loss: 0.577\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[918,   20] loss: 0.00089, running_loss: 0.569\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[919,   20] loss: 0.00093, running_loss: 0.598\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[920,   20] loss: 0.00147, running_loss: 0.943\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[921,   20] loss: 0.00113, running_loss: 0.721\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[922,   20] loss: 0.00143, running_loss: 0.914\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[923,   20] loss: 0.00123, running_loss: 0.786\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[924,   20] loss: 0.00124, running_loss: 0.796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[925,   20] loss: 0.00104, running_loss: 0.664\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[926,   20] loss: 0.00159, running_loss: 1.018\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[927,   20] loss: 0.00098, running_loss: 0.630\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[928,   20] loss: 0.00118, running_loss: 0.753\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[929,   20] loss: 0.00138, running_loss: 0.885\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[930,   20] loss: 0.00108, running_loss: 0.693\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[931,   20] loss: 0.00091, running_loss: 0.581\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[932,   20] loss: 0.00122, running_loss: 0.784\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[933,   20] loss: 0.00091, running_loss: 0.580\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[934,   20] loss: 0.00121, running_loss: 0.775\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[935,   20] loss: 0.00123, running_loss: 0.786\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[936,   20] loss: 0.00156, running_loss: 0.999\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[937,   20] loss: 0.00105, running_loss: 0.675\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[938,   20] loss: 0.00074, running_loss: 0.473\n",
      "Accacy on train_loader set: 99 % [1151/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[939,   20] loss: 0.00080, running_loss: 0.513\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[940,   20] loss: 0.00060, running_loss: 0.382\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[941,   20] loss: 0.00062, running_loss: 0.398\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 78 % [113/144]\n",
      "[942,   20] loss: 0.00088, running_loss: 0.561\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[943,   20] loss: 0.00103, running_loss: 0.660\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[944,   20] loss: 0.00086, running_loss: 0.548\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[945,   20] loss: 0.00084, running_loss: 0.538\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[946,   20] loss: 0.00091, running_loss: 0.584\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[947,   20] loss: 0.00098, running_loss: 0.627\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[948,   20] loss: 0.00095, running_loss: 0.607\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[949,   20] loss: 0.00103, running_loss: 0.659\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[950,   20] loss: 0.00098, running_loss: 0.626\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[951,   20] loss: 0.00094, running_loss: 0.599\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[952,   20] loss: 0.00105, running_loss: 0.670\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[953,   20] loss: 0.00117, running_loss: 0.747\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[954,   20] loss: 0.00086, running_loss: 0.548\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[955,   20] loss: 0.00079, running_loss: 0.507\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[956,   20] loss: 0.00104, running_loss: 0.666\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[957,   20] loss: 0.00123, running_loss: 0.786\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 68 % [98/144]\n",
      "[958,   20] loss: 0.00090, running_loss: 0.575\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[959,   20] loss: 0.00091, running_loss: 0.584\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[960,   20] loss: 0.00114, running_loss: 0.729\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[961,   20] loss: 0.00129, running_loss: 0.827\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[962,   20] loss: 0.00091, running_loss: 0.583\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[963,   20] loss: 0.00102, running_loss: 0.652\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[964,   20] loss: 0.00129, running_loss: 0.826\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[965,   20] loss: 0.00106, running_loss: 0.679\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[966,   20] loss: 0.00101, running_loss: 0.645\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[967,   20] loss: 0.00179, running_loss: 1.146\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[968,   20] loss: 0.00099, running_loss: 0.636\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[969,   20] loss: 0.00089, running_loss: 0.567\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[970,   20] loss: 0.00122, running_loss: 0.778\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[971,   20] loss: 0.00109, running_loss: 0.699\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[972,   20] loss: 0.00083, running_loss: 0.531\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[973,   20] loss: 0.00125, running_loss: 0.799\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[974,   20] loss: 0.00114, running_loss: 0.727\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[975,   20] loss: 0.00112, running_loss: 0.718\n",
      "Accacy on train_loader set: 98 % [1136/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[976,   20] loss: 0.00106, running_loss: 0.681\n",
      "Accacy on train_loader set: 98 % [1135/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[977,   20] loss: 0.00117, running_loss: 0.752\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[978,   20] loss: 0.00098, running_loss: 0.629\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[979,   20] loss: 0.00114, running_loss: 0.728\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[980,   20] loss: 0.00129, running_loss: 0.826\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[981,   20] loss: 0.00101, running_loss: 0.646\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[982,   20] loss: 0.00115, running_loss: 0.739\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[983,   20] loss: 0.00091, running_loss: 0.581\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[984,   20] loss: 0.00102, running_loss: 0.651\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 61 % [89/144]\n",
      "[985,   20] loss: 0.00078, running_loss: 0.500\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[986,   20] loss: 0.00148, running_loss: 0.945\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[987,   20] loss: 0.00111, running_loss: 0.708\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[988,   20] loss: 0.00089, running_loss: 0.571\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[989,   20] loss: 0.00083, running_loss: 0.534\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[990,   20] loss: 0.00093, running_loss: 0.592\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[991,   20] loss: 0.00123, running_loss: 0.785\n",
      "Accacy on train_loader set: 98 % [1140/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[992,   20] loss: 0.00077, running_loss: 0.494\n",
      "Accacy on train_loader set: 98 % [1129/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[993,   20] loss: 0.00114, running_loss: 0.727\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[994,   20] loss: 0.00108, running_loss: 0.688\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[995,   20] loss: 0.00126, running_loss: 0.803\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[996,   20] loss: 0.00085, running_loss: 0.541\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[997,   20] loss: 0.00083, running_loss: 0.529\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[998,   20] loss: 0.00094, running_loss: 0.602\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[999,   20] loss: 0.00070, running_loss: 0.447\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1000,   20] loss: 0.00049, running_loss: 0.312\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1001,   20] loss: 0.00100, running_loss: 0.641\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1002,   20] loss: 0.00086, running_loss: 0.548\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1003,   20] loss: 0.00092, running_loss: 0.590\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1004,   20] loss: 0.00111, running_loss: 0.708\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n",
      "[1005,   20] loss: 0.00078, running_loss: 0.500\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1006,   20] loss: 0.00122, running_loss: 0.780\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1007,   20] loss: 0.00088, running_loss: 0.565\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1008,   20] loss: 0.00092, running_loss: 0.588\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1009,   20] loss: 0.00126, running_loss: 0.803\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1010,   20] loss: 0.00087, running_loss: 0.559\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 81 % [117/144]\n",
      "[1011,   20] loss: 0.00128, running_loss: 0.820\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1012,   20] loss: 0.00070, running_loss: 0.450\n",
      "Accacy on train_loader set: 99 % [1150/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1013,   20] loss: 0.00097, running_loss: 0.619\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 67 % [97/144]\n",
      "[1014,   20] loss: 0.00104, running_loss: 0.663\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1015,   20] loss: 0.00092, running_loss: 0.589\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1016,   20] loss: 0.00109, running_loss: 0.696\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1017,   20] loss: 0.00092, running_loss: 0.589\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1018,   20] loss: 0.00089, running_loss: 0.571\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1019,   20] loss: 0.00087, running_loss: 0.559\n",
      "Accacy on train_loader set: 99 % [1148/1152]\n",
      "Accacy on eval_loader set: 79 % [115/144]\n",
      "[1020,   20] loss: 0.00073, running_loss: 0.469\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1021,   20] loss: 0.00097, running_loss: 0.620\n",
      "Accacy on train_loader set: 98 % [1138/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1022,   20] loss: 0.00129, running_loss: 0.828\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1023,   20] loss: 0.00077, running_loss: 0.493\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1024,   20] loss: 0.00109, running_loss: 0.701\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1025,   20] loss: 0.00135, running_loss: 0.867\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1026,   20] loss: 0.00101, running_loss: 0.650\n",
      "Accacy on train_loader set: 99 % [1143/1152]\n",
      "Accacy on eval_loader set: 68 % [99/144]\n",
      "[1027,   20] loss: 0.00115, running_loss: 0.738\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1028,   20] loss: 0.00070, running_loss: 0.447\n",
      "Accacy on train_loader set: 99 % [1149/1152]\n",
      "Accacy on eval_loader set: 71 % [103/144]\n",
      "[1029,   20] loss: 0.00119, running_loss: 0.764\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1030,   20] loss: 0.00111, running_loss: 0.711\n",
      "Accacy on train_loader set: 98 % [1137/1152]\n",
      "Accacy on eval_loader set: 72 % [104/144]\n",
      "[1031,   20] loss: 0.00062, running_loss: 0.399\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1032,   20] loss: 0.00070, running_loss: 0.445\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1033,   20] loss: 0.00117, running_loss: 0.748\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [101/144]\n",
      "[1034,   20] loss: 0.00098, running_loss: 0.625\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1035,   20] loss: 0.00142, running_loss: 0.912\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1036,   20] loss: 0.00086, running_loss: 0.549\n",
      "Accacy on train_loader set: 99 % [1147/1152]\n",
      "Accacy on eval_loader set: 74 % [107/144]\n",
      "[1037,   20] loss: 0.00096, running_loss: 0.612\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1038,   20] loss: 0.00139, running_loss: 0.892\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1039,   20] loss: 0.00097, running_loss: 0.620\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1040,   20] loss: 0.00128, running_loss: 0.821\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1041,   20] loss: 0.00105, running_loss: 0.672\n",
      "Accacy on train_loader set: 99 % [1142/1152]\n",
      "Accacy on eval_loader set: 76 % [110/144]\n",
      "[1042,   20] loss: 0.00080, running_loss: 0.514\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 75 % [108/144]\n",
      "[1043,   20] loss: 0.00099, running_loss: 0.636\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 51 % [74/144]\n",
      "[1044,   20] loss: 0.00131, running_loss: 0.837\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1045,   20] loss: 0.00062, running_loss: 0.394\n",
      "Accacy on train_loader set: 99 % [1145/1152]\n",
      "Accacy on eval_loader set: 70 % [102/144]\n",
      "[1046,   20] loss: 0.00109, running_loss: 0.695\n",
      "Accacy on train_loader set: 99 % [1141/1152]\n",
      "Accacy on eval_loader set: 77 % [112/144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1047,   20] loss: 0.00099, running_loss: 0.635\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 69 % [100/144]\n",
      "[1048,   20] loss: 0.00092, running_loss: 0.590\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 73 % [106/144]\n",
      "[1049,   20] loss: 0.00112, running_loss: 0.718\n",
      "Accacy on train_loader set: 99 % [1146/1152]\n",
      "Accacy on eval_loader set: 72 % [105/144]\n",
      "[1050,   20] loss: 0.00105, running_loss: 0.670\n",
      "Accacy on train_loader set: 99 % [1144/1152]\n",
      "Accacy on eval_loader set: 77 % [111/144]\n",
      "[1051,   20] loss: 0.00130, running_loss: 0.829\n",
      "Accacy on train_loader set: 98 % [1139/1152]\n",
      "Accacy on eval_loader set: 75 % [109/144]\n",
      "[1052,   20] loss: 0.00124, running_loss: 0.790\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1336/3196921788.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mcorrect_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eval_loader'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmax_correct_rate\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcorrect_rate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1336/2382891494.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    for epoch in range(3500):\n",
    "        train(epoch)\n",
    "        correct_rate=validate('eval_loader')\n",
    "        if max_correct_rate < correct_rate:\n",
    "            max_correct_rate = correct_rate\n",
    "            saveModel(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da277c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c62dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model=loadModel(model_path)\n",
    "    validate('test_loader')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
